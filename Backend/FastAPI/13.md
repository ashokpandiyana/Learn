# Chapter 13: Deployment & Production Concerns

## Introduction to Production Deployment

Moving from development to production requires:
- Proper server configuration
- Containerization
- Environment management
- Scaling strategies
- Monitoring and logging
- Security hardening

---

## Running with Production Servers

### Uvicorn Configuration

```bash
# Development (auto-reload, single worker)
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Production (multiple workers, no reload)
uvicorn main:app \
    --host 0.0.0.0 \
    --port 8000 \
    --workers 4 \
    --log-level info \
    --access-log \
    --no-use-colors
```

### Gunicorn with Uvicorn Workers

```bash
# Install Gunicorn
uv pip install gunicorn

# Run with Gunicorn + Uvicorn workers
gunicorn main:app \
    --workers 4 \
    --worker-class uvicorn.workers.UvicornWorker \
    --bind 0.0.0.0:8000 \
    --timeout 120 \
    --graceful-timeout 30 \
    --keep-alive 5 \
    --access-logfile - \
    --error-logfile - \
    --log-level info
```

### Calculating Worker Count

```python
# config/server.py
import multiprocessing

def calculate_workers():
    """
    Calculate optimal number of workers
    Formula: (2 x num_cores) + 1
    """
    cores = multiprocessing.cpu_count()
    workers = (2 * cores) + 1
    return workers

# gunicorn_config.py
import multiprocessing

# Server socket
bind = "0.0.0.0:8000"

# Worker processes
workers = (multiprocessing.cpu_count() * 2) + 1
worker_class = "uvicorn.workers.UvicornWorker"

# Timeout
timeout = 120
graceful_timeout = 30
keepalive = 5

# Logging
accesslog = "-"
errorlog = "-"
loglevel = "info"

# Process naming
proc_name = "fastapi-app"

# Worker lifecycle
max_requests = 1000  # Restart workers after N requests
max_requests_jitter = 50  # Add randomness to prevent simultaneous restarts
```

### Running with Configuration File

```bash
# Run with config file
gunicorn -c gunicorn_config.py main:app
```

---

## Containerization with Docker

### Basic Dockerfile

```dockerfile
# Dockerfile
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Install UV
RUN pip install uv

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN uv pip install --system --no-cache -r requirements.txt

# Copy application code
COPY ./app ./app

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Multi-Stage Build (Optimized)

```dockerfile
# Multi-stage Dockerfile
# Stage 1: Build dependencies
FROM python:3.11-slim as builder

WORKDIR /app

# Install UV
RUN pip install uv

# Copy requirements
COPY requirements.txt .

# Install dependencies to /app/.venv
RUN uv venv /app/.venv && \
    . /app/.venv/bin/activate && \
    uv pip install --no-cache -r requirements.txt

# Stage 2: Runtime
FROM python:3.11-slim

WORKDIR /app

# Copy virtual environment from builder
COPY --from=builder /app/.venv /app/.venv

# Copy application code
COPY ./app ./app

# Create non-root user
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app
USER appuser

# Use virtual environment
ENV PATH="/app/.venv/bin:$PATH"

EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=3s \
    CMD python -c "import requests; requests.get('http://localhost:8000/health', timeout=2)"

CMD ["gunicorn", "app.main:app", \
     "--workers", "4", \
     "--worker-class", "uvicorn.workers.UvicornWorker", \
     "--bind", "0.0.0.0:8000"]
```

### Docker Compose for Development

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/mydb
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./app:/app/app  # Mount for development
    depends_on:
      - db
      - redis
    command: uvicorn app.main:app --host 0.0.0.0 --reload

  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=mydb
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # Database migrations
  migrations:
    build:
      context: .
      dockerfile: Dockerfile
    command: alembic upgrade head
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/mydb
    depends_on:
      - db

volumes:
  postgres_data:
  redis_data:
```

### Docker Compose for Production

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  api:
    image: myregistry.com/myapp:latest
    restart: always
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s

  nginx:
    image: nginx:alpine
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - api

  db:
    image: postgres:15
    restart: always
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_NAME}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 1G

  redis:
    image: redis:7-alpine
    restart: always
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes

volumes:
  postgres_data:
  redis_data:
```

---

## Configuration Management

### Environment Variables with Pydantic

```python
# config.py
from pydantic_settings import BaseSettings
from functools import lru_cache
from typing import Optional

class Settings(BaseSettings):
    """Application settings from environment variables"""
    
    # Application
    APP_NAME: str = "FastAPI Application"
    DEBUG: bool = False
    
    # Server
    HOST: str = "0.0.0.0"
    PORT: int = 8000
    WORKERS: int = 4
    
    # Database
    DATABASE_URL: str
    DB_POOL_SIZE: int = 20
    DB_MAX_OVERFLOW: int = 10
    
    # Redis
    REDIS_URL: str = "redis://localhost:6379/0"
    
    # Security
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    
    # CORS
    CORS_ORIGINS: list = ["http://localhost:3000"]
    
    # AWS (if using)
    AWS_ACCESS_KEY_ID: Optional[str] = None
    AWS_SECRET_ACCESS_KEY: Optional[str] = None
    AWS_REGION: Optional[str] = "us-east-1"
    S3_BUCKET: Optional[str] = None
    
    # Email
    SMTP_HOST: Optional[str] = None
    SMTP_PORT: int = 587
    SMTP_USER: Optional[str] = None
    SMTP_PASSWORD: Optional[str] = None
    
    # Monitoring
    SENTRY_DSN: Optional[str] = None
    
    class Config:
        env_file = ".env"
        case_sensitive = True

@lru_cache()
def get_settings() -> Settings:
    """Get cached settings instance"""
    return Settings()

# Usage
settings = get_settings()
```

### Environment Files

```bash
# .env.development
DEBUG=true
DATABASE_URL=postgresql://user:password@localhost/mydb_dev
REDIS_URL=redis://localhost:6379/0
SECRET_KEY=dev-secret-key-change-in-production
CORS_ORIGINS=["http://localhost:3000","http://localhost:8080"]

# .env.production
DEBUG=false
DATABASE_URL=postgresql://user:${DB_PASSWORD}@prod-db.example.com/mydb
REDIS_URL=redis://prod-redis.example.com:6379/0
SECRET_KEY=${SECRET_KEY_FROM_VAULT}
CORS_ORIGINS=["https://example.com","https://www.example.com"]
SENTRY_DSN=https://key@sentry.io/project

# .env.test
DEBUG=true
DATABASE_URL=postgresql://user:password@localhost/mydb_test
REDIS_URL=redis://localhost:6379/1
SECRET_KEY=test-secret-key
```

---

## Reverse Proxy Configuration

### Nginx Configuration

```nginx
# nginx.conf
events {
    worker_connections 1024;
}

http {
    # Upstream FastAPI servers
    upstream fastapi_backend {
        least_conn;  # Load balancing method
        server api:8000 max_fails=3 fail_timeout=30s;
        # For multiple instances:
        # server api1:8000;
        # server api2:8000;
        # server api3:8000;
    }

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/m;
    
    # Caching
    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:10m 
                     max_size=1g inactive=60m use_temp_path=off;

    server {
        listen 80;
        server_name api.example.com;
        
        # Redirect to HTTPS
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name api.example.com;

        # SSL configuration
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on;

        # Security headers
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-Frame-Options "DENY" always;
        add_header X-XSS-Protection "1; mode=block" always;

        # Client body size limit
        client_max_body_size 10M;

        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # Compression
        gzip on;
        gzip_types text/plain text/css application/json application/javascript text/xml application/xml;
        gzip_min_length 1000;

        # Static files (if serving from Nginx)
        location /static/ {
            alias /app/static/;
            expires 30d;
            add_header Cache-Control "public, immutable";
        }

        # API endpoints
        location /api/ {
            # Rate limiting
            limit_req zone=api_limit burst=20 nodelay;

            # Proxy to FastAPI
            proxy_pass http://fastapi_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # WebSocket support
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
        }

        # Health check endpoint (no rate limit)
        location /health {
            proxy_pass http://fastapi_backend;
            access_log off;
        }

        # Metrics endpoint (restrict access)
        location /metrics {
            allow 10.0.0.0/8;  # Internal network only
            deny all;
            proxy_pass http://fastapi_backend;
        }
    }
}
```

### Traefik Configuration

```yaml
# traefik.yml
version: '3.8'

services:
  traefik:
    image: traefik:v2.10
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--certificatesresolvers.myresolver.acme.httpchallenge=true"
      - "--certificatesresolvers.myresolver.acme.httpchallenge.entrypoint=web"
      - "--certificatesresolvers.myresolver.acme.email=admin@example.com"
      - "--certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json"
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"  # Traefik dashboard
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "./letsencrypt:/letsencrypt"

  api:
    build: .
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.api.rule=Host(`api.example.com`)"
      - "traefik.http.routers.api.entrypoints=websecure"
      - "traefik.http.routers.api.tls.certresolver=myresolver"
      - "traefik.http.services.api.loadbalancer.server.port=8000"
      # Rate limiting
      - "traefik.http.middlewares.ratelimit.ratelimit.average=100"
      - "traefik.http.middlewares.ratelimit.ratelimit.burst=50"
      - "traefik.http.routers.api.middlewares=ratelimit"
    deploy:
      replicas: 3
```

---

## Scaling Strategies

### Horizontal Scaling

```yaml
# Kubernetes deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fastapi-app
spec:
  replicas: 3  # Number of pods
  selector:
    matchLabels:
      app: fastapi
  template:
    metadata:
      labels:
        app: fastapi
    spec:
      containers:
      - name: api
        image: myregistry.com/fastapi-app:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: fastapi-service
spec:
  selector:
    app: fastapi
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: fastapi-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: fastapi-app
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### Stateless Design

```python
# BAD: Stateful (doesn't scale)
user_sessions = {}  # In-memory storage

@app.post("/login")
async def login(credentials: Credentials):
    token = generate_token()
    user_sessions[token] = user_data  # Stored in memory!
    return {"token": token}

# GOOD: Stateless (scales horizontally)
@app.post("/login")
async def login(credentials: Credentials, redis=Depends(get_redis)):
    token = generate_jwt_token(user_data)  # Self-contained
    # Or store in shared Redis
    await redis.set(f"session:{token}", user_data, ex=3600)
    return {"token": token}
```

---

## Database Connection Pooling

### SQLAlchemy Connection Pool

```python
# database.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from config import get_settings

settings = get_settings()

# Create engine with connection pool
engine = create_engine(
    settings.DATABASE_URL,
    pool_size=20,  # Number of connections to keep open
    max_overflow=10,  # Additional connections when pool is full
    pool_pre_ping=True,  # Test connections before using
    pool_recycle=3600,  # Recycle connections after 1 hour
    echo=False  # Set to True for SQL logging
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def get_db():
    """Database session dependency"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

### Async Database Pool

```python
# database_async.py
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

DATABASE_URL = "postgresql+asyncpg://user:pass@localhost/db"

# Create async engine
engine = create_async_engine(
    DATABASE_URL,
    pool_size=20,
    max_overflow=10,
    pool_pre_ping=True,
    echo=False
)

# Create async session factory
async_session = sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False
)

async def get_async_db():
    """Async database session dependency"""
    async with async_session() as session:
        yield session
```

---

## Health Checks

### Comprehensive Health Check

```python
# health.py
from fastapi import APIRouter, Depends, status
from sqlalchemy.orm import Session
from redis import Redis
import httpx
from database import get_db
from cache import get_redis

router = APIRouter()

@router.get("/health/live")
async def liveness():
    """
    Liveness probe - is the app running?
    Kubernetes restarts pod if this fails
    """
    return {"status": "alive"}

@router.get("/health/ready")
async def readiness(
    db: Session = Depends(get_db),
    redis: Redis = Depends(get_redis)
):
    """
    Readiness probe - is the app ready to serve traffic?
    Kubernetes removes from load balancer if this fails
    """
    checks = {}
    overall_status = "ready"
    
    # Check database
    try:
        db.execute("SELECT 1")
        checks["database"] = "healthy"
    except Exception as e:
        checks["database"] = "unhealthy"
        overall_status = "not_ready"
    
    # Check Redis
    try:
        redis.ping()
        checks["redis"] = "healthy"
    except Exception:
        checks["redis"] = "unhealthy"
        overall_status = "not_ready"
    
    if overall_status != "ready":
        return JSONResponse(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            content={"status": overall_status, "checks": checks}
        )
    
    return {"status": overall_status, "checks": checks}

@router.get("/health/detailed")
async def detailed_health():
    """Detailed health with metrics"""
    import psutil
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "uptime": get_uptime(),
        "system": {
            "cpu_percent": psutil.cpu_percent(),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_percent": psutil.disk_usage('/').percent
        },
        "application": {
            "version": "1.0.0",
            "environment": get_settings().ENV
        }
    }
```

---

## Deployment Checklist

### Pre-Deployment

```python
# deployment_checks.py
"""
Pre-deployment validation script
Run before deploying to production
"""

def check_environment_variables():
    """Ensure all required env vars are set"""
    from config import get_settings
    
    settings = get_settings()
    required = [
        "DATABASE_URL",
        "SECRET_KEY",
        "REDIS_URL"
    ]
    
    missing = []
    for var in required:
        if not getattr(settings, var, None):
            missing.append(var)
    
    if missing:
        raise ValueError(f"Missing env vars: {missing}")
    
    print("✓ All environment variables set")

def check_database_migrations():
    """Ensure migrations are up to date"""
    import subprocess
    result = subprocess.run(["alembic", "current"], capture_output=True)
    if result.returncode != 0:
        raise ValueError("Database not initialized")
    print("✓ Database migrations up to date")

def check_dependencies():
    """Ensure no security vulnerabilities"""
    import subprocess
    result = subprocess.run(["safety", "check"], capture_output=True)
    if result.returncode != 0:
        print("⚠ Security vulnerabilities found")
    else:
        print("✓ No known vulnerabilities")

def run_tests():
    """Run test suite"""
    import subprocess
    result = subprocess.run(["pytest", "tests/"], capture_output=True)
    if result.returncode != 0:
        raise ValueError("Tests failed")
    print("✓ All tests passed")

if __name__ == "__main__":
    check_environment_variables()
    check_database_migrations()
    check_dependencies()
    run_tests()
    print("\n✓ Ready for deployment!")
```

---

## Summary

In Chapter 13, you learned:
- Running with production servers (Uvicorn, Gunicorn)
- Worker configuration and calculation
- Docker containerization (single and multi-stage)
- Docker Compose for dev and production
- Configuration management with Pydantic Settings
- Reverse proxy setup (Nginx, Traefik)
- Horizontal scaling strategies
- Kubernetes deployment configuration
- Database connection pooling
- Comprehensive health checks
- Deployment validation checklist

**Production Deployment Checklist:**
- ✅ Use Gunicorn with Uvicorn workers
- ✅ Configure proper worker count
- ✅ Containerize with Docker
- ✅ Use multi-stage builds for smaller images
- ✅ Set up reverse proxy (Nginx/Traefik)
- ✅ Configure SSL/TLS
- ✅ Implement health checks
- ✅ Set up connection pooling
- ✅ Configure proper timeouts
- ✅ Enable compression
- ✅ Set resource limits
- ✅ Implement monitoring
- ✅ Configure logging
- ✅ Set up auto-scaling
- ✅ Use environment variables for config

**Next: Chapter 14 - Security, Compliance & Hardening**