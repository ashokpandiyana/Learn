# Chapter 9: Validation, Serialization & Performance

## Introduction to Data Validation

Validation ensures data integrity and prevents security vulnerabilities. FastAPI uses Pydantic for powerful validation at every layer.

---

## Deep Validation with Pydantic

### Field Validators

```python
from pydantic import BaseModel, field_validator, Field
from typing import Optional
import re

class User(BaseModel):
    username: str = Field(..., min_length=3, max_length=50)
    email: str
    password: str
    age: Optional[int] = None
    website: Optional[str] = None
    
    @field_validator('username')
    @classmethod
    def username_alphanumeric(cls, v: str) -> str:
        """Validate username is alphanumeric"""
        if not re.match(r'^[a-zA-Z0-9_]+$', v):
            raise ValueError('Username must be alphanumeric')
        return v.lower()  # Normalize to lowercase
    
    @field_validator('email')
    @classmethod
    def email_valid(cls, v: str) -> str:
        """Validate email format"""
        pattern = r'^[\w\.-]+@[\w\.-]+\.\w+$'
        if not re.match(pattern, v):
            raise ValueError('Invalid email format')
        return v.lower()
    
    @field_validator('password')
    @classmethod
    def password_strong(cls, v: str) -> str:
        """Validate password strength"""
        if len(v) < 8:
            raise ValueError('Password must be at least 8 characters')
        if not any(c.isupper() for c in v):
            raise ValueError('Password must contain uppercase letter')
        if not any(c.islower() for c in v):
            raise ValueError('Password must contain lowercase letter')
        if not any(c.isdigit() for c in v):
            raise ValueError('Password must contain digit')
        return v
    
    @field_validator('age')
    @classmethod
    def age_valid(cls, v: Optional[int]) -> Optional[int]:
        """Validate age range"""
        if v is not None and (v < 0 or v > 150):
            raise ValueError('Age must be between 0 and 150')
        return v
    
    @field_validator('website')
    @classmethod
    def website_valid(cls, v: Optional[str]) -> Optional[str]:
        """Validate website URL"""
        if v is not None:
            if not v.startswith(('http://', 'https://')):
                raise ValueError('Website must start with http:// or https://')
        return v
```

### Model Validators (Cross-Field Validation)

```python
from pydantic import BaseModel, model_validator, Field
from datetime import date, datetime

class DateRange(BaseModel):
    start_date: date
    end_date: date
    
    @model_validator(mode='after')
    def validate_date_range(self):
        """Validate start_date is before end_date"""
        if self.start_date > self.end_date:
            raise ValueError('start_date must be before end_date')
        return self

class PasswordChange(BaseModel):
    old_password: str
    new_password: str
    confirm_password: str
    
    @model_validator(mode='after')
    def passwords_match(self):
        """Validate new passwords match"""
        if self.new_password != self.confirm_password:
            raise ValueError('New passwords do not match')
        if self.old_password == self.new_password:
            raise ValueError('New password must be different from old password')
        return self

class CreditCard(BaseModel):
    number: str = Field(..., min_length=13, max_length=19)
    cvv: str = Field(..., min_length=3, max_length=4)
    expiry_month: int = Field(..., ge=1, le=12)
    expiry_year: int = Field(..., ge=2024)
    
    @model_validator(mode='after')
    def validate_not_expired(self):
        """Validate card is not expired"""
        current_date = datetime.now()
        expiry_date = datetime(self.expiry_year, self.expiry_month, 1)
        
        if expiry_date < current_date:
            raise ValueError('Credit card has expired')
        return self
    
    @field_validator('number')
    @classmethod
    def validate_luhn(cls, v: str) -> str:
        """Validate credit card number using Luhn algorithm"""
        # Remove spaces
        v = v.replace(' ', '')
        
        # Check if all digits
        if not v.isdigit():
            raise ValueError('Card number must contain only digits')
        
        # Luhn algorithm
        digits = [int(d) for d in v]
        checksum = 0
        
        for i, digit in enumerate(reversed(digits)):
            if i % 2 == 1:
                digit *= 2
                if digit > 9:
                    digit -= 9
            checksum += digit
        
        if checksum % 10 != 0:
            raise ValueError('Invalid credit card number')
        
        return v
```

### Custom Validators with Context

```python
from pydantic import BaseModel, field_validator, ValidationInfo

class Product(BaseModel):
    name: str
    price: float
    discount_price: Optional[float] = None
    
    @field_validator('discount_price')
    @classmethod
    def discount_less_than_price(cls, v: Optional[float], info: ValidationInfo) -> Optional[float]:
        """Validate discount price is less than regular price"""
        if v is not None:
            # Access other field values through info.data
            regular_price = info.data.get('price')
            if regular_price and v >= regular_price:
                raise ValueError('Discount price must be less than regular price')
        return v

class Order(BaseModel):
    items: List[dict]
    subtotal: float
    tax: float
    total: float
    
    @model_validator(mode='after')
    def validate_totals(self):
        """Validate calculated totals are correct"""
        calculated_subtotal = sum(item['price'] * item['quantity'] for item in self.items)
        calculated_total = self.subtotal + self.tax
        
        if abs(calculated_subtotal - self.subtotal) > 0.01:
            raise ValueError('Subtotal does not match items')
        
        if abs(calculated_total - self.total) > 0.01:
            raise ValueError('Total does not match subtotal + tax')
        
        return self
```

### Reusable Validators

```python
from pydantic import BaseModel, field_validator
from typing import Callable

def validate_phone_number(v: str) -> str:
    """Reusable phone number validator"""
    # Remove common formatting characters
    cleaned = re.sub(r'[\s\-\(\)]', '', v)
    
    # Check if it's all digits and correct length
    if not cleaned.isdigit() or len(cleaned) not in [10, 11]:
        raise ValueError('Invalid phone number format')
    
    return cleaned

def validate_postal_code(v: str) -> str:
    """Reusable postal code validator"""
    # US ZIP code format: 12345 or 12345-6789
    pattern = r'^\d{5}(-\d{4})?$'
    if not re.match(pattern, v):
        raise ValueError('Invalid postal code format')
    return v

class Address(BaseModel):
    street: str
    city: str
    state: str
    postal_code: str
    phone: str
    
    # Apply reusable validators
    _validate_postal_code = field_validator('postal_code')(
        lambda cls, v: validate_postal_code(v)
    )
    _validate_phone = field_validator('phone')(
        lambda cls, v: validate_phone_number(v)
    )
```

---

## Advanced Pydantic Features

### Computed Fields

```python
from pydantic import BaseModel, computed_field
from datetime import datetime, date
from typing import List

class Invoice(BaseModel):
    items: List[dict]
    tax_rate: float = 0.1
    discount: float = 0.0
    
    @computed_field
    @property
    def subtotal(self) -> float:
        """Calculate subtotal"""
        return sum(item['price'] * item['quantity'] for item in self.items)
    
    @computed_field
    @property
    def tax(self) -> float:
        """Calculate tax"""
        return round(self.subtotal * self.tax_rate, 2)
    
    @computed_field
    @property
    def total(self) -> float:
        """Calculate total"""
        return round(self.subtotal + self.tax - self.discount, 2)

class Person(BaseModel):
    first_name: str
    last_name: str
    birth_date: date
    
    @computed_field
    @property
    def full_name(self) -> str:
        """Computed full name"""
        return f"{self.first_name} {self.last_name}"
    
    @computed_field
    @property
    def age(self) -> int:
        """Calculate age from birth date"""
        today = date.today()
        return today.year - self.birth_date.year - (
            (today.month, today.day) < (self.birth_date.month, self.birth_date.day)
        )

# Usage
invoice = Invoice(
    items=[
        {"name": "Item 1", "price": 10.0, "quantity": 2},
        {"name": "Item 2", "price": 15.0, "quantity": 1}
    ],
    discount=5.0
)

print(invoice.subtotal)  # 35.0
print(invoice.tax)       # 3.5
print(invoice.total)     # 33.5
print(invoice.model_dump())  # Includes computed fields
```

### Custom Types

```python
from pydantic import BaseModel, Field
from typing import Annotated
from pydantic.functional_validators import AfterValidator

# Define custom validation function
def validate_positive(v: float) -> float:
    if v <= 0:
        raise ValueError('Must be positive')
    return v

def validate_percentage(v: float) -> float:
    if not 0 <= v <= 100:
        raise ValueError('Must be between 0 and 100')
    return v

# Create custom types
PositiveFloat = Annotated[float, AfterValidator(validate_positive)]
Percentage = Annotated[float, AfterValidator(validate_percentage)]

class Product(BaseModel):
    name: str
    price: PositiveFloat  # Must be > 0
    discount: Percentage  # Must be 0-100
    
# Usage
product = Product(name="Item", price=10.5, discount=15.0)  # Valid
# product = Product(name="Item", price=-10, discount=15.0)  # Error: Must be positive
# product = Product(name="Item", price=10, discount=150)     # Error: Must be between 0 and 100
```

### Strict vs Lax Validation

```python
from pydantic import BaseModel, ConfigDict, Field

class StrictModel(BaseModel):
    """Strict validation - no type coercion"""
    model_config = ConfigDict(strict=True)
    
    id: int  # "123" will fail
    price: float  # "10.5" will fail

class LaxModel(BaseModel):
    """Lax validation - type coercion allowed (default)"""
    id: int  # "123" -> 123
    price: float  # "10.5" -> 10.5

# Strict validation for specific fields
class MixedModel(BaseModel):
    id: int  # Lax
    price: Annotated[float, Field(strict=True)]  # Strict
```

---

## Serialization Strategies

### Response Model Filtering

```python
from pydantic import BaseModel, ConfigDict
from typing import Optional

class UserInDB(BaseModel):
    """Complete user model in database"""
    id: int
    username: str
    email: str
    hashed_password: str
    is_active: bool
    is_admin: bool
    
    model_config = ConfigDict(from_attributes=True)

class UserPublic(BaseModel):
    """Public user data (no sensitive fields)"""
    id: int
    username: str
    is_active: bool

class UserPrivate(BaseModel):
    """User's own data (includes email)"""
    id: int
    username: str
    email: str
    is_active: bool

# Endpoints with different response models
@app.get("/users/{user_id}", response_model=UserPublic)
async def get_user_public(user_id: int):
    """Public endpoint - returns limited data"""
    user = get_user_from_db(user_id)
    return user  # Automatically filters to UserPublic fields

@app.get("/users/me", response_model=UserPrivate)
async def get_current_user(user: User = Depends(get_current_user)):
    """Private endpoint - returns more data"""
    return user  # Returns UserPrivate fields
```

### Dynamic Response Models

```python
from typing import Union

@app.get("/users/{user_id}")
async def get_user_dynamic(
    user_id: int,
    include_email: bool = False,
    current_user: Optional[User] = Depends(get_optional_current_user)
):
    """Dynamic response based on authentication and query params"""
    user = get_user_from_db(user_id)
    
    # Return different models based on context
    if current_user and (current_user.id == user_id or current_user.is_admin):
        # Return full data for own profile or admin
        return UserPrivate.model_validate(user)
    elif include_email and current_user:
        # Return with email for authenticated users
        return UserWithEmail.model_validate(user)
    else:
        # Return public data
        return UserPublic.model_validate(user)
```

### Excluding Fields Dynamically

```python
@app.get("/users/{user_id}")
async def get_user_exclude(
    user_id: int,
    exclude_fields: List[str] = Query([])
):
    """Exclude specific fields from response"""
    user = get_user_from_db(user_id)
    
    # Convert to dict and remove excluded fields
    user_dict = user.model_dump(exclude=set(exclude_fields))
    
    return user_dict

# GET /users/1?exclude_fields=email&exclude_fields=phone
```

---

## Performance Optimization

### Database Query Optimization

```python
from sqlalchemy.orm import joinedload, selectinload

@app.get("/users/{user_id}/posts")
async def get_user_posts(user_id: int, db: Session = Depends(get_db)):
    """
    Avoid N+1 queries by eager loading
    """
    # ❌ BAD: N+1 query problem
    # user = db.query(User).filter(User.id == user_id).first()
    # posts = user.posts  # Triggers separate query for each post
    
    # ✅ GOOD: Eager loading
    user = db.query(User).options(
        joinedload(User.posts)  # Loads posts in same query
    ).filter(User.id == user_id).first()
    
    return {"user": user.username, "posts": user.posts}

@app.get("/posts")
async def list_posts(db: Session = Depends(get_db)):
    """List posts with authors"""
    # ✅ GOOD: Use selectinload for one-to-many
    posts = db.query(Post).options(
        selectinload(Post.author),
        selectinload(Post.comments)
    ).limit(100).all()
    
    return posts
```

### Response Caching

```python
from functools import lru_cache
from fastapi import Response
import hashlib
import json

# In-memory caching with LRU
@lru_cache(maxsize=1000)
def get_cached_data(key: str):
    """Cache expensive computation"""
    # Expensive operation
    return compute_expensive_data(key)

@app.get("/expensive")
async def expensive_endpoint(param: str):
    """Endpoint with in-memory caching"""
    result = get_cached_data(param)
    return result

# Redis caching
from redis import Redis
redis_client = Redis(host='localhost', port=6379, decode_responses=True)

def get_cache_key(prefix: str, **kwargs) -> str:
    """Generate cache key from parameters"""
    params = json.dumps(kwargs, sort_keys=True)
    hash_value = hashlib.md5(params.encode()).hexdigest()
    return f"{prefix}:{hash_value}"

@app.get("/users/{user_id}")
async def get_user_cached(user_id: int):
    """Endpoint with Redis caching"""
    cache_key = get_cache_key("user", user_id=user_id)
    
    # Try cache first
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)
    
    # Cache miss - fetch from database
    user = get_user_from_db(user_id)
    
    # Cache for 5 minutes
    redis_client.setex(
        cache_key,
        300,  # 5 minutes
        json.dumps(user.model_dump())
    )
    
    return user

# HTTP caching headers
@app.get("/public-data")
async def get_public_data(response: Response):
    """Endpoint with HTTP caching headers"""
    data = get_data()
    
    # Set caching headers
    response.headers["Cache-Control"] = "public, max-age=3600"  # 1 hour
    response.headers["ETag"] = hashlib.md5(
        json.dumps(data).encode()
    ).hexdigest()
    
    return data
```

### Pagination for Large Datasets

```python
from typing import Generic, TypeVar, List
from pydantic import BaseModel

T = TypeVar('T')

class Page(BaseModel, Generic[T]):
    """Generic pagination response"""
    items: List[T]
    total: int
    page: int
    pages: int
    has_next: bool
    has_prev: bool

@app.get("/users", response_model=Page[UserPublic])
async def list_users_paginated(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    db: Session = Depends(get_db)
):
    """
    Efficient pagination
    Only fetch required rows from database
    """
    skip = (page - 1) * page_size
    
    # Get total count (can be expensive)
    total = db.query(User).count()
    
    # Fetch only needed rows
    users = db.query(User).offset(skip).limit(page_size).all()
    
    pages = (total + page_size - 1) // page_size
    
    return {
        "items": users,
        "total": total,
        "page": page,
        "pages": pages,
        "has_next": page < pages,
        "has_prev": page > 1
    }
```

### Async Operations

```python
import asyncio
from typing import List

@app.get("/aggregate-data")
async def get_aggregate_data():
    """
    Fetch multiple data sources concurrently
    """
    # ❌ SLOW: Sequential (4 seconds total)
    # users = await fetch_users()      # 1 second
    # posts = await fetch_posts()      # 1 second
    # comments = await fetch_comments() # 1 second
    # stats = await fetch_stats()      # 1 second
    
    # ✅ FAST: Concurrent (1 second total)
    users, posts, comments, stats = await asyncio.gather(
        fetch_users(),      # All run concurrently
        fetch_posts(),
        fetch_comments(),
        fetch_stats()
    )
    
    return {
        "users": users,
        "posts": posts,
        "comments": comments,
        "stats": stats
    }

@app.post("/process-items")
async def process_items(items: List[str]):
    """Process items concurrently"""
    # Process all items concurrently
    results = await asyncio.gather(
        *[process_item(item) for item in items]
    )
    
    return {"results": results}
```

### Response Compression

```python
from fastapi.middleware.gzip import GZipMiddleware

app = FastAPI()

# Add compression middleware
app.add_middleware(GZipMiddleware, minimum_size=1000)

@app.get("/large-data")
async def get_large_data():
    """
    Response will be automatically compressed
    if larger than 1000 bytes
    """
    return {"data": "..." * 10000}
```

### Streaming Large Responses

```python
from fastapi.responses import StreamingResponse
import csv
from io import StringIO

@app.get("/export-users")
async def export_users(db: Session = Depends(get_db)):
    """
    Stream CSV instead of loading all data in memory
    """
    def generate_csv():
        # Create CSV in memory
        output = StringIO()
        writer = csv.writer(output)
        
        # Write header
        writer.writerow(['ID', 'Username', 'Email'])
        yield output.getvalue()
        output.truncate(0)
        output.seek(0)
        
        # Stream users in batches
        offset = 0
        batch_size = 1000
        
        while True:
            users = db.query(User).offset(offset).limit(batch_size).all()
            if not users:
                break
            
            for user in users:
                writer.writerow([user.id, user.username, user.email])
                yield output.getvalue()
                output.truncate(0)
                output.seek(0)
            
            offset += batch_size
    
    return StreamingResponse(
        generate_csv(),
        media_type="text/csv",
        headers={"Content-Disposition": "attachment; filename=users.csv"}
    )
```

---

## Performance Monitoring

### Request Timing Middleware

```python
import time
from fastapi import Request

@app.middleware("http")
async def add_process_time_header(request: Request, call_next):
    """Measure request processing time"""
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    response.headers["X-Process-Time"] = str(process_time)
    
    # Log slow requests
    if process_time > 1.0:
        print(f"Slow request: {request.url.path} took {process_time:.2f}s")
    
    return response
```

### Query Performance Logging

```python
from sqlalchemy import event
from sqlalchemy.engine import Engine
import logging

logger = logging.getLogger(__name__)

@event.listens_for(Engine, "before_cursor_execute")
def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    """Log query start time"""
    conn.info.setdefault('query_start_time', []).append(time.time())

@event.listens_for(Engine, "after_cursor_execute")
def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    """Log query execution time"""
    total = time.time() - conn.info['query_start_time'].pop(-1)
    
    # Log slow queries
    if total > 0.1:  # 100ms threshold
        logger.warning(f"Slow query ({total:.3f}s): {statement}")
```

---

## Complete Performance Example

```python
# main.py - Optimized API
from fastapi import FastAPI, Depends, Query, Response
from fastapi.middleware.gzip import GZipMiddleware
from sqlalchemy.orm import Session, joinedload
from typing import List, Optional
import time

app = FastAPI()

# Add compression
app.add_middleware(GZipMiddleware, minimum_size=1000)

# ========== Caching Layer ==========

from functools import wraps
import hashlib
import json

def cache_response(expire: int = 300):
    """Decorator for caching responses"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # Generate cache key
            cache_key = f"{func.__name__}:{hashlib.md5(json.dumps(kwargs).encode()).hexdigest()}"
            
            # Check cache
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            
            # Execute function
            result = await func(*args, **kwargs)
            
            # Cache result
            redis_client.setex(
                cache_key,
                expire,
                json.dumps(result)
            )
            
            return result
        return wrapper
    return decorator

# ========== Optimized Endpoints ==========

@app.get("/users/{user_id}")
@cache_response(expire=300)  # Cache for 5 minutes
async def get_user_optimized(
    user_id: int,
    db: Session = Depends(get_db)
):
    """Optimized user endpoint with caching"""
    user = db.query(User).options(
        joinedload(User.posts)  # Eager load relationships
    ).filter(User.id == user_id).first()
    
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    return UserPublic.model_validate(user)

@app.get("/posts")
async def list_posts_optimized(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    db: Session = Depends(get_db),
    response: Response = None
):
    """
    Optimized post listing with:
    - Pagination
    - Eager loading
    - HTTP caching headers
    """
    skip = (page - 1) * page_size
    
    # Efficient query with eager loading
    posts = db.query(Post).options(
        joinedload(Post.author),
        selectinload(Post.comments)
    ).offset(skip).limit(page_size).all()
    
    # Set caching headers
    response.headers["Cache-Control"] = "public, max-age=60"
    
    return {"posts": posts, "page": page}

@app.get("/dashboard")
async def get_dashboard():
    """
    Dashboard with concurrent data fetching
    """
    # Fetch all data concurrently
    users_count, posts_count, comments_count, stats = await asyncio.gather(
        get_users_count(),
        get_posts_count(),
        get_comments_count(),
        get_statistics()
    )
    
    return {
        "users": users_count,
        "posts": posts_count,
        "comments": comments_count,
        "stats": stats
    }
```

---

## Best Practices

1. **Validate early**: Use Pydantic validators at model level
2. **Cache aggressively**: Cache expensive operations
3. **Eager load relationships**: Avoid N+1 queries
4. **Use async for I/O**: Concurrent external API calls
5. **Paginate everything**: Never return unbounded results
6. **Monitor performance**: Log slow queries and requests
7. **Compress responses**: Enable GZip middleware
8. **Stream large data**: Don't load everything in memory

## Common Pitfalls

1. **Over-validation**: Too strict validation hurts UX
2. **N+1 queries**: Loading relationships in loops
3. **No caching**: Recalculating same data repeatedly
4. **Unbounded queries**: No limits on result size
5. **Blocking I/O**: Using sync operations in async code
6. **Large responses**: Returning entire database tables

---

## Summary

In Chapter 9, you learned:
- Deep validation with Pydantic validators
- Cross-field validation with model validators
- Custom types and reusable validators
- Computed fields for derived data
- Response model filtering strategies
- Performance optimization techniques
- Caching strategies (in-memory, Redis, HTTP)
- Database query optimization
- Async operations for concurrent processing
- Complete optimized API example

**Next: Chapter 10 - Middleware, Observability & Logging**