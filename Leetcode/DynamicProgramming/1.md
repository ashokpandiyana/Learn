# Chapter 1: Foundations of Dynamic Programming

## 1.1 What is Dynamic Programming?

### Definition
Dynamic Programming (DP) is an algorithmic paradigm that solves complex problems by breaking them down into simpler overlapping subproblems and storing their solutions to avoid redundant computations.

### Core Philosophy
The essence of DP lies in the principle: **"Those who cannot remember the past are condemned to repeat it."**

Instead of recalculating the same subproblem multiple times, we store (memoize) the result and reuse it.

### When to Use Dynamic Programming

A problem is suitable for DP when it exhibits **BOTH** of these properties:

#### 1. **Optimal Substructure**
The optimal solution to the problem can be constructed from optimal solutions of its subproblems.

**Example**: Shortest path in a graph
- If the shortest path from A to C goes through B, then the path from A to B must also be the shortest path to B.

#### 2. **Overlapping Subproblems**
The problem can be broken down into subproblems which are reused several times.

**Example**: Fibonacci sequence
- To calculate F(5), we need F(4) and F(3)
- To calculate F(4), we need F(3) and F(2)
- Notice F(3) is calculated multiple times!

### DP vs Other Paradigms

| Paradigm | Properties | Example |
|----------|------------|---------|
| **Divide & Conquer** | Non-overlapping subproblems | Merge Sort, Quick Sort |
| **Greedy** | Local optimal choices lead to global optimal | Dijkstra's, Huffman Coding |
| **Dynamic Programming** | Overlapping subproblems + Optimal substructure | Fibonacci, LCS, Knapsack |

### Important Distinction

**Not all recursive problems need DP!**

```python
# This doesn't need DP - no overlapping subproblems
def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n - 1)

# This NEEDS DP - massive overlapping subproblems
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n - 1) + fibonacci(n - 2)
```

---

## 1.2 Core Concepts

### 1.2.1 Memoization (Top-Down Approach)

Memoization is the **top-down** approach where we write the solution recursively and cache the results.

#### Visualization of Fibonacci Without Memoization
```
                    fib(5)
                   /      \
              fib(4)      fib(3)
             /     \      /     \
        fib(3)   fib(2) fib(2) fib(1)
       /     \   /    \  /    \
   fib(2) fib(1) ...   ...    ...
   /    \
fib(1) fib(0)
```

Notice how fib(3) is calculated **twice**, fib(2) is calculated **three times**!

#### Fibonacci with Memoization

```python
# Method 1: Using dictionary
def fib_memo(n, memo=None):
    if memo is None:
        memo = {}
    
    # Base cases
    if n <= 1:
        return n
    
    # Check if already calculated
    if n in memo:
        return memo[n]
    
    # Calculate and store
    memo[n] = fib_memo(n - 1, memo) + fib_memo(n - 2, memo)
    return memo[n]

# Method 2: Using Python's @lru_cache decorator (preferred)
from functools import lru_cache

@lru_cache(maxsize=None)
def fib_memo_decorator(n):
    if n <= 1:
        return n
    return fib_memo_decorator(n - 1) + fib_memo_decorator(n - 2)

# Method 3: Using @cache (Python 3.9+)
from functools import cache

@cache
def fib_cache(n):
    if n <= 1:
        return n
    return fib_cache(n - 1) + fib_cache(n - 2)

# Test
print(fib_memo(10))           # 55
print(fib_memo_decorator(10)) # 55
print(fib_cache(10))          # 55
```

**Time Complexity**: O(n) - each subproblem calculated once  
**Space Complexity**: O(n) - for memoization + O(n) for recursion stack

#### Pros and Cons of Memoization

**Pros:**
- Natural to write (follows recursive thinking)
- Only computes needed subproblems
- Easier to understand problem structure

**Cons:**
- Recursion stack overhead
- May cause stack overflow for large inputs
- Slightly slower due to function call overhead

---

### 1.2.2 Tabulation (Bottom-Up Approach)

Tabulation is the **bottom-up** approach where we iteratively build up solutions from the smallest subproblems.

#### Fibonacci with Tabulation

```python
def fib_tabulation(n):
    if n <= 1:
        return n
    
    # Create table
    dp = [0] * (n + 1)
    
    # Base cases
    dp[0] = 0
    dp[1] = 1
    
    # Fill table bottom-up
    for i in range(2, n + 1):
        dp[i] = dp[i - 1] + dp[i - 2]
    
    return dp[n]

# Test
print(fib_tabulation(10))  # 55
```

**Time Complexity**: O(n)  
**Space Complexity**: O(n)

#### Pros and Cons of Tabulation

**Pros:**
- No recursion stack overhead
- Usually faster in practice
- Better for space optimization
- Guaranteed to compute all subproblems

**Cons:**
- Less intuitive to write
- Computes ALL subproblems (even if not needed)
- Harder to visualize problem structure

---

### 1.2.3 State Definition

**The state is the set of parameters that uniquely identify a subproblem.**

This is the **most critical** aspect of DP. A good state definition makes the problem easy; a poor one makes it impossible.

#### Example: Climbing Stairs

**Problem**: You can climb 1 or 2 stairs at a time. How many ways to reach stair n?

**State Definition**: `dp[i]` = number of ways to reach stair i

```python
def climbStairs(n):
    if n <= 2:
        return n
    
    dp = [0] * (n + 1)
    dp[1] = 1  # One way to reach stair 1
    dp[2] = 2  # Two ways to reach stair 2
    
    for i in range(3, n + 1):
        dp[i] = dp[i - 1] + dp[i - 2]
    
    return dp[n]
```

**Why this state works**: To reach stair i, we can come from stair (i-1) or stair (i-2), so we sum those possibilities.

---

### 1.2.4 Transition/Recurrence Relation

The **recurrence relation** defines how to compute the current state from previous states.

#### Finding the Recurrence Relation (Step-by-Step)

1. **Define the state clearly**
2. **Think about the last decision made**
3. **Express current state in terms of previous states**

#### Example: House Robber

**Problem**: Houses have money. Can't rob adjacent houses. Maximize money robbed.

**State**: `dp[i]` = maximum money robbing houses 0 to i

**Recurrence Thinking**:
- At house i, you have two choices:
  1. **Rob house i**: Get `nums[i] + dp[i-2]` (can't rob i-1)
  2. **Don't rob house i**: Get `dp[i-1]`
- Take the maximum!

**Recurrence**: `dp[i] = max(nums[i] + dp[i-2], dp[i-1])`

```python
def rob(nums):
    if not nums:
        return 0
    if len(nums) <= 2:
        return max(nums)
    
    n = len(nums)
    dp = [0] * n
    dp[0] = nums[0]
    dp[1] = max(nums[0], nums[1])
    
    for i in range(2, n):
        dp[i] = max(nums[i] + dp[i - 2], dp[i - 1])
    
    return dp[n - 1]

# Test
print(rob([2, 7, 9, 3, 1]))  # 12 (rob houses 0, 2, 4)
```

---

### 1.2.5 Base Cases

Base cases are the **smallest subproblems** where the answer is directly known.

**Critical**: Missing or incorrect base cases are the #1 source of DP bugs!

#### Example: Coin Change

**Problem**: Given coins and amount, find minimum coins needed.

```python
def coinChange(coins, amount):
    # Base case: 0 amount needs 0 coins
    dp = [float('inf')] * (amount + 1)
    dp[0] = 0
    
    for i in range(1, amount + 1):
        for coin in coins:
            if coin <= i:
                dp[i] = min(dp[i], dp[i - coin] + 1)
    
    return dp[amount] if dp[amount] != float('inf') else -1

# Test
print(coinChange([1, 2, 5], 11))  # 3 (5 + 5 + 1)
print(coinChange([2], 3))         # -1 (impossible)
```

**Base Cases Here**:
- `dp[0] = 0`: Zero amount requires zero coins
- Initialize all others to `inf` (impossible until proven otherwise)

---

## 1.3 Time and Space Complexity Analysis

### Analyzing Time Complexity

**Formula**: `Number of States × Time per State`

#### Example Analysis

```python
# Fibonacci
@cache
def fib(n):
    if n <= 1:
        return n
    return fib(n - 1) + fib(n - 2)
```

- **Number of states**: n+1 states (0 to n)
- **Time per state**: O(1) (just addition)
- **Total**: O(n)

```python
# Longest Common Subsequence
def lcs(s1, s2):
    m, n = len(s1), len(s2)
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if s1[i-1] == s2[j-1]:
                dp[i][j] = dp[i-1][j-1] + 1
            else:
                dp[i][j] = max(dp[i-1][j], dp[i][j-1])
    
    return dp[m][n]
```

- **Number of states**: m × n states
- **Time per state**: O(1)
- **Total**: O(m × n)

### Space Optimization Techniques

Many DP problems can have their space complexity reduced!

#### Technique 1: Rolling Array

When current state only depends on previous row/column:

```python
# Fibonacci - Space Optimized
def fib_optimized(n):
    if n <= 1:
        return n
    
    prev2 = 0  # fib(i-2)
    prev1 = 1  # fib(i-1)
    
    for i in range(2, n + 1):
        curr = prev1 + prev2
        prev2 = prev1
        prev1 = curr
    
    return prev1

# Space: O(n) -> O(1)
```

#### Technique 2: 2D to 1D

```python
# LCS - Space Optimized
def lcs_optimized(s1, s2):
    m, n = len(s1), len(s2)
    # Use only one row
    dp = [0] * (n + 1)
    
    for i in range(1, m + 1):
        prev = 0  # This was dp[i-1][j-1]
        for j in range(1, n + 1):
            temp = dp[j]  # Save before overwriting
            if s1[i-1] == s2[j-1]:
                dp[j] = prev + 1
            else:
                dp[j] = max(dp[j], dp[j-1])
            prev = temp
    
    return dp[n]

# Space: O(m × n) -> O(n)
```

---

## 1.4 Python-Specific Tools

### 1.4.1 functools.lru_cache and cache

```python
from functools import lru_cache, cache

# lru_cache with size limit
@lru_cache(maxsize=128)
def expensive_function(n):
    # ...
    pass

# cache with unlimited size (Python 3.9+)
@cache
def another_function(n):
    # ...
    pass

# Clear cache when needed
expensive_function.cache_clear()
```

**Important**: Only use with hashable arguments (int, str, tuple). Lists and dicts won't work!

### 1.4.2 List Comprehensions for DP Tables

```python
# 1D array
dp = [0] * n

# 2D array
dp = [[0] * n for _ in range(m)]

# WRONG - creates shallow copies!
dp = [[0] * n] * m  # All rows reference the same list!

# Initialize with specific values
dp = [float('inf')] * n
dp = [False] * n
```

### 1.4.3 Recursion Limit

Python has a default recursion limit (~1000). For deep recursion:

```python
import sys
sys.setrecursionlimit(10000)

@cache
def deep_recursion(n):
    if n == 0:
        return 0
    return deep_recursion(n - 1) + 1
```

**Warning**: Be careful with this - you can cause a stack overflow if you set it too high!

### 1.4.4 Infinity Values

```python
# For minimization problems
min_val = float('inf')

# For maximization problems
max_val = float('-inf')

# Comparison works naturally
print(5 < float('inf'))   # True
print(-5 > float('-inf')) # True
```

---

## Complete Example: Min Cost Climbing Stairs

Let's put everything together with a complete problem.

**Problem**: Array `cost` where `cost[i]` is cost of ith step. You can start at index 0 or 1. Each time you can climb 1 or 2 steps. Find minimum cost to reach the top (beyond last step).

### Step 1: Identify DP Problem
- Optimal value? ✓ (minimum cost)
- Optimal substructure? ✓ (min cost to reach step i depends on min cost to reach previous steps)
- Overlapping subproblems? ✓ (step i-1 used in multiple calculations)

### Step 2: Define State
`dp[i]` = minimum cost to reach step i

### Step 3: Recurrence Relation
To reach step i, we can come from step i-1 or i-2, and we must pay cost[i]:
```
dp[i] = cost[i] + min(dp[i-1], dp[i-2])
```

### Step 4: Base Cases
- `dp[0] = cost[0]` - start at step 0
- `dp[1] = cost[1]` - start at step 1

### Step 5: Implementation

```python
# Approach 1: Memoization
from functools import cache

def minCostClimbingStairs_memo(cost):
    n = len(cost)
    
    @cache
    def dp(i):
        # Reached the top
        if i >= n:
            return 0
        # Can reach from this step
        if i == n - 1 or i == n - 2:
            return cost[i]
        
        return cost[i] + min(dp(i + 1), dp(i + 2))
    
    # Can start from step 0 or 1
    return min(dp(0), dp(1))

# Approach 2: Tabulation
def minCostClimbingStairs_tab(cost):
    n = len(cost)
    if n <= 2:
        return min(cost)
    
    dp = [0] * n
    dp[0] = cost[0]
    dp[1] = cost[1]
    
    for i in range(2, n):
        dp[i] = cost[i] + min(dp[i - 1], dp[i - 2])
    
    # Can reach top from last or second last step
    return min(dp[n - 1], dp[n - 2])

# Approach 3: Space Optimized
def minCostClimbingStairs_optimized(cost):
    n = len(cost)
    if n <= 2:
        return min(cost)
    
    prev2 = cost[0]
    prev1 = cost[1]
    
    for i in range(2, n):
        curr = cost[i] + min(prev1, prev2)
        prev2 = prev1
        prev1 = curr
    
    return min(prev1, prev2)

# Test
cost = [10, 15, 20]
print(minCostClimbingStairs_memo(cost))      # 15
print(minCostClimbingStairs_tab(cost))       # 15
print(minCostClimbingStairs_optimized(cost)) # 15

cost = [1, 100, 1, 1, 1, 100, 1, 1, 100, 1]
print(minCostClimbingStairs_optimized(cost)) # 6
```

**Complexity Analysis**:
- Time: O(n)
- Space: O(n) for memo/tab, O(1) for optimized

---

## Key Takeaways from Chapter 1

1. **DP requires both optimal substructure and overlapping subproblems**
2. **Memoization = Top-down, Tabulation = Bottom-up**
3. **State definition is the most critical step**
4. **Recurrence relation connects current state to previous states**
5. **Base cases must be carefully identified**
6. **Python's `@cache` and `@lru_cache` make memoization easy**
7. **Always analyze: States × Time per State**
8. **Many problems can be space-optimized from O(n) to O(1)**

Practice identifying these elements in every DP problem you solve!