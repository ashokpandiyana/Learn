# Chapter 10: Divide and Conquer

## 10.1 Divide and Conquer Principles

### What is Divide and Conquer?

**Divide and Conquer** is an algorithm design paradigm based on recursion with three steps:

1. **DIVIDE:** Break the problem into smaller subproblems
2. **CONQUER:** Solve subproblems recursively (base case: solve directly if small enough)
3. **COMBINE:** Merge solutions of subproblems to solve original problem

### Key Characteristics

**Different from basic recursion:**
```
Basic Recursion:
- Reduces problem by small constant (n ‚Üí n-1)
- Linear reduction
- Example: factorial, Fibonacci

Divide and Conquer:
- Splits problem into independent parts (n ‚Üí n/2, n/2)
- Logarithmic reduction
- Example: merge sort, binary search
```

**Requirements:**
- Subproblems should be **independent** (no overlap)
- Subproblems should be of **same type** as original
- Should be able to **combine** solutions efficiently

### The D&C Template

```python
def divide_and_conquer(problem):
    # BASE CASE: Problem small enough to solve directly
    if is_small_enough(problem):
        return solve_directly(problem)
    
    # DIVIDE: Split into subproblems
    subproblem1, subproblem2 = divide(problem)
    
    # CONQUER: Solve subproblems recursively
    solution1 = divide_and_conquer(subproblem1)
    solution2 = divide_and_conquer(subproblem2)
    
    # COMBINE: Merge solutions
    final_solution = combine(solution1, solution2)
    
    return final_solution
```

### Example: Maximum Element in Array

**Simple Recursion Approach:**
```python
def find_max_simple(arr, index=0):
    """
    Simple recursion: O(n) time, O(n) space
    Reduces by 1 each time
    """
    if index == len(arr) - 1:
        return arr[index]
    
    return max(arr[index], find_max_simple(arr, index + 1))
```

**Divide and Conquer Approach:**
```python
def find_max_dc(arr, left, right):
    """
    Divide and Conquer: O(n) time, O(log n) space
    Splits in half each time
    """
    # BASE CASE: Single element
    if left == right:
        return arr[left]
    
    # BASE CASE: Two elements
    if right == left + 1:
        return max(arr[left], arr[right])
    
    # DIVIDE: Split array in half
    mid = (left + right) // 2
    
    # CONQUER: Find max in each half
    max_left = find_max_dc(arr, left, mid)
    max_right = find_max_dc(arr, mid + 1, right)
    
    # COMBINE: Return maximum of both halves
    return max(max_left, max_right)

# Test
arr = [3, 7, 1, 9, 4, 6, 2]
print(find_max_dc(arr, 0, len(arr) - 1))  # 9
```

**Recursion Tree:**
```
                 [3,7,1,9,4,6,2]
                 /              \
          [3,7,1,9]            [4,6,2]
          /       \            /     \
      [3,7]      [1,9]      [4,6]   [2]
      /  \       /  \       /  \      |
    [3] [7]   [1] [9]    [4] [6]    [2]
     3   7     1   9      4   6      2
      \  /       \ /        \ /       |
       7          9          6        2
         \       /            \      /
           9                   6
             \                /
                    9
```

**Key Difference:**
- Simple recursion: Height = n (linear)
- Divide & Conquer: Height = log n (logarithmic)

---

## 10.2 Classic Divide and Conquer Algorithms

### Algorithm 1: Merge Sort

**Problem:** Sort an array in O(n log n) time.

```python
def merge_sort(arr):
    """
    Merge Sort using Divide and Conquer
    
    Time: O(n log n)
    Space: O(n)
    """
    # BASE CASE: Array with 0 or 1 element is sorted
    if len(arr) <= 1:
        return arr
    
    # DIVIDE: Split array in middle
    mid = len(arr) // 2
    left_half = arr[:mid]
    right_half = arr[mid:]
    
    # CONQUER: Recursively sort both halves
    left_sorted = merge_sort(left_half)
    right_sorted = merge_sort(right_half)
    
    # COMBINE: Merge sorted halves
    return merge(left_sorted, right_sorted)

def merge(left, right):
    """
    Merge two sorted arrays into one sorted array
    
    Time: O(n), Space: O(n)
    """
    result = []
    i = j = 0
    
    # Compare elements from both arrays
    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    
    # Add remaining elements
    result.extend(left[i:])
    result.extend(right[j:])
    
    return result

# Test
arr = [38, 27, 43, 3, 9, 82, 10]
sorted_arr = merge_sort(arr)
print(sorted_arr)  # [3, 9, 10, 27, 38, 43, 82]
```

**Recursion Tree and Merging:**
```
Original: [38, 27, 43, 3, 9, 82, 10]

DIVIDE PHASE:
                [38,27,43,3,9,82,10]
                /                  \
        [38,27,43,3]            [9,82,10]
        /          \            /        \
    [38,27]      [3,43]      [9,82]     [10]
    /    \        /   \      /    \       |
  [38]  [27]    [3]  [43]  [9]  [82]   [10]

CONQUER PHASE (Merging):
  [38]  [27]    [3]  [43]  [9]  [82]   [10]
    \    /        \   /      \    /       |
   [27,38]      [3,43]      [9,82]     [10]
        \          /            \        /
       [3,27,38,43]           [9,10,82]
              \                    /
           [3,9,10,27,38,43,82]

Each level processes n elements
Height = log n levels
Total: O(n log n)
```

**Step-by-Step Merge Example:**
```
Merge [27, 38] and [3, 43]:

Step 1: Compare 27 and 3
        3 < 27, add 3
        Result: [3]

Step 2: Compare 27 and 43
        27 < 43, add 27
        Result: [3, 27]

Step 3: Compare 38 and 43
        38 < 43, add 38
        Result: [3, 27, 38]

Step 4: Only 43 left, add it
        Result: [3, 27, 38, 43]
```

---

### Algorithm 2: Quick Sort

**Problem:** Sort using divide and conquer with partitioning.

```python
def quick_sort(arr, low, high):
    """
    Quick Sort using Divide and Conquer
    
    Average: O(n log n)
    Worst: O(n¬≤) if pivot is always min/max
    Space: O(log n) recursion stack
    """
    # BASE CASE: Array has 0 or 1 element
    if low >= high:
        return
    
    # DIVIDE: Partition array around pivot
    pivot_index = partition(arr, low, high)
    
    # CONQUER: Recursively sort left and right parts
    quick_sort(arr, low, pivot_index - 1)
    quick_sort(arr, pivot_index + 1, high)

def partition(arr, low, high):
    """
    Partition array around pivot (last element)
    Elements < pivot go left, >= pivot go right
    
    Time: O(n), Space: O(1)
    """
    pivot = arr[high]
    i = low - 1  # Index of smaller element
    
    for j in range(low, high):
        # If current element <= pivot
        if arr[j] <= pivot:
            i += 1
            arr[i], arr[j] = arr[j], arr[i]
    
    # Place pivot in correct position
    arr[i + 1], arr[high] = arr[high], arr[i + 1]
    return i + 1

# Test
arr = [10, 7, 8, 9, 1, 5]
quick_sort(arr, 0, len(arr) - 1)
print(arr)  # [1, 5, 7, 8, 9, 10]
```

**Partition Example:**
```
Array: [10, 7, 8, 9, 1, 5], Pivot = 5

Initial:  [10, 7, 8, 9, 1, 5]
          i=-1              j=0

j=0: 10 > 5, skip
     [10, 7, 8, 9, 1, 5]
     i=-1           j=1

j=1: 7 > 5, skip
j=2: 8 > 5, skip
j=3: 9 > 5, skip
j=4: 1 <= 5, i++, swap
     [1, 7, 8, 9, 10, 5]
     i=0             j=5

Place pivot: swap arr[i+1] and arr[high]
     [1, 5, 8, 9, 10, 7]
        ‚Üë pivot in position

Left: [1], Right: [8, 9, 10, 7]
Recurse on both parts
```

**Recursion Tree:**
```
                [10,7,8,9,1,5]
                pivot=5, pos=1
                /              \
            [1]              [8,9,10,7]
                             pivot=7, pos=0
                             /          \
                          []          [9,10,8]
                                     pivot=8, pos=0
                                     /         \
                                  []         [10,9]
                                            pivot=9
                                            /    \
                                          []    [10]
```

---

### Algorithm 3: Binary Search

**Problem:** Find element in sorted array in O(log n) time.

```python
def binary_search(arr, target, left, right):
    """
    Binary Search using Divide and Conquer
    
    Time: O(log n), Space: O(log n)
    """
    # BASE CASE: Element not found
    if left > right:
        return -1
    
    # DIVIDE: Find middle
    mid = (left + right) // 2
    
    # BASE CASE: Found target
    if arr[mid] == target:
        return mid
    
    # CONQUER: Search in appropriate half
    if target < arr[mid]:
        return binary_search(arr, target, left, mid - 1)
    else:
        return binary_search(arr, target, mid + 1, right)

# Test
arr = [1, 3, 5, 7, 9, 11, 13, 15]
target = 7
index = binary_search(arr, target, 0, len(arr) - 1)
print(f"Found {target} at index {index}")  # Found 7 at index 3
```

**Search Process:**
```
Array: [1, 3, 5, 7, 9, 11, 13, 15]
Target: 7

Step 1: [1, 3, 5, 7, 9, 11, 13, 15]
        mid=3 (arr[3]=7)
        Found! Return 3

Search for 11:
Step 1: [1, 3, 5, 7, 9, 11, 13, 15]
        mid=3 (arr[3]=7)
        11 > 7, search right half

Step 2:             [9, 11, 13, 15]
                    mid=5 (arr[5]=11)
                    Found! Return 5
```

---

### Algorithm 4: Kth Largest Element (Quick Select)

**Problem:** Find kth largest element in O(n) average time.

```python
def find_kth_largest(arr, k):
    """
    Find kth largest element using Quick Select
    
    Average: O(n)
    Worst: O(n¬≤)
    Space: O(log n)
    """
    # Convert to 0-indexed
    k = len(arr) - k
    
    def quick_select(left, right):
        # Choose random pivot for better average case
        pivot_index = partition(arr, left, right)
        
        if pivot_index == k:
            return arr[pivot_index]
        elif pivot_index < k:
            return quick_select(pivot_index + 1, right)
        else:
            return quick_select(left, pivot_index - 1)
    
    def partition(arr, left, right):
        pivot = arr[right]
        i = left
        
        for j in range(left, right):
            if arr[j] <= pivot:
                arr[i], arr[j] = arr[j], arr[i]
                i += 1
        
        arr[i], arr[right] = arr[right], arr[i]
        return i
    
    return quick_select(0, len(arr) - 1)

# Test
arr = [3, 2, 1, 5, 6, 4]
k = 2
result = find_kth_largest(arr, k)
print(f"{k}th largest element: {result}")  # 5
```

**Process:**
```
Array: [3, 2, 1, 5, 6, 4]
Find 2nd largest (index 4 in 0-indexed sorted)

Step 1: Partition with pivot=4
        [3, 2, 1, 4, 6, 5]
                  ‚Üë position 3
        k=4, pivot=3, search right

Step 2: Partition [6, 5] with pivot=5
        [3, 2, 1, 4, 5, 6]
                     ‚Üë position 4
        Found! Return 5
```

---

### Algorithm 5: Count Inversions

**Problem:** Count pairs (i, j) where i < j but arr[i] > arr[j].

```python
def count_inversions(arr):
    """
    Count inversions using modified merge sort
    
    Time: O(n log n), Space: O(n)
    """
    def merge_count(arr, temp, left, mid, right):
        """Merge and count inversions"""
        i = left      # Left subarray
        j = mid + 1   # Right subarray
        k = left      # Merged array
        inv_count = 0
        
        while i <= mid and j <= right:
            if arr[i] <= arr[j]:
                temp[k] = arr[i]
                i += 1
            else:
                # There are (mid - i + 1) inversions
                temp[k] = arr[j]
                inv_count += (mid - i + 1)
                j += 1
            k += 1
        
        # Copy remaining elements
        while i <= mid:
            temp[k] = arr[i]
            i += 1
            k += 1
        
        while j <= right:
            temp[k] = arr[j]
            j += 1
            k += 1
        
        # Copy back to original array
        for i in range(left, right + 1):
            arr[i] = temp[i]
        
        return inv_count
    
    def merge_sort_count(arr, temp, left, right):
        inv_count = 0
        if left < right:
            mid = (left + right) // 2
            
            inv_count += merge_sort_count(arr, temp, left, mid)
            inv_count += merge_sort_count(arr, temp, mid + 1, right)
            inv_count += merge_count(arr, temp, left, mid, right)
        
        return inv_count
    
    n = len(arr)
    temp = [0] * n
    return merge_sort_count(arr, temp, 0, n - 1)

# Test
arr = [8, 4, 2, 1]
count = count_inversions(arr)
print(f"Inversions: {count}")  # 6: (8,4), (8,2), (8,1), (4,2), (4,1), (2,1)
```

**Inversion Count Example:**
```
Array: [8, 4, 2, 1]

Inversions:
(8, 4) - 8 > 4
(8, 2) - 8 > 2
(8, 1) - 8 > 1
(4, 2) - 4 > 2
(4, 1) - 4 > 1
(2, 1) - 2 > 1

Total: 6 inversions

During merge of [8] and [4]:
  8 > 4, so there's 1 inversion
  
During merge of [8,4] and [2,1]:
  When we pick 2 before 8,4: 2 inversions
  When we pick 1 before 8,4: 2 inversions
  Total from this merge: 4

Total inversions: 6
```

---

## 10.3 Advanced Divide and Conquer Problems

### Problem 1: Closest Pair of Points

**Problem:** Find two points with minimum distance.

```python
import math

def closest_pair(points):
    """
    Find closest pair of points
    
    Time: O(n log n), Space: O(n)
    """
    def distance(p1, p2):
        return math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)
    
    def brute_force(pts):
        """For small arrays, use brute force"""
        min_dist = float('inf')
        n = len(pts)
        for i in range(n):
            for j in range(i+1, n):
                min_dist = min(min_dist, distance(pts[i], pts[j]))
        return min_dist
    
    def strip_closest(strip, d):
        """Find closest in strip of width 2d"""
        min_dist = d
        strip.sort(key=lambda p: p[1])  # Sort by y
        
        for i in range(len(strip)):
            j = i + 1
            while j < len(strip) and (strip[j][1] - strip[i][1]) < min_dist:
                min_dist = min(min_dist, distance(strip[i], strip[j]))
                j += 1
        
        return min_dist
    
    def closest_util(px, py):
        n = len(px)
        
        # BASE CASE: Use brute force for small arrays
        if n <= 3:
            return brute_force(px)
        
        # DIVIDE: Split into left and right halves
        mid = n // 2
        midpoint = px[mid]
        
        pyl = [p for p in py if p[0] <= midpoint[0]]
        pyr = [p for p in py if p[0] > midpoint[0]]
        
        # CONQUER: Find minimum in both halves
        dl = closest_util(px[:mid], pyl)
        dr = closest_util(px[mid:], pyr)
        
        # Find minimum of two
        d = min(dl, dr)
        
        # COMBINE: Check strip around dividing line
        strip = [p for p in py if abs(p[0] - midpoint[0]) < d]
        
        return min(d, strip_closest(strip, d))
    
    # Sort by x and y coordinates
    px = sorted(points, key=lambda p: p[0])
    py = sorted(points, key=lambda p: p[1])
    
    return closest_util(px, py)

# Test
points = [(2, 3), (12, 30), (40, 50), (5, 1), (12, 10), (3, 4)]
min_dist = closest_pair(points)
print(f"Minimum distance: {min_dist:.2f}")
```

---

### Problem 2: Maximum Subarray Sum (Kadane's D&C)

```python
def max_subarray_dc(arr, left, right):
    """
    Find maximum subarray sum using D&C
    
    Time: O(n log n), Space: O(log n)
    """
    # BASE CASE: Single element
    if left == right:
        return arr[left]
    
    # DIVIDE: Find middle
    mid = (left + right) // 2
    
    # CONQUER: Max in left half and right half
    max_left = max_subarray_dc(arr, left, mid)
    max_right = max_subarray_dc(arr, mid + 1, right)
    
    # COMBINE: Max crossing middle
    # Find max sum ending at mid
    left_sum = float('-inf')
    current_sum = 0
    for i in range(mid, left - 1, -1):
        current_sum += arr[i]
        left_sum = max(left_sum, current_sum)
    
    # Find max sum starting from mid+1
    right_sum = float('-inf')
    current_sum = 0
    for i in range(mid + 1, right + 1):
        current_sum += arr[i]
        right_sum = max(right_sum, current_sum)
    
    # Return maximum of three
    return max(max_left, max_right, left_sum + right_sum)

# Test
arr = [-2, 1, -3, 4, -1, 2, 1, -5, 4]
result = max_subarray_dc(arr, 0, len(arr) - 1)
print(f"Maximum subarray sum: {result}")  # 6: [4, -1, 2, 1]
```

---

### Problem 3: Median of Two Sorted Arrays

```python
def find_median_sorted_arrays(nums1, nums2):
    """
    Find median of two sorted arrays
    
    Time: O(log(min(m,n))), Space: O(1)
    """
    # Ensure nums1 is smaller
    if len(nums1) > len(nums2):
        nums1, nums2 = nums2, nums1
    
    m, n = len(nums1), len(nums2)
    low, high = 0, m
    
    while low <= high:
        # DIVIDE: Partition both arrays
        partition1 = (low + high) // 2
        partition2 = (m + n + 1) // 2 - partition1
        
        # Get max/min around partitions
        maxLeft1 = float('-inf') if partition1 == 0 else nums1[partition1-1]
        minRight1 = float('inf') if partition1 == m else nums1[partition1]
        
        maxLeft2 = float('-inf') if partition2 == 0 else nums2[partition2-1]
        minRight2 = float('inf') if partition2 == n else nums2[partition2]
        
        # CONQUER: Check if correct partition
        if maxLeft1 <= minRight2 and maxLeft2 <= minRight1:
            # COMBINE: Calculate median
            if (m + n) % 2 == 0:
                return (max(maxLeft1, maxLeft2) + min(minRight1, minRight2)) / 2
            else:
                return max(maxLeft1, maxLeft2)
        elif maxLeft1 > minRight2:
            high = partition1 - 1
        else:
            low = partition1 + 1

# Test
nums1 = [1, 3]
nums2 = [2]
print(find_median_sorted_arrays(nums1, nums2))  # 2.0
```

---

## Key Takeaways from Chapter 10

### 1. D&C vs Other Approaches

| Approach | When to Use | Time | Example |
|----------|-------------|------|---------|
| **D&C** | Independent subproblems | O(n log n) | Merge sort, Binary search |
| **DP** | Overlapping subproblems | O(n¬≤) typically | Fibonacci, LCS |
| **Greedy** | Optimal substructure + greedy choice | O(n) typically | Activity selection |
| **Backtracking** | Constraint satisfaction | Exponential | N-Queens |

### 2. Master Theorem

For recurrences of form: **T(n) = aT(n/b) + f(n)**

Where:
- a = number of subproblems
- n/b = size of each subproblem
- f(n) = work outside recursion

**Cases:**
1. If f(n) = O(n^(log_b(a) - Œµ)): **T(n) = Œò(n^log_b(a))**
2. If f(n) = Œò(n^log_b(a)): **T(n) = Œò(n^log_b(a) log n)**
3. If f(n) = Œ©(n^(log_b(a) + Œµ)): **T(n) = Œò(f(n))**

**Examples:**
```
Merge Sort: T(n) = 2T(n/2) + O(n)
a=2, b=2, f(n)=n
log_b(a) = log_2(2) = 1
f(n) = Œò(n^1) ‚Üí Case 2
T(n) = Œò(n log n)

Binary Search: T(n) = T(n/2) + O(1)
a=1, b=2, f(n)=1
log_b(a) = log_2(1) = 0
f(n) = Œò(n^0) ‚Üí Case 2
T(n) = Œò(log n)
```

### 3. Common Patterns

**Binary Split Pattern:**
```python
def binary_dc(arr, left, right):
    if left > right:
        return base_case
    
    mid = (left + right) // 2
    left_result = binary_dc(arr, left, mid)
    right_result = binary_dc(arr, mid+1, right)
    return combine(left_result, right_result)
```

**Partition Pattern:**
```python
def partition_dc(arr, low, high):
    if low >= high:
        return
    
    pivot = partition(arr, low, high)
    partition_dc(arr, low, pivot-1)
    partition_dc(arr, pivot+1, high)
```

### 4. Space Optimization

**In-place operations** save space:
```python
# Good: O(log n) space
def quick_sort(arr, low, high):
    # Sorts in-place
    
# Better for space: O(1) extra space
def merge_sort_inplace(arr, low, high):
    # More complex but saves space
```

---

## Practice Problems

### Easy
1. Power(x, n) in O(log n)
2. Count occurrences in sorted array
3. Find peak element
4. Search in rotated sorted array

### Medium
5. Kth smallest element in sorted matrix
6. Merge k sorted lists
7. Count of range sum
8. Maximum subarray product
9. Count smaller numbers after self
10. Reverse pairs

### Hard
11. Median of two sorted arrays
12. Maximum rectangle in histogram
13. Burst balloons
14. Count of smaller numbers after self
15. Closest pair of points

### Challenge
16. Strassen's matrix multiplication
17. Karatsuba algorithm
18. Convex hull (divide and conquer)
19. Skyline problem
20. Count inversions (optimize further)

---

## Common Mistakes

‚ùå **Not identifying independent subproblems**
```python
# Wrong: Subproblems overlap (use DP instead)
def fib_dc(n):
    if n <= 1: return n
    return fib_dc(n-1) + fib_dc(n-2)
```

‚ùå **Inefficient combining**
```python
# Wrong: Combining takes O(n¬≤)
def bad_merge(left, right):
    result = []
    for l in left:
        for r in right:
            # O(n¬≤) combining destroys D&C benefit!
```

‚ùå **Not handling base cases**
```python
# Wrong: Missing base case
def binary_search(arr, target, l, r):
    mid = (l + r) // 2
    # Missing: if l > r: return -1
```

‚úÖ **Correct approach:**
- Ensure subproblems are independent
- Combine efficiently (ideally O(n) or better)
- Handle all base cases
- Consider in-place operations for space

Master Divide and Conquer, and you unlock one of the most powerful algorithm design techniques! üöÄ
