# Chapter 38: Approaching System Design Problems - In-Depth Guide

## Introduction

System design interviews test your ability to design large-scale distributed systems. Success requires both technical knowledge and a structured approach to problem-solving. This chapter provides a comprehensive framework for tackling any system design problem.

---

## The 6-Step Framework

### Step 1: Understand Requirements and Scope (5-10 minutes)

This is the MOST CRITICAL step. Many candidates fail by jumping into solutions without understanding the problem.

#### Clarify Functional Requirements

Ask specific questions about what the system should do:

```
Example: Design Twitter

Questions to ask:
- Can users post tweets? What's the character limit?
- Can users follow other users?
- Should we support direct messages?
- Do we need a news feed/timeline?
- Should tweets support media (images, videos)?
- Do we need retweets and likes?
- Should we implement trending topics?
- Is there a search feature?
```

#### Clarify Non-Functional Requirements

These define system quality attributes:

**Performance:**
- What's the expected latency for tweet posting?
- How fast should the timeline load?

**Scalability:**
- How many daily active users?
- How many tweets per day?
- Peak usage patterns?

**Availability:**
- Can we tolerate downtime?
- What's the acceptable availability (99.9% vs 99.99%)?

**Consistency:**
- Is eventual consistency acceptable?
- Do users need to see tweets immediately?

```python
# Template for requirements gathering
class SystemRequirements:
    def __init__(self):
        self.functional = {
            "core_features": [],
            "optional_features": [],
            "explicitly_excluded": []
        }
        
        self.non_functional = {
            "users": {
                "daily_active": None,
                "total_users": None
            },
            "scale": {
                "reads_per_second": None,
                "writes_per_second": None,
                "storage_size": None
            },
            "performance": {
                "read_latency_p99": None,
                "write_latency_p99": None
            },
            "availability": {
                "uptime_target": None,
                "acceptable_downtime": None
            }
        }
```

---

### Step 2: Back-of-the-Envelope Calculations (5-10 minutes)

Always do capacity estimation to understand scale. This shows engineering maturity.

#### Key Metrics to Calculate

1. **Storage Requirements**
2. **Bandwidth Requirements**
3. **QPS (Queries Per Second)**
4. **Memory for Caching**

#### Example: Twitter Storage Calculation

```python
"""
Twitter Storage Calculation Example
"""

# Assumptions
DAILY_ACTIVE_USERS = 200_000_000  # 200 million DAU
TWEETS_PER_USER_PER_DAY = 2
TWEET_SIZE = 300  # bytes (280 chars + metadata)
MEDIA_PERCENTAGE = 0.20  # 20% tweets have media
AVERAGE_MEDIA_SIZE = 200_000  # 200 KB

# Calculate daily tweets
daily_tweets = DAILY_ACTIVE_USERS * TWEETS_PER_USER_PER_DAY
print(f"Daily tweets: {daily_tweets:,}")  # 400 million tweets/day

# Calculate text storage
text_storage_per_day = daily_tweets * TWEET_SIZE
print(f"Text storage per day: {text_storage_per_day / (1024**3):.2f} GB")

# Calculate media storage
tweets_with_media = daily_tweets * MEDIA_PERCENTAGE
media_storage_per_day = tweets_with_media * AVERAGE_MEDIA_SIZE
print(f"Media storage per day: {media_storage_per_day / (1024**3):.2f} GB")

# Total storage per day
total_storage_per_day = text_storage_per_day + media_storage_per_day
print(f"Total storage per day: {total_storage_per_day / (1024**3):.2f} GB")

# Storage for 5 years
storage_5_years = total_storage_per_day * 365 * 5
print(f"Storage for 5 years: {storage_5_years / (1024**4):.2f} TB")

# Output:
# Daily tweets: 400,000,000
# Text storage per day: 0.11 GB
# Media storage per day: 14.90 GB
# Total storage per day: 15.02 GB
# Storage for 5 years: 26.74 TB
```

#### QPS Calculation Example

```python
"""
Calculate Queries Per Second (QPS)
"""

# Twitter read/write calculation
DAILY_TWEETS = 400_000_000
SECONDS_PER_DAY = 86_400

# Write QPS
write_qps = DAILY_TWEETS / SECONDS_PER_DAY
print(f"Average write QPS: {write_qps:.0f}")
print(f"Peak write QPS (3x average): {write_qps * 3:.0f}")

# Read QPS (assume 100:1 read to write ratio)
read_qps = write_qps * 100
print(f"Average read QPS: {read_qps:,.0f}")
print(f"Peak read QPS (3x average): {read_qps * 3:,.0f}")

# Output:
# Average write QPS: 4630
# Peak write QPS (3x average): 13889
# Average read QPS: 463,000
# Peak read QPS (3x average): 1,389,000
```

#### Cache Memory Calculation

```python
"""
Calculate cache memory needed
"""

# Cache hot content (80/20 rule)
DAILY_ACTIVE_USERS = 200_000_000
REQUESTS_PER_USER = 50  # Timeline refreshes
CACHE_HIT_RATIO = 0.20  # Cache 20% of content

# Total requests
total_requests = DAILY_ACTIVE_USERS * REQUESTS_PER_USER

# Unique cached items (assuming 20% generates 80% of traffic)
cached_items = total_requests * CACHE_HIT_RATIO

# Average cache entry size
AVERAGE_TWEET_SIZE = 300  # bytes
TWEETS_PER_TIMELINE = 20

cache_entry_size = AVERAGE_TWEET_SIZE * TWEETS_PER_TIMELINE
total_cache_memory = cached_items * cache_entry_size

print(f"Cache memory needed: {total_cache_memory / (1024**3):.2f} GB")
```

#### Bandwidth Calculation

```python
"""
Calculate bandwidth requirements
"""

# Incoming bandwidth (writes)
TWEET_SIZE = 300  # bytes
WRITE_QPS = 4630

incoming_bandwidth = WRITE_QPS * TWEET_SIZE
print(f"Incoming bandwidth: {incoming_bandwidth / (1024**2):.2f} MB/s")

# Outgoing bandwidth (reads)
READ_QPS = 463_000
RESPONSE_SIZE = 6000  # bytes (20 tweets in timeline)

outgoing_bandwidth = READ_QPS * RESPONSE_SIZE
print(f"Outgoing bandwidth: {outgoing_bandwidth / (1024**3):.2f} GB/s")

# Output:
# Incoming bandwidth: 1.33 MB/s
# Outgoing bandwidth: 2.59 GB/s
```

---

### Step 3: Define System Interface / API Design (5 minutes)

Define the core APIs your system will expose. Keep it simple and RESTful.

#### Example: Twitter API

```javascript
/**
 * Core APIs for Twitter-like system
 */

// 1. Post a tweet
POST /api/v1/tweets
Request Body:
{
  "user_id": "user123",
  "content": "Hello world!",
  "media_urls": ["https://cdn.example.com/image.jpg"],
  "timestamp": "2024-01-15T10:30:00Z"
}
Response:
{
  "tweet_id": "tweet456",
  "user_id": "user123",
  "content": "Hello world!",
  "created_at": "2024-01-15T10:30:00Z",
  "likes_count": 0,
  "retweets_count": 0
}

// 2. Get user timeline/feed
GET /api/v1/timeline/{user_id}?limit=20&offset=0
Response:
{
  "tweets": [
    {
      "tweet_id": "tweet789",
      "user_id": "user456",
      "username": "johndoe",
      "content": "Great day!",
      "created_at": "2024-01-15T10:25:00Z",
      "likes_count": 42,
      "retweets_count": 5
    }
    // ... more tweets
  ],
  "pagination": {
    "limit": 20,
    "offset": 0,
    "has_more": true
  }
}

// 3. Follow a user
POST /api/v1/users/{user_id}/follow
Request Body:
{
  "follower_id": "user123"
}

// 4. Like a tweet
POST /api/v1/tweets/{tweet_id}/like
Request Body:
{
  "user_id": "user123"
}

// 5. Search tweets
GET /api/v1/search?query=hello&limit=20
```

#### Example: URL Shortener API

```python
"""
API Design for URL Shortener
"""

# 1. Create short URL
"""
POST /api/v1/shorten
{
    "long_url": "https://example.com/very/long/url/path",
    "custom_alias": "mylink",  # optional
    "expiration_date": "2025-12-31"  # optional
}

Response 201:
{
    "short_url": "https://short.ly/abc123",
    "long_url": "https://example.com/very/long/url/path",
    "created_at": "2024-01-15T10:30:00Z",
    "expiration_date": "2025-12-31"
}
"""

# 2. Redirect short URL
"""
GET /{short_code}

Response 302 (Redirect):
Location: https://example.com/very/long/url/path
"""

# 3. Get analytics
"""
GET /api/v1/analytics/{short_code}

Response 200:
{
    "short_code": "abc123",
    "total_clicks": 1523,
    "unique_clicks": 892,
    "clicks_by_date": [
        {"date": "2024-01-15", "clicks": 45},
        {"date": "2024-01-16", "clicks": 67}
    ],
    "referrers": [
        {"source": "twitter.com", "clicks": 234},
        {"source": "facebook.com", "clicks": 189}
    ]
}
"""
```

---

### Step 4: High-Level Design (10-15 minutes)

Draw a high-level architecture diagram showing major components.

#### Key Components to Consider

```
┌─────────────────────────────────────────────────────────────────┐
│                         CLIENT LAYER                            │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐                     │
│  │ Web App  │  │ Mobile   │  │  API     │                     │
│  │          │  │ Apps     │  │  Clients │                     │
│  └──────────┘  └──────────┘  └──────────┘                     │
└─────────────────────────────────────────────────────────────────┘
                          ▼
┌─────────────────────────────────────────────────────────────────┐
│                      LOAD BALANCER                              │
│                (Distribute traffic across servers)              │
└─────────────────────────────────────────────────────────────────┘
                          ▼
┌─────────────────────────────────────────────────────────────────┐
│                    APPLICATION SERVERS                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐      │
│  │  API     │  │  API     │  │  API     │  │  API     │      │
│  │ Server 1 │  │ Server 2 │  │ Server 3 │  │ Server N │      │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘      │
└─────────────────────────────────────────────────────────────────┘
         ▼                ▼                  ▼
┌────────────────┐  ┌───────────────┐  ┌───────────────┐
│  CACHE LAYER   │  │  DATABASE     │  │  OBJECT       │
│  (Redis/       │  │  (Primary +   │  │  STORAGE      │
│   Memcached)   │  │   Replicas)   │  │  (S3)         │
└────────────────┘  └───────────────┘  └───────────────┘
```

#### Example: Twitter High-Level Design

```
                                ┌──────────────┐
                                │    Users     │
                                └──────┬───────┘
                                       │
                                       ▼
                          ┌────────────────────────┐
                          │    CDN (Static         │
                          │    Content)            │
                          └────────────────────────┘
                                       │
                                       ▼
                          ┌────────────────────────┐
                          │   Load Balancer        │
                          └────────────────────────┘
                                       │
                    ┌──────────────────┼──────────────────┐
                    ▼                  ▼                  ▼
        ┌──────────────────┐ ┌──────────────────┐ ┌─────────────────┐
        │   API Servers    │ │  API Servers     │ │  API Servers    │
        │  (Tweet Write)   │ │  (Timeline Read) │ │   (Search)      │
        └──────────────────┘ └──────────────────┘ └─────────────────┘
                │                      │                    │
                │                      │                    │
        ┌───────▼───────┐     ┌───────▼────────┐  ┌───────▼────────┐
        │  Tweet DB     │     │  Timeline      │  │  Search        │
        │  (Cassandra)  │     │  Cache (Redis) │  │  (Elastic-     │
        │               │     │                │  │   search)      │
        └───────────────┘     └────────────────┘  └────────────────┘
                │
        ┌───────▼───────┐
        │  Media Store  │
        │  (S3/CDN)     │
        └───────────────┘
                │
        ┌───────▼───────┐
        │  Message      │
        │  Queue        │
        │  (Kafka)      │
        └───────────────┘
                │
        ┌───────▼───────┐
        │  Fan-out      │
        │  Service      │
        │  (Timeline    │
        │   Generation) │
        └───────────────┘
```

---

### Step 5: Detailed Design (15-20 minutes)

Dive deep into specific components. Focus on 2-3 critical components.

#### What to Focus On

**Choose based on the problem:**
- **Twitter**: Timeline generation, tweet storage
- **URL Shortener**: Hash generation, redirection
- **Instagram**: Image storage, feed generation
- **Uber**: Location matching, ETA calculation

#### Example: Detailed Tweet Storage Design

```python
"""
Detailed design for tweet storage in Twitter-like system

Key challenges:
1. High write throughput (4k writes/sec)
2. Need to fetch tweets by user
3. Need to fetch tweets by timeline
4. Store both text and media
"""

class TweetStorageDesign:
    """
    Design decisions:
    
    1. Database Choice: Cassandra (NoSQL)
       - Write-optimized
       - Horizontal scalability
       - Wide column store fits our access patterns
    
    2. Data Model:
    """
    
    # Table 1: Tweets by tweet_id (primary key)
    tweets_table_schema = """
    CREATE TABLE tweets (
        tweet_id UUID PRIMARY KEY,
        user_id UUID,
        content TEXT,
        media_urls LIST<TEXT>,
        created_at TIMESTAMP,
        likes_count COUNTER,
        retweets_count COUNTER,
        reply_to_tweet_id UUID
    );
    
    -- Indexed for fast lookup
    CREATE INDEX ON tweets(user_id);
    """
    
    # Table 2: Tweets by user (for profile page)
    user_tweets_schema = """
    CREATE TABLE user_tweets (
        user_id UUID,
        tweet_id UUID,
        created_at TIMESTAMP,
        content TEXT,
        PRIMARY KEY (user_id, created_at, tweet_id)
    ) WITH CLUSTERING ORDER BY (created_at DESC);
    
    -- Allows efficient: SELECT * FROM user_tweets WHERE user_id = ? 
    --                   ORDER BY created_at DESC LIMIT 20
    """
    
    # Table 3: User timeline (pre-computed)
    timeline_schema = """
    CREATE TABLE user_timeline (
        user_id UUID,
        tweet_id UUID,
        author_id UUID,
        created_at TIMESTAMP,
        PRIMARY KEY (user_id, created_at, tweet_id)
    ) WITH CLUSTERING ORDER BY (created_at DESC);
    
    -- Fast timeline reads: SELECT * FROM user_timeline 
    --                      WHERE user_id = ? LIMIT 20
    """
```

#### Example: Timeline Generation (Fan-out Strategy)

```javascript
/**
 * Two approaches to timeline generation:
 * 1. Fan-out on write (push model)
 * 2. Fan-out on read (pull model)
 * 
 * Twitter uses hybrid approach
 */

class TimelineService {
    /**
     * APPROACH 1: Fan-out on Write (Push Model)
     * 
     * When user posts tweet:
     * 1. Store tweet in tweets table
     * 2. Get all followers
     * 3. Insert tweet into each follower's timeline cache
     * 
     * Pros: Fast reads (timeline is pre-computed)
     * Cons: Slow writes for users with many followers (celebrities)
     */
    async fanOutOnWrite(tweet, authorId) {
        // Store tweet
        await this.tweetStore.save(tweet);
        
        // Get all followers
        const followers = await this.graphService.getFollowers(authorId);
        
        // For each follower, add to their timeline
        const promises = followers.map(followerId => 
            this.timelineCache.addTweet(followerId, tweet)
        );
        
        await Promise.all(promises);
        
        // Problem: If author has 10M followers, this takes too long!
    }
    
    /**
     * APPROACH 2: Fan-out on Read (Pull Model)
     * 
     * When user requests timeline:
     * 1. Get list of users they follow
     * 2. Fetch recent tweets from each
     * 3. Merge and sort
     * 
     * Pros: Fast writes
     * Cons: Slow reads (must aggregate from many sources)
     */
    async fanOutOnRead(userId, limit = 20) {
        // Get users being followed
        const following = await this.graphService.getFollowing(userId);
        
        // Fetch recent tweets from each
        const tweetPromises = following.map(authorId =>
            this.tweetStore.getUserRecentTweets(authorId, limit)
        );
        
        const tweetArrays = await Promise.all(tweetPromises);
        
        // Merge and sort by timestamp
        const allTweets = tweetArrays.flat();
        allTweets.sort((a, b) => b.timestamp - a.timestamp);
        
        return allTweets.slice(0, limit);
        
        // Problem: Slow if following many users!
    }
    
    /**
     * APPROACH 3: Hybrid (What Twitter Actually Uses)
     * 
     * - Regular users: Fan-out on write
     * - Celebrities: Fan-out on read
     * - Mix both in timeline
     */
    async hybridApproach(userId, limit = 20) {
        // Part 1: Get pre-computed timeline (from fan-out on write)
        const cachedTimeline = await this.timelineCache.get(userId, limit);
        
        // Part 2: Get tweets from celebrities user follows (fan-out on read)
        const celebritiesFollowed = await this.graphService.getCelebritiesFollowed(userId);
        
        const celebrityTweets = await Promise.all(
            celebritiesFollowed.map(celeb =>
                this.tweetStore.getUserRecentTweets(celeb, 10)
            )
        );
        
        // Part 3: Merge both sources
        const allTweets = [...cachedTimeline, ...celebrityTweets.flat()];
        allTweets.sort((a, b) => b.timestamp - a.timestamp);
        
        return allTweets.slice(0, limit);
    }
}

// Celebrity detection
class UserService {
    isCelebrity(userId) {
        const followerCount = this.getFollowerCount(userId);
        return followerCount > 1_000_000; // 1M+ followers = celebrity
    }
}
```

---

### Step 6: Identify Bottlenecks and Trade-offs (5-10 minutes)

Discuss what could go wrong and how to improve the design.

#### Common Bottlenecks

```python
"""
Identifying and addressing bottlenecks
"""

class SystemBottlenecks:
    """
    1. DATABASE BOTTLENECK
    """
    database_issues = {
        "problem": "Single database can't handle load",
        "solutions": [
            "Read replicas for read-heavy workload",
            "Sharding/Partitioning for write-heavy workload",
            "Caching layer (Redis) to reduce database hits",
            "Database connection pooling"
        ]
    }
    
    """
    2. SINGLE POINT OF FAILURE
    """
    spof_issues = {
        "problem": "If load balancer fails, entire system down",
        "solutions": [
            "Multiple load balancers with failover",
            "Health checks and automatic failover",
            "Multi-region deployment",
            "Database replication across regions"
        ]
    }
    
    """
    3. SLOW API RESPONSE
    """
    performance_issues = {
        "problem": "API response time > 2 seconds",
        "solutions": [
            "Add caching layer",
            "Database query optimization (indexes)",
            "Async processing for heavy operations",
            "CDN for static content",
            "Lazy loading",
            "Pagination for large datasets"
        ]
    }
    
    """
    4. INCONSISTENT DATA
    """
    consistency_issues = {
        "problem": "Users see stale data",
        "solutions": [
            "Use cache invalidation strategies",
            "Implement eventual consistency where acceptable",
            "Use strong consistency for critical data (payments)",
            "Version numbers or timestamps for conflict resolution"
        ]
    }
```

#### Trade-offs Discussion Template

```javascript
/**
 * Template for discussing trade-offs
 */

class SystemTradeoffs {
    /**
     * CONSISTENCY vs AVAILABILITY (CAP Theorem)
     */
    capTheorem = {
        consistency: {
            choice: "Strong consistency",
            tradeoff: "May sacrifice availability during partition",
            useCase: "Banking systems, payment processing"
        },
        availability: {
            choice: "High availability",
            tradeoff: "Accept eventual consistency",
            useCase: "Social media feeds, analytics"
        }
    };
    
    /**
     * LATENCY vs THROUGHPUT
     */
    performance = {
        optimizeLatency: {
            approach: "More servers, smaller batch sizes",
            tradeoff: "Lower throughput, higher cost",
            useCase: "Real-time gaming, trading platforms"
        },
        optimizeThroughput: {
            approach: "Batch processing, fewer but larger requests",
            tradeoff: "Higher latency",
            useCase: "Batch analytics, ETL jobs"
        }
    };
    
    /**
     * COST vs PERFORMANCE
     */
    costPerformance = {
        highPerformance: {
            approach: "Premium hardware, more caching, redundancy",
            tradeoff: "2-3x higher operational costs",
            useCase: "High-traffic consumer apps"
        },
        costEffective: {
            approach: "Optimize for efficiency, less redundancy",
            tradeoff: "Slower response times, less resilience",
            useCase: "Internal tools, MVP products"
        }
    };
    
    /**
     * NORMALIZATION vs DENORMALIZATION
     */
    dataModeling = {
        normalized: {
            approach: "Separate tables, joins required",
            pros: ["Data integrity", "Storage efficiency"],
            cons: ["Slower reads", "Complex queries"]
        },
        denormalized: {
            approach: "Duplicate data, no joins",
            pros: ["Fast reads", "Simple queries"],
            cons: ["Data inconsistency risk", "More storage"]
        }
    };
}
```

---

## Common Mistakes to Avoid

### 1. Jumping to Solution Too Quickly

```
❌ BAD:
Interviewer: "Design Twitter"
Candidate: "We'll use microservices with Kafka and Cassandra..."

✅ GOOD:
Candidate: "Let me clarify the requirements first. Should we support 
direct messages? What about video content? How many users are we expecting?"
```

### 2. Over-Engineering

```
❌ BAD: 
Proposing microservices, service mesh, event sourcing, CQRS for a 
system with 1000 users

✅ GOOD:
Start with monolith + cache + database, then discuss how to scale
```

### 3. Ignoring Numbers

```
❌ BAD:
"We'll use Redis for caching"

✅ GOOD:
"Given 100M daily users with 50 requests each, we need to cache 5B requests.
With 80/20 rule, caching 20% most popular content needs 500GB Redis cluster"
```

### 4. Not Discussing Trade-offs

```
❌ BAD:
"We'll use eventual consistency"

✅ GOOD:
"I'm proposing eventual consistency because social media feeds can tolerate
slight delays. However, for the payment system, we need strong consistency
to prevent double-charging"
```

---

## Interview Tips

### 1. Think Out Loud
```python
# Verbalize your thought process
"I'm thinking about two approaches:
1. Fan-out on write - faster reads but slower writes
2. Fan-out on read - faster writes but slower reads

For Twitter, reads are 100x more common than writes, so I'm leaning 
toward fan-out on write. However, this breaks down for celebrities 
with millions of followers, so we might need a hybrid approach..."
```

### 2. Draw Diagrams
```
Always draw as you explain:
- Boxes for components
- Arrows for data flow
- Numbers for scale (QPS, storage)
- Labels for technologies
```

### 3. Start Simple, Then Iterate
```
Version 1: Basic architecture
Version 2: Add caching
Version 3: Add load balancing
Version 4: Add database replication
Version 5: Address bottlenecks
```

### 4. Ask for Feedback
```
"Does this approach make sense?"
"Should I go deeper into any particular component?"
"Is there anything you'd like me to clarify?"
```

---

## Practice Checklist

Use this checklist for every system design problem:

```
□ Clarified functional requirements
□ Clarified non-functional requirements
□ Estimated scale (users, QPS, storage)
□ Defined core APIs
□ Drew high-level architecture
□ Identified critical components
□ Designed database schema
□ Discussed caching strategy
□ Addressed scalability
□ Discussed trade-offs
□ Identified bottlenecks
□ Proposed monitoring/alerting
```

---

## Key Takeaways

1. **Requirements First**: Always clarify before designing
2. **Numbers Matter**: Do back-of-envelope calculations
3. **Start Simple**: Basic design first, then scale
4. **Trade-offs**: No perfect solution, explain choices
5. **Communication**: Think out loud, draw diagrams
6. **Iterate**: Design → Identify issues → Improve

The goal isn't the "perfect" solution, but demonstrating structured thinking and technical depth!