# Chapter 34: Containerization & Orchestration

## Table of Contents
1. Introduction to Containers
2. Docker Fundamentals
3. Container Images and Layers
4. Docker Compose
5. Kubernetes Architecture
6. Pods, Services, and Deployments
7. Container Networking
8. Persistent Storage
9. Service Discovery
10. Auto-Scaling
11. Production Best Practices

---

## 1. Introduction to Containers

**Definition:** Containers package application code with dependencies and runtime in isolated, lightweight units.

### VMs vs Containers

```
Virtual Machines:
┌─────────────────────────────────┐
│         Application             │
├─────────────────────────────────┤
│         Guest OS (5 GB)         │
├─────────────────────────────────┤
│         Hypervisor              │
├─────────────────────────────────┤
│         Host OS                 │
├─────────────────────────────────┤
│         Hardware                │
└─────────────────────────────────┘
Boot time: Minutes
Size: GBs
Isolation: Strong (separate OS)

Containers:
┌─────────────────────────────────┐
│         Application             │
├─────────────────────────────────┤
│         Container Runtime       │
├─────────────────────────────────┤
│         Host OS (shared)        │
├─────────────────────────────────┤
│         Hardware                │
└─────────────────────────────────┘
Boot time: Seconds
Size: MBs
Isolation: Process-level
```

### Container Benefits

```
✅ Consistency: "Works on my machine" = Works everywhere
✅ Lightweight: MBs not GBs
✅ Fast: Start in seconds
✅ Portable: Run anywhere (dev, staging, prod)
✅ Efficient: Share OS kernel
✅ Scalable: Easy to replicate
```

---

## 2. Docker Fundamentals

### Dockerfile

```dockerfile
# ============================================
# Dockerfile - Build Image
# ============================================

# Base image
FROM node:18-alpine AS base

# Set working directory
WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy application code
COPY . .

# Build stage (for TypeScript)
FROM base AS build
RUN npm ci
RUN npm run build

# Production stage
FROM node:18-alpine AS production

WORKDIR /app

# Copy only necessary files from build stage
COPY --from=build /app/dist ./dist
COPY --from=build /app/node_modules ./node_modules
COPY --from=build /app/package.json ./

# Create non-root user
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

# Change ownership
RUN chown -R nodejs:nodejs /app

# Switch to non-root user
USER nodejs

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js

# Start application
CMD ["node", "dist/server.js"]

# ============================================
# Multi-stage build benefits:
# - Smaller final image (only production files)
# - Faster builds (cached layers)
# - More secure (no build tools in production)
# ============================================
```

### Docker Commands

```bash
# ============================================
# Build and Run
# ============================================

# Build image
docker build -t myapp/api:v1.0.0 .

# Build with build args
docker build \
  --build-arg NODE_ENV=production \
  --build-arg APP_VERSION=v1.0.0 \
  -t myapp/api:v1.0.0 .

# Run container
docker run -d \
  --name api \
  -p 3000:3000 \
  -e DATABASE_URL=postgresql://... \
  -e REDIS_URL=redis://... \
  --restart unless-stopped \
  myapp/api:v1.0.0

# View logs
docker logs -f api

# Execute command in container
docker exec -it api /bin/sh

# Stop container
docker stop api

# Remove container
docker rm api

# Push to registry
docker tag myapp/api:v1.0.0 myregistry.com/myapp/api:v1.0.0
docker push myregistry.com/myapp/api:v1.0.0

# ============================================
# Container Management
# ============================================

# List running containers
docker ps

# List all containers
docker ps -a

# View container resources
docker stats

# Inspect container
docker inspect api

# View container processes
docker top api

# Remove unused containers, images
docker system prune -a
```

---

## 3. Container Images and Layers

### Image Layers

```dockerfile
# Each instruction creates a layer

FROM node:18-alpine          # Layer 1 (base)
WORKDIR /app                 # Layer 2
COPY package*.json ./        # Layer 3
RUN npm ci                   # Layer 4 (cached if package.json unchanged)
COPY . .                     # Layer 5
CMD ["node", "server.js"]    # Layer 6

# Layers are cached
# Changing Layer 5 doesn't rebuild Layers 1-4
# Build is fast!
```

### Optimizing Docker Images

```dockerfile
# ============================================
# ❌ Bad: Inefficient Dockerfile
# ============================================

FROM node:18

WORKDIR /app

# Copies everything (changes often, breaks cache)
COPY . .

# Installs every time (slow)
RUN npm install

# Large image (includes dev dependencies)
CMD ["node", "server.js"]

# Problems:
# - Large image size (~1 GB)
# - Slow builds (no caching)
# - Includes dev dependencies
# - Runs as root (security risk)

# ============================================
# ✅ Good: Optimized Dockerfile
# ============================================

FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files first (changes rarely)
COPY package*.json ./

# Install dependencies (cached until package.json changes)
RUN npm ci

# Copy source code (changes often, separate layer)
COPY . .

# Build application
RUN npm run build

# Production stage
FROM node:18-alpine

WORKDIR /app

# Copy only production files
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY package*.json ./

# Non-root user
RUN addgroup -S appgroup && adduser -S appuser -G appgroup
USER appuser

# Minimal image
EXPOSE 3000
CMD ["node", "dist/server.js"]

# Benefits:
# - Small image (~100 MB vs 1 GB)
# - Fast builds (layer caching)
# - Production dependencies only
# - Non-root user (secure)
```

### .dockerignore

```
# ============================================
# .dockerignore - Exclude from build context
# ============================================

node_modules
npm-debug.log
.git
.gitignore
README.md
.env
.env.local
dist
coverage
.vscode
.idea
*.md

# Reduces build context size
# Faster builds
# Smaller images
```

---

## 4. Docker Compose

**Definition:** Tool for defining and running multi-container applications.

```yaml
# ============================================
# docker-compose.yml - Multi-Container App
# ============================================

version: '3.8'

services:
  # API Service
  api:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        NODE_ENV: production
    
    image: myapp/api:latest
    container_name: api
    
    ports:
      - "3000:3000"
    
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:secret@postgres:5432/myapp
      - REDIS_URL=redis://redis:6379
    
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    
    restart: unless-stopped
    
    networks:
      - app-network
    
    volumes:
      - ./logs:/app/logs
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
  
  # PostgreSQL Database
  postgres:
    image: postgres:14-alpine
    container_name: postgres
    
    environment:
      - POSTGRES_DB=myapp
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=secret
    
    ports:
      - "5432:5432"
    
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    
    networks:
      - app-network
    
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
  
  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: redis
    
    ports:
      - "6379:6379"
    
    command: redis-server --appendonly yes
    
    volumes:
      - redis-data:/data
    
    networks:
      - app-network
    
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
  
  # Nginx (Reverse Proxy)
  nginx:
    image: nginx:alpine
    container_name: nginx
    
    ports:
      - "80:80"
      - "443:443"
    
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    
    depends_on:
      - api
    
    networks:
      - app-network
    
    restart: unless-stopped

# Networks
networks:
  app-network:
    driver: bridge

# Volumes
volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
```

**Docker Compose Commands:**

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f api

# Stop all services
docker-compose down

# Rebuild and restart
docker-compose up -d --build

# Scale service
docker-compose up -d --scale api=3

# Execute command
docker-compose exec api npm run migrate

# View status
docker-compose ps
```

---

## 5. Kubernetes Architecture

### Control Plane Components

**1. API Server (kube-apiserver)**
```
- Front-end for Kubernetes
- Handles all API requests
- Authentication and authorization
- Validation
```

**2. etcd**
```
- Distributed key-value store
- Stores all cluster data
- Source of truth
- Highly available
```

**3. Scheduler (kube-scheduler)**
```
- Assigns Pods to Nodes
- Considers resource requirements
- Constraints and affinity rules
```

**4. Controller Manager**
```
- Node Controller (monitors nodes)
- Replication Controller (maintains replica count)
- Endpoints Controller (populates endpoints)
- Service Account Controller (creates default accounts)
```

### Node Components

**1. kubelet**
```
- Agent on each node
- Ensures containers running
- Reports to control plane
```

**2. kube-proxy**
```
- Network proxy
- Maintains network rules
- Enables Service abstraction
```

**3. Container Runtime**
```
- Runs containers
- containerd, CRI-O, Docker
```

---

## 6. Pods, Services, and Deployments

### Pods

**Definition:** Smallest deployable unit. Can contain one or more containers.

```yaml
# ============================================
# Pod Manifest
# ============================================

apiVersion: v1
kind: Pod
metadata:
  name: api-pod
  labels:
    app: api
    environment: production
spec:
  containers:
  # Main application container
  - name: api
    image: myapp/api:v1.0.0
    ports:
    - containerPort: 3000
    
    env:
    - name: NODE_ENV
      value: production
    - name: DATABASE_URL
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: url
    
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi
    
    livenessProbe:
      httpGet:
        path: /health/live
        port: 3000
      initialDelaySeconds: 30
      periodSeconds: 10
    
    readinessProbe:
      httpGet:
        path: /health/ready
        port: 3000
      initialDelaySeconds: 5
      periodSeconds: 5
  
  # Sidecar container (logging)
  - name: log-forwarder
    image: fluent/fluent-bit:latest
    volumeMounts:
    - name: varlog
      mountPath: /var/log
  
  volumes:
  - name: varlog
    emptyDir: {}
```

### Services

**Definition:** Stable network endpoint for accessing Pods.

```yaml
# ============================================
# Service Types
# ============================================

# ClusterIP (internal only)
apiVersion: v1
kind: Service
metadata:
  name: api-service
spec:
  type: ClusterIP  # Default, internal only
  selector:
    app: api
  ports:
  - port: 80
    targetPort: 3000

---
# NodePort (expose on each node)
apiVersion: v1
kind: Service
metadata:
  name: api-nodeport
spec:
  type: NodePort
  selector:
    app: api
  ports:
  - port: 80
    targetPort: 3000
    nodePort: 30001  # Accessible on <NodeIP>:30001

---
# LoadBalancer (cloud load balancer)
apiVersion: v1
kind: Service
metadata:
  name: api-loadbalancer
spec:
  type: LoadBalancer
  selector:
    app: api
  ports:
  - port: 80
    targetPort: 3000

# Cloud provider creates actual load balancer
# Returns external IP

---
# Headless Service (for StatefulSets)
apiVersion: v1
kind: Service
metadata:
  name: database
spec:
  clusterIP: None  # Headless
  selector:
    app: database
  ports:
  - port: 5432
```

### Deployments

**Definition:** Manages ReplicaSets, provides declarative updates.

```yaml
# ============================================
# Deployment - Manages Pods
# ============================================

apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-deployment
  labels:
    app: api
spec:
  # Number of replicas
  replicas: 3
  
  # How to select Pods
  selector:
    matchLabels:
      app: api
  
  # Update strategy
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  
  # Pod template
  template:
    metadata:
      labels:
        app: api
        version: v1
    spec:
      containers:
      - name: api
        image: myapp/api:v1.0.0
        ports:
        - containerPort: 3000
        
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
```

**Deployment Commands:**

```bash
# Apply deployment
kubectl apply -f deployment.yaml

# Get deployments
kubectl get deployments

# Describe deployment
kubectl describe deployment api-deployment

# Scale deployment
kubectl scale deployment api-deployment --replicas=5

# Update image (rolling update)
kubectl set image deployment/api-deployment api=myapp/api:v1.1.0

# Watch rollout
kubectl rollout status deployment/api-deployment

# Rollback to previous version
kubectl rollout undo deployment/api-deployment

# Rollback to specific revision
kubectl rollout undo deployment/api-deployment --to-revision=2

# View rollout history
kubectl rollout history deployment/api-deployment
```

---

## 7. Container Networking

### Kubernetes Network Model

```
Requirements:
1. All Pods can communicate with all Pods
2. All Nodes can communicate with all Pods
3. Pod sees its own IP (no NAT)

Pod-to-Pod Communication:
Pod A (10.244.1.5) → Pod B (10.244.2.7)
Direct IP communication
```

### Network Plugins (CNI)

```bash
# Popular CNI plugins:

# Calico (network policies, performance)
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

# Flannel (simple, easy)
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# Weave (easy setup, encryption)
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
```

### Network Policies

```yaml
# ============================================
# Network Policy - Firewall Rules
# ============================================

apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: api-network-policy
  namespace: production
spec:
  # Apply to Pods with label app=api
  podSelector:
    matchLabels:
      app: api
  
  policyTypes:
  - Ingress
  - Egress
  
  # Ingress rules
  ingress:
  # Allow from nginx pods
  - from:
    - podSelector:
        matchLabels:
          app: nginx
    ports:
    - protocol: TCP
      port: 3000
  
  # Egress rules
  egress:
  # Allow to database
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  
  # Allow to Redis
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  
  # Allow DNS
  - to:
    - namespaceSelector: {}
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53

# Result: API pods can only:
# - Receive traffic from nginx
# - Send traffic to database, redis, DNS
# All other traffic blocked
```

---

## 8. Persistent Storage

### Volumes

```yaml
# ============================================
# Volume Types
# ============================================

apiVersion: v1
kind: Pod
metadata:
  name: app-with-volumes
spec:
  containers:
  - name: app
    image: myapp/api:latest
    volumeMounts:
    - name: config
      mountPath: /etc/config
      readOnly: true
    
    - name: cache
      mountPath: /app/cache
    
    - name: logs
      mountPath: /var/log
  
  volumes:
  # ConfigMap volume
  - name: config
    configMap:
      name: app-config
  
  # EmptyDir (temporary, deleted when Pod deleted)
  - name: cache
    emptyDir: {}
  
  # HostPath (node's filesystem)
  - name: logs
    hostPath:
      path: /var/log/app
      type: DirectoryOrCreate
```

### Persistent Volumes

```yaml
# ============================================
# Persistent Volume (admin creates)
# ============================================

apiVersion: v1
kind: PersistentVolume
metadata:
  name: postgres-pv
spec:
  capacity:
    storage: 100Gi
  
  accessModes:
    - ReadWriteOnce
  
  persistentVolumeReclaimPolicy: Retain
  
  storageClassName: fast-ssd
  
  # AWS EBS volume
  awsElasticBlockStore:
    volumeID: vol-0123456789abcdef
    fsType: ext4

---
# Persistent Volume Claim (user requests)
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
spec:
  accessModes:
    - ReadWriteOnce
  
  resources:
    requests:
      storage: 100Gi
  
  storageClassName: fast-ssd

---
# Use in Pod
apiVersion: v1
kind: Pod
metadata:
  name: postgres
spec:
  containers:
  - name: postgres
    image: postgres:14
    volumeMounts:
    - name: postgres-storage
      mountPath: /var/lib/postgresql/data
  
  volumes:
  - name: postgres-storage
    persistentVolumeClaim:
      claimName: postgres-pvc

# Data persists even if Pod deleted
```

### StatefulSet (for Databases)

```yaml
# ============================================
# StatefulSet - Ordered, Stable Pods
# ============================================

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 3
  
  selector:
    matchLabels:
      app: postgres
  
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:14
        ports:
        - containerPort: 5432
        
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
  
  # Volume claim template
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi

# Creates:
# - postgres-0 (with postgres-storage-postgres-0 PVC)
# - postgres-1 (with postgres-storage-postgres-1 PVC)
# - postgres-2 (with postgres-storage-postgres-2 PVC)

# Each Pod has stable identity and persistent storage
```

---

## 9. Service Discovery

### DNS-Based Discovery

```yaml
# ============================================
# Service Discovery in Kubernetes
# ============================================

# Service
apiVersion: v1
kind: Service
metadata:
  name: api-service
  namespace: production
spec:
  selector:
    app: api
  ports:
  - port: 80
    targetPort: 3000

# Automatically creates DNS records:
# - api-service (within same namespace)
# - api-service.production (from other namespaces)
# - api-service.production.svc.cluster.local (fully qualified)
```

**Service Discovery in Application:**

```javascript
// ============================================
// Application Code (No Service Discovery Logic!)
// ============================================

const express = require('express');
const app = express();

// Call another service (just use service name!)
app.get('/api/users/:id', async (req, res) => {
  // Kubernetes DNS resolves "order-service" to IP
  const response = await fetch('http://order-service/orders?userId=' + req.params.id);
  const orders = await response.json();
  
  res.json({ orders });
});

// No service discovery code needed!
// No hardcoded IPs!
// Kubernetes handles DNS
```

---

## 10. Auto-Scaling

### Horizontal Pod Autoscaler

```yaml
# ============================================
# HPA - Auto-scale Pods
# ============================================

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-deployment
  
  minReplicas: 2
  maxReplicas: 20
  
  metrics:
  # Scale based on CPU
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  
  # Scale based on memory
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  
  # Scale based on custom metric (requests/second)
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1000"
  
  # Scaling behavior
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # Wait 5 min before scaling down
      policies:
      - type: Percent
        value: 50  # Max 50% reduction at a time
        periodSeconds: 60
    
    scaleUp:
      stabilizationWindowSeconds: 0  # Scale up immediately
      policies:
      - type: Percent
        value: 100  # Can double instantly
        periodSeconds: 30
      - type: Pods
        value: 4  # Or add 4 pods
        periodSeconds: 60
      selectPolicy: Max  # Use max of policies
```

### Cluster Autoscaler

```yaml
# ============================================
# Cluster Autoscaler - Auto-scale Nodes
# ============================================

# When Pods can't be scheduled (insufficient resources),
# Cluster Autoscaler adds new nodes

# AWS EKS example
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cluster-autoscaler
  namespace: kube-system

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      serviceAccountName: cluster-autoscaler
      containers:
      - name: cluster-autoscaler
        image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.27.0
        command:
          - ./cluster-autoscaler
          - --cloud-provider=aws
          - --namespace=kube-system
          - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/my-cluster
          - --scale-down-delay-after-add=10m
          - --scale-down-unneeded-time=10m

# Cluster Autoscaler:
# - Monitors pending Pods
# - Adds nodes when needed
# - Removes underutilized nodes
# - Works with cloud provider auto-scaling groups
```

---

## 11. Production Best Practices

### Complete Production Deployment

```yaml
# ============================================
# production-deployment.yaml - Complete Setup
# ============================================

# Namespace
apiVersion: v1
kind: Namespace
metadata:
  name: production

---
# ConfigMap (non-sensitive config)
apiVersion: v1
kind: ConfigMap
metadata:
  name: api-config
  namespace: production
data:
  APP_NAME: "MyApp API"
  LOG_LEVEL: "info"
  MAX_CONNECTIONS: "100"

---
# Secret (sensitive data)
apiVersion: v1
kind: Secret
metadata:
  name: api-secret
  namespace: production
type: Opaque
data:
  # Base64 encoded
  database-url: cG9zdGdyZXNxbDovL2RiLmV4YW1wbGUuY29tOjU0MzIvbXlhcHA=
  api-key: c2tfbGl2ZV8xMjM0NTY3ODkwYWJjZGVm

---
# Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api
  namespace: production
spec:
  replicas: 4
  
  selector:
    matchLabels:
      app: api
  
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  
  template:
    metadata:
      labels:
        app: api
        version: v1
    spec:
      # Anti-affinity (spread across nodes)
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - api
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: api
        image: myapp/api:v1.2.0
        
        imagePullPolicy: IfNotPresent
        
        ports:
        - name: http
          containerPort: 3000
          protocol: TCP
        
        # Environment from ConfigMap
        envFrom:
        - configMapRef:
            name: api-config
        
        # Environment from Secret
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: api-secret
              key: database-url
        
        # Resources (important for HPA)
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        
        # Probes
        livenessProbe:
          httpGet:
            path: /health/live
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /health/ready
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        
        # Security context
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
      
      # Image pull secret (for private registry)
      imagePullSecrets:
      - name: registry-secret

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: api-service
  namespace: production
spec:
  type: LoadBalancer
  selector:
    app: api
  ports:
  - port: 80
    targetPort: http
    protocol: TCP

---
# HPA
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api
  
  minReplicas: 4
  maxReplicas: 20
  
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---
# Pod Disruption Budget (ensure availability during updates)
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: api-pdb
  namespace: production
spec:
  minAvailable: 2  # Always keep at least 2 pods running
  selector:
    matchLabels:
      app: api
```

---

## Chapter 34 Summary

### Key Concepts

1. **Containers** - Lightweight, portable application packaging
2. **Docker** - Build, ship, run containers
3. **Dockerfile** - Define container image
4. **Docker Compose** - Multi-container applications
5. **Kubernetes** - Container orchestration at scale
6. **Pods** - Smallest deployable unit
7. **Services** - Stable network endpoints
8. **Deployments** - Manage Pod replicas
9. **Networking** - CNI plugins, network policies
10. **Storage** - Persistent volumes for stateful apps
11. **Auto-Scaling** - HPA for pods, CA for nodes

### Docker vs Kubernetes

| Aspect | Docker | Kubernetes |
|--------|--------|------------|
| **Scope** | Single host | Multi-host cluster |
| **Orchestration** | Docker Compose | Advanced orchestration |
| **Scaling** | Manual | Automatic (HPA) |
| **Self-healing** | Manual restart | Automatic |
| **Load Balancing** | Manual | Built-in (Services) |
| **Use Case** | Development, small deployments | Production at scale |

### Kubernetes Components

| Component | Purpose | Where |
|-----------|---------|-------|
| **API Server** | Frontend for cluster | Control plane |
| **etcd** | Cluster state storage | Control plane |
| **Scheduler** | Pod placement | Control plane |
| **Controller Manager** | Maintain desired state | Control plane |
| **kubelet** | Manage Pods on node | Worker nodes |
| **kube-proxy** | Network routing | Worker nodes |

### Production Checklist

- [ ] Resource limits set (prevent resource exhaustion)
- [ ] Liveness/readiness probes configured
- [ ] Multiple replicas (high availability)
- [ ] Pod Disruption Budget (maintain availability)
- [ ] Network policies (security)
- [ ] Secrets for sensitive data
- [ ] Anti-affinity rules (spread across nodes)
- [ ] HPA configured (auto-scaling)
- [ ] Monitoring and logging
- [ ] Non-root user (security)

### Interview Tips

**Common Questions:**
1. "Explain containers vs VMs"
2. "What is Kubernetes?"
3. "Pod vs Deployment vs Service?"
4. "How does Kubernetes networking work?"

**How to Answer:**
- Draw architecture diagrams
- Explain container benefits (lightweight, portable)
- Describe Kubernetes components (control plane, nodes)
- Show YAML examples
- Discuss production considerations

### Next Steps

Chapter 35 will cover **Observability** - logging, metrics, tracing, and monitoring distributed systems to understand what's happening in production.