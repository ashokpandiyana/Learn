# Chapter 12: Database Architecture

## Table of Contents
1. Introduction to Database Architecture
2. Relational Databases (SQL)
3. Normalization
4. Indexing Strategies
5. ACID Properties
6. Replication
7. Sharding
8. NoSQL Databases
9. CAP Theorem
10. Choosing the Right Database
11. Real-World Patterns

---

## 1. Introduction to Database Architecture

**Definition:** Database architecture refers to how data is organized, stored, and accessed within a database system, including considerations for performance, scalability, and reliability.

### Database Scaling Challenges

**Problem:**
```
Growing Data:
Year 1: 1 GB, 1000 users
Year 2: 100 GB, 100,000 users
Year 3: 10 TB, 10,000,000 users

Single database can't handle this!
```

**Solutions:**
1. **Vertical Scaling** - Bigger machine (limited, expensive)
2. **Replication** - Multiple copies (read scaling)
3. **Sharding** - Split data across machines (write scaling)
4. **Different Database Types** - Use right tool for the job

---

## 2. Relational Databases (SQL)

**Definition:** Store data in tables with rows and columns, relationships defined by foreign keys.

### Schema Example

```sql
-- Users table
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(100) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Posts table
CREATE TABLE posts (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    content TEXT,
    published_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Comments table
CREATE TABLE comments (
    id SERIAL PRIMARY KEY,
    post_id INTEGER REFERENCES posts(id) ON DELETE CASCADE,
    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Relationships:
-- user -> posts (one-to-many)
-- post -> comments (one-to-many)
-- user -> comments (one-to-many)
```

### Querying with JOINs

```sql
-- Get all posts with author names
SELECT 
    posts.id,
    posts.title,
    users.name AS author,
    posts.created_at
FROM posts
INNER JOIN users ON posts.user_id = users.id
WHERE posts.published_at IS NOT NULL
ORDER BY posts.created_at DESC
LIMIT 10;

-- Get post with comments and comment authors
SELECT 
    posts.title,
    posts.content,
    users.name AS author,
    comments.content AS comment,
    cu.name AS commenter
FROM posts
INNER JOIN users ON posts.user_id = users.id
LEFT JOIN comments ON comments.post_id = posts.id
LEFT JOIN users cu ON comments.user_id = cu.id
WHERE posts.id = 123;

-- Get users with post count
SELECT 
    users.id,
    users.name,
    COUNT(posts.id) AS post_count
FROM users
LEFT JOIN posts ON posts.user_id = users.id
GROUP BY users.id, users.name
HAVING COUNT(posts.id) > 5
ORDER BY post_count DESC;
```

### Transactions

```sql
-- Transfer money between accounts
BEGIN;

-- Deduct from sender
UPDATE accounts 
SET balance = balance - 100 
WHERE user_id = 123;

-- Add to receiver
UPDATE accounts 
SET balance = balance + 100 
WHERE user_id = 456;

-- Only if both succeed
COMMIT;

-- If either fails
ROLLBACK;
```

---

## 3. Normalization

**Definition:** Process of organizing data to reduce redundancy and improve data integrity.

### Normal Forms

**1NF (First Normal Form):**
- Atomic values (no arrays/lists in single field)
- Each column contains only one value

```sql
-- ❌ Not 1NF - phones is a list
CREATE TABLE users_bad (
    id INT,
    name VARCHAR(100),
    phones VARCHAR(500)  -- "555-1234, 555-5678, 555-9012"
);

-- ✅ 1NF - separate table for phones
CREATE TABLE users (
    id INT PRIMARY KEY,
    name VARCHAR(100)
);

CREATE TABLE user_phones (
    id INT PRIMARY KEY,
    user_id INT REFERENCES users(id),
    phone VARCHAR(20)
);
```

**2NF (Second Normal Form):**
- Must be in 1NF
- All non-key attributes fully dependent on primary key

```sql
-- ❌ Not 2NF - author_email depends only on author_id, not on (post_id, author_id)
CREATE TABLE post_authors_bad (
    post_id INT,
    author_id INT,
    author_email VARCHAR(255),  -- Redundant
    PRIMARY KEY (post_id, author_id)
);

-- ✅ 2NF - separate tables
CREATE TABLE posts (
    id INT PRIMARY KEY,
    title VARCHAR(255)
);

CREATE TABLE authors (
    id INT PRIMARY KEY,
    email VARCHAR(255)
);

CREATE TABLE post_authors (
    post_id INT REFERENCES posts(id),
    author_id INT REFERENCES authors(id),
    PRIMARY KEY (post_id, author_id)
);
```

**3NF (Third Normal Form):**
- Must be in 2NF
- No transitive dependencies (non-key attributes depend only on primary key)

```sql
-- ❌ Not 3NF - city depends on zip_code, not directly on user_id
CREATE TABLE users_bad (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    zip_code VARCHAR(10),
    city VARCHAR(100)  -- Determined by zip_code
);

-- ✅ 3NF - separate zip_codes table
CREATE TABLE users (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    zip_code VARCHAR(10) REFERENCES zip_codes(code)
);

CREATE TABLE zip_codes (
    code VARCHAR(10) PRIMARY KEY,
    city VARCHAR(100),
    state VARCHAR(2)
);
```

### Denormalization (When to Break Rules)

Sometimes breaking normalization rules improves performance:

```sql
-- Normalized (requires JOIN)
SELECT 
    posts.title,
    users.name AS author
FROM posts
JOIN users ON posts.user_id = users.id;

-- Denormalized (no JOIN needed, but author_name is redundant)
CREATE TABLE posts (
    id INT PRIMARY KEY,
    title VARCHAR(255),
    user_id INT,
    author_name VARCHAR(100)  -- Denormalized - stored redundantly
);

SELECT title, author_name FROM posts;  -- Fast, no JOIN
```

**When to denormalize:**
- Read-heavy workloads
- Need maximum query performance
- Willing to trade storage and update complexity for speed

---

## 4. Indexing Strategies

**Definition:** Indexes are data structures that improve query performance by allowing fast lookups.

### Types of Indexes

**1. B-Tree Index (Default)**

```sql
-- Create index on email column
CREATE INDEX idx_users_email ON users(email);

-- Query uses index
SELECT * FROM users WHERE email = 'john@example.com';
-- Without index: Full table scan O(n)
-- With index: B-tree lookup O(log n)

-- Composite index
CREATE INDEX idx_posts_user_created ON posts(user_id, created_at DESC);

-- Uses composite index efficiently
SELECT * FROM posts 
WHERE user_id = 123 
ORDER BY created_at DESC;
```

**B-Tree Structure:**
```
                [50]
               /    \
        [25,40]      [75,90]
       /  |   \      /  |   \
   [10] [30] [45] [60] [80] [95]
```

**2. Hash Index**

```sql
-- Good for exact match lookups
CREATE INDEX idx_users_id_hash ON users USING HASH (id);

-- Fast
SELECT * FROM users WHERE id = 123;

-- Cannot use hash index (needs range)
SELECT * FROM users WHERE id > 100;  -- Won't use hash index
```

**3. Full-Text Index**

```sql
-- PostgreSQL full-text search
ALTER TABLE posts ADD COLUMN tsv tsvector;

CREATE INDEX idx_posts_tsv ON posts USING GIN(tsv);

-- Update trigger to maintain tsvector
CREATE TRIGGER posts_tsv_update BEFORE INSERT OR UPDATE ON posts
FOR EACH ROW EXECUTE FUNCTION
  tsvector_update_trigger(tsv, 'pg_catalog.english', title, content);

-- Search query
SELECT title, ts_rank(tsv, query) AS rank
FROM posts, to_tsquery('english', 'database & architecture') query
WHERE tsv @@ query
ORDER BY rank DESC;
```

**4. Partial Index**

```sql
-- Index only published posts
CREATE INDEX idx_posts_published 
ON posts(published_at) 
WHERE published_at IS NOT NULL;

-- Smaller index, faster queries for published posts
SELECT * FROM posts WHERE published_at IS NOT NULL;
```

### Index Best Practices

```python
# ✅ Good - Uses index
cursor.execute("SELECT * FROM users WHERE email = %s", (email,))

# ❌ Bad - Can't use index (function on column)
cursor.execute("SELECT * FROM users WHERE LOWER(email) = %s", (email.lower(),))

# ✅ Better - Functional index
# CREATE INDEX idx_users_email_lower ON users(LOWER(email));
cursor.execute("SELECT * FROM users WHERE LOWER(email) = %s", (email.lower(),))

# ❌ Bad - OR conditions may not use index efficiently
cursor.execute("SELECT * FROM posts WHERE title = %s OR content = %s", (term, term))

# ✅ Better - UNION uses indexes
cursor.execute("""
    SELECT * FROM posts WHERE title = %s
    UNION
    SELECT * FROM posts WHERE content = %s
""", (term, term))
```

### Checking Index Usage

```sql
-- PostgreSQL - Explain query plan
EXPLAIN ANALYZE
SELECT * FROM users WHERE email = 'john@example.com';

-- Output shows if index is used:
-- Index Scan using idx_users_email on users (cost=0.42..8.44)
-- vs
-- Seq Scan on users (cost=0.00..1500.00)  -- No index used!

-- Find unused indexes
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan = 0
AND indexname NOT LIKE 'pg_toast%';
```

---

## 5. ACID Properties

**Definition:** ACID guarantees that database transactions are processed reliably.

### A - Atomicity

**All or nothing** - Either entire transaction succeeds or entire transaction fails.

```python
import psycopg2

def transfer_money(from_account, to_account, amount):
    conn = psycopg2.connect("dbname=bank")
    cursor = conn.cursor()
    
    try:
        # Start transaction
        cursor.execute("BEGIN;")
        
        # Deduct from sender
        cursor.execute(
            "UPDATE accounts SET balance = balance - %s WHERE id = %s",
            (amount, from_account)
        )
        
        # Simulate error
        if amount > 1000:
            raise Exception("Amount too large!")
        
        # Add to receiver
        cursor.execute(
            "UPDATE accounts SET balance = balance + %s WHERE id = %s",
            (amount, to_account)
        )
        
        # Commit transaction
        conn.commit()
        print("Transfer successful!")
        
    except Exception as e:
        # Rollback on any error
        conn.rollback()
        print(f"Transfer failed: {e}")
        # Both updates are cancelled - atomicity guaranteed
    
    finally:
        cursor.close()
        conn.close()
```

### C - Consistency

**Valid state to valid state** - Database constraints maintained.

```sql
-- Constraints ensure consistency
CREATE TABLE accounts (
    id INT PRIMARY KEY,
    balance DECIMAL(10,2) CHECK (balance >= 0),  -- Can't go negative
    user_id INT REFERENCES users(id)             -- Must reference valid user
);

-- This will fail (violates CHECK constraint)
UPDATE accounts SET balance = -100 WHERE id = 1;
-- ERROR: new row violates check constraint "accounts_balance_check"

-- This will fail (violates FOREIGN KEY constraint)
INSERT INTO accounts (id, balance, user_id) VALUES (1, 100, 9999);
-- ERROR: insert or update violates foreign key constraint
```

### I - Isolation

**Transactions don't interfere** - Concurrent transactions isolated from each other.

**Isolation Levels:**

```sql
-- 1. READ UNCOMMITTED (lowest isolation)
SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;
-- Can read uncommitted changes from other transactions
-- Problem: Dirty reads

-- 2. READ COMMITTED (PostgreSQL default)
SET TRANSACTION ISOLATION LEVEL READ COMMITTED;
-- Only sees committed changes
-- Problem: Non-repeatable reads

-- 3. REPEATABLE READ
SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;
-- Same query returns same results within transaction
-- Problem: Phantom reads

-- 4. SERIALIZABLE (highest isolation)
SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
-- Complete isolation, like transactions run sequentially
-- Problem: Slower, more lock contention
```

**Example - Race Condition:**

```python
# Without proper isolation - race condition!
def book_seat(seat_id):
    # Transaction 1 and 2 both check simultaneously
    cursor.execute("SELECT status FROM seats WHERE id = %s", (seat_id,))
    status = cursor.fetchone()[0]
    
    if status == 'available':
        # Both transactions see 'available'!
        cursor.execute("UPDATE seats SET status = 'booked' WHERE id = %s", (seat_id,))
        conn.commit()
        return "Booked!"
    return "Not available"

# With proper isolation - use SERIALIZABLE or SELECT FOR UPDATE
def book_seat_safe(seat_id):
    cursor.execute("BEGIN;")
    
    # Lock the row
    cursor.execute(
        "SELECT status FROM seats WHERE id = %s FOR UPDATE",
        (seat_id,)
    )
    status = cursor.fetchone()[0]
    
    if status == 'available':
        cursor.execute("UPDATE seats SET status = 'booked' WHERE id = %s", (seat_id,))
        conn.commit()
        return "Booked!"
    else:
        conn.rollback()
        return "Not available"
```

### D - Durability

**Persisted** - Once committed, data is permanent (survives crashes).

```sql
-- After COMMIT, data is written to disk
BEGIN;
INSERT INTO users (name, email) VALUES ('John', 'john@example.com');
COMMIT;  -- Now guaranteed to survive power failure

-- Database uses Write-Ahead Logging (WAL)
-- Changes logged to disk before data files updated
```

---

## 6. Replication

**Definition:** Maintaining copies of data on multiple database servers.

### Master-Slave Replication

```
           ┌─────────────┐
           │   Master    │ ← All writes
           │  (Primary)  │
           └──────┬──────┘
                  │ Replicate
         ┌────────┼────────┐
         ↓        ↓        ↓
    ┌────────┐ ┌────────┐ ┌────────┐
    │ Slave1 │ │ Slave2 │ │ Slave3 │ ← Read-only
    └────────┘ └────────┘ └────────┘
```

### Configuration

**PostgreSQL Master:**
```conf
# postgresql.conf
wal_level = replica
max_wal_senders = 10
wal_keep_segments = 64
```

**PostgreSQL Slave:**
```conf
# recovery.conf (for standby)
standby_mode = on
primary_conninfo = 'host=master-ip port=5432 user=replicator password=secret'
```

### Application Code

```typescript
import { Pool } from 'pg';

class DatabasePool {
    private masterPool: Pool;
    private slaveP ools: Pool[];
    private currentSlaveIndex: number = 0;
    
    constructor() {
        // Master for writes
        this.masterPool = new Pool({
            host: 'master-db.example.com',
            port: 5432,
            database: 'myapp',
            user: 'app',
            password: 'secret',
            max: 20
        });
        
        // Slaves for reads
        this.slavePools = [
            new Pool({
                host: 'slave1-db.example.com',
                port: 5432,
                database: 'myapp',
                user: 'app',
                password: 'secret',
                max: 50
            }),
            new Pool({
                host: 'slave2-db.example.com',
                port: 5432,
                database: 'myapp',
                user: 'app',
                password: 'secret',
                max: 50
            })
        ];
    }
    
    // All writes go to master
    async write(query: string, params: any[]): Promise<any> {
        return await this.masterPool.query(query, params);
    }
    
    // Reads go to slaves (round-robin)
    async read(query: string, params: any[]): Promise<any> {
        const pool = this.slavePools[this.currentSlaveIndex];
        this.currentSlaveIndex = (this.currentSlaveIndex + 1) % this.slavePools.length;
        return await pool.query(query, params);
    }
}

// Usage
const db = new DatabasePool();

// Write to master
await db.write(
    'INSERT INTO users (name, email) VALUES ($1, $2)',
    ['John', 'john@example.com']
);

// Read from slave
const users = await db.read(
    'SELECT * FROM users WHERE email = $1',
    ['john@example.com']
);
```

### Replication Lag

**Problem:** Slave might be behind master.

```typescript
async function handleWrite() {
    // Write to master
    await db.write('UPDATE users SET name = $1 WHERE id = $2', ['Jane', 123]);
    
    // Immediately read - might read old data from slave!
    const user = await db.read('SELECT * FROM users WHERE id = $1', [123]);
    // user.name might still be 'John' due to replication lag
}

// Solution 1: Read from master after write
async function handleWriteSafe1() {
    await db.write('UPDATE users SET name = $1 WHERE id = $2', ['Jane', 123]);
    
    // Read from master to get latest data
    const user = await db.write('SELECT * FROM users WHERE id = $1', [123]);
}

// Solution 2: Use session-level read-after-write consistency
class SmartDatabasePool extends DatabasePool {
    private recentWrites: Set<string> = new Set();
    
    async write(query: string, params: any[]): Promise<any> {
        const result = await super.write(query, params);
        
        // Track recent writes (e.g., user IDs)
        if (params.length > 0) {
            this.recentWrites.add(JSON.stringify(params));
            
            // Clear after 5 seconds
            setTimeout(() => {
                this.recentWrites.delete(JSON.stringify(params));
            }, 5000);
        }
        
        return result;
    }
    
    async read(query: string, params: any[]): Promise<any> {
        // If we recently wrote this data, read from master
        if (this.recentWrites.has(JSON.stringify(params))) {
            return await this.masterPool.query(query, params);
        }
        
        // Otherwise, read from slave
        return await super.read(query, params);
    }
}
```

---

## 7. Sharding

**Definition:** Splitting data across multiple database servers (horizontal partitioning).

### Sharding Strategies

**1. Hash-Based Sharding**

```python
def get_shard(user_id, num_shards=4):
    """Determine which shard based on user_id hash"""
    shard_index = hash(user_id) % num_shards
    return shard_index

# User 123 → Shard 3
# User 456 → Shard 0
# User 789 → Shard 1
```

**2. Range-Based Sharding**

```python
def get_shard_by_range(user_id):
    """Shard based on ID range"""
    if user_id < 1000000:
        return 0  # Shard 0: IDs 0-999,999
    elif user_id < 2000000:
        return 1  # Shard 1: IDs 1,000,000-1,999,999
    elif user_id < 3000000:
        return 2  # Shard 2: IDs 2,000,000-2,999,999
    else:
        return 3  # Shard 3: IDs 3,000,000+
```

**3. Geographic Sharding**

```python
def get_shard_by_location(country):
    """Shard based on geographic location"""
    if country in ['US', 'CA', 'MX']:
        return 'americas-shard'
    elif country in ['GB', 'FR', 'DE']:
        return 'europe-shard'
    elif country in ['CN', 'JP', 'IN']:
        return 'asia-shard'
    else:
        return 'global-shard'
```

### Implementation

```typescript
class ShardedDatabase {
    private shards: Map<number, Pool>;
    
    constructor() {
        this.shards = new Map([
            [0, new Pool({ host: 'shard0.db.example.com' })],
            [1, new Pool({ host: 'shard1.db.example.com' })],
            [2, new Pool({ host: 'shard2.db.example.com' })],
            [3, new Pool({ host: 'shard3.db.example.com' })]
        ]);
    }
    
    private getShard(userId: number): Pool {
        const shardIndex = userId % this.shards.size;
        return this.shards.get(shardIndex)!;
    }
    
    async getUser(userId: number): Promise<any> {
        const shard = this.getShard(userId);
        const result = await shard.query(
            'SELECT * FROM users WHERE id = $1',
            [userId]
        );
        return result.rows[0];
    }
    
    async createUser(userId: number, name: string, email: string): Promise<void> {
        const shard = this.getShard(userId);
        await shard.query(
            'INSERT INTO users (id, name, email) VALUES ($1, $2, $3)',
            [userId, name, email]
        );
    }
    
    // Complex query - query all shards
    async getAllActiveUsers(): Promise<any[]> {
        const promises = Array.from(this.shards.values()).map(shard =>
            shard.query('SELECT * FROM users WHERE active = true')
        );
        
        const results = await Promise.all(promises);
        
        // Merge results from all shards
        return results.flatMap(r => r.rows);
    }
}
```

### Challenges with Sharding

**1. No Cross-Shard JOINs**

```sql
-- ❌ Can't do this across shards
SELECT 
    users.name,
    posts.title
FROM users
JOIN posts ON posts.user_id = users.id;

-- If users and posts on different shards = problem!

-- ✅ Solution: Denormalize or application-level joins
-- Store user_name in posts table
SELECT 
    user_name,
    title
FROM posts;
```

**2. Distributed Transactions**

```python
# ❌ Can't do atomic transaction across shards
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE user_id = 123;  # Shard 1
UPDATE accounts SET balance = balance + 100 WHERE user_id = 456;  # Shard 2
COMMIT;  # Can't coordinate across shards!

# ✅ Solution: Use 2-Phase Commit or Saga pattern (see Chapter 5)
```

**3. Auto-Increment IDs**

```python
# ❌ Auto-increment doesn't work across shards
# Each shard would generate IDs independently: 1, 2, 3...

# ✅ Solution 1: UUID
import uuid
user_id = str(uuid.uuid4())

# ✅ Solution 2: Twitter Snowflake ID
# 64-bit ID: timestamp + machine_id + sequence
# Guarantees uniqueness across shards
```

---

## 8. NoSQL Databases

**Definition:** Non-relational databases optimized for specific use cases.

### 8.1 Document Databases (MongoDB)

**Use Case:** Flexible schema, hierarchical data

```javascript
// MongoDB - Store complex nested documents
db.users.insertOne({
    _id: ObjectId("507f1f77bcf86cd799439011"),
    name: "John Doe",
    email: "john@example.com",
    address: {
        street: "123 Main St",
        city: "New York",
        zip: "10001"
    },
    orders: [
        {
            orderId: "ORD001",
            total: 99.99,
            items: [
                { productId: "PROD1", quantity: 2 },
                { productId: "PROD2", quantity: 1 }
            ]
        }
    ],
    preferences: {
        newsletter: true,
        notifications: {
            email: true,
            sms: false
        }
    }
});

// Query nested fields
db.users.find({
    "address.city": "New York",
    "preferences.newsletter": true
});

// Update nested field
db.users.updateOne(
    { _id: ObjectId("507f1f77bcf86cd799439011") },
    { $set: { "preferences.notifications.sms": true } }
);
```

### 8.2 Key-Value Stores (Redis, DynamoDB)

**Use Case:** Simple lookups, caching, sessions

```python
import redis

# Redis - Key-value operations
r = redis.Redis(host='localhost', port=6379)

# Simple string
r.set('user:123:name', 'John Doe')
name = r.get('user:123:name')

# Hash (object)
r.hset('user:123', mapping={
    'name': 'John Doe',
    'email': 'john@example.com',
    'age': 30
})
user = r.hgetall('user:123')

# List (queue)
r.lpush('tasks', 'task1', 'task2', 'task3')
task = r.rpop('tasks')

# Set (unique items)
r.sadd('user:123:tags', 'developer', 'nodejs', 'python')
tags = r.smembers('user:123:tags')

# Sorted Set (leaderboard)
r.zadd('leaderboard', {'player1': 100, 'player2': 250, 'player3': 180})
top_players = r.zrevrange('leaderboard', 0, 9, withscores=True)
```

### 8.3 Column Family (Cassandra, HBase)

**Use Case:** Time-series data, high write throughput

```python
# Cassandra - Column family
from cassandra.cluster import Cluster

cluster = Cluster(['localhost'])
session = cluster.connect('myapp')

# Create table
session.execute("""
    CREATE TABLE user_activity (
        user_id uuid,
        timestamp timestamp,
        activity_type text,
        details text,
        PRIMARY KEY (user_id, timestamp)
    ) WITH CLUSTERING ORDER BY (timestamp DESC)
""")

# Insert
session.execute("""
    INSERT INTO user_activity (user_id, timestamp, activity_type, details)
    VALUES (uuid(), now(), 'page_view', '/products')
""")

# Query - efficient for same user_id
rows = session.execute("""
    SELECT * FROM user_activity
    WHERE user_id = ?
    AND timestamp > ?
""", (user_id, yesterday))
```

### 8.4 Graph Databases (Neo4j)

**Use Case:** Relationships, social networks, recommendations

```cypher
// Neo4j - Graph queries

// Create nodes
CREATE (john:User {name: 'John', email: 'john@example.com'})
CREATE (jane:User {name: 'Jane', email: 'jane@example.com'})
CREATE (python:Skill {name: 'Python'})
CREATE (javascript:Skill {name: 'JavaScript'})

// Create relationships
MATCH (john:User {name: 'John'}), (jane:User {name: 'Jane'})
CREATE (john)-[:FOLLOWS]->(jane)

MATCH (john:User {name: 'John'}), (python:Skill {name: 'Python'})
CREATE (john)-[:KNOWS {level: 'expert'}]->(python)

// Query: Find friends of friends
MATCH (me:User {name: 'John'})-[:FOLLOWS]->()-[:FOLLOWS]->(fof)
WHERE NOT (me)-[:FOLLOWS]->(fof) AND me <> fof
RETURN fof.name

// Query: Recommend skills based on friends
MATCH (me:User {name: 'John'})-[:FOLLOWS]->(friend)-[:KNOWS]->(skill)
WHERE NOT (me)-[:KNOWS]->(skill)
RETURN skill.name, COUNT(*) as friend_count
ORDER BY friend_count DESC
```

---

## 9. CAP Theorem

**Definition:** In a distributed system, you can only have 2 out of 3:

**C - Consistency:** All nodes see the same data at the same time
**A - Availability:** Every request receives a response
**P - Partition Tolerance:** System continues despite network failures

```
       Consistency
            /\
           /  \
          /    \
         /  CP  \
        / (e.g.  \
       /  MongoDB) \
      /_____________\
     /      |        \
    /   CA  |  AP     \
   / (Single| (Cassandra)\
  /   node) | DynamoDB)  \
 /__________P____________\
Partition     Availability
Tolerance
```

### Examples

**CP (Consistency + Partition Tolerance):**
- **MongoDB** (default), **HBase**, **Redis** (single instance)
- Sacrifices availability during network partitions
- Ensures data consistency

**AP (Availability + Partition Tolerance):**
- **Cassandra**, **DynamoDB**, **CouchDB**
- Always available, but might return stale data
- Eventually consistent

**CA (Consistency + Availability):**
- **Traditional RDBMS** (single instance)
- Not partition tolerant
- Real CP or AP in distributed setups

### Consistency Levels Example (Cassandra)

```python
from cassandra.cluster import Cluster
from cassandra.query import SimpleStatement, ConsistencyLevel

cluster = Cluster(['localhost'])
session = cluster.connect('myapp')

# Write with strong consistency (slower)
query = SimpleStatement(
    "INSERT INTO users (id, name) VALUES (?, ?)",
    consistency_level=ConsistencyLevel.QUORUM  # Majority must confirm
)
session.execute(query, (user_id, name))

# Read with eventual consistency (faster)
query = SimpleStatement(
    "SELECT * FROM users WHERE id = ?",
    consistency_level=ConsistencyLevel.ONE  # Read from any node
)
result = session.execute(query, (user_id,))

# Read with strong consistency (slower)
query = SimpleStatement(
    "SELECT * FROM users WHERE id = ?",
    consistency_level=ConsistencyLevel.QUORUM  # Read from majority
)
result = session.execute(query, (user_id,))
```

---

## 10. Choosing the Right Database

### Decision Matrix

| Requirement | Database Choice |
|-------------|----------------|
| **Complex queries, JOINs** | PostgreSQL, MySQL |
| **Flexible schema** | MongoDB, DynamoDB |
| **High write throughput** | Cassandra, HBase |
| **Time-series data** | InfluxDB, TimescaleDB |
| **Caching, sessions** | Redis, Memcached |
| **Graph relationships** | Neo4j, ArangoDB |
| **Full-text search** | Elasticsearch, Solr |
| **Analytics** | BigQuery, Redshift, Snowflake |
| **ACID guarantees** | PostgreSQL, MySQL |
| **Horizontal scaling** | Cassandra, DynamoDB, MongoDB |

### SQL vs NoSQL

```
Use SQL when:
✅ Complex queries with JOINs
✅ Transactions required (ACID)
✅ Well-defined schema
✅ Relationships between data
✅ Data integrity critical

Use NoSQL when:
✅ Flexible/evolving schema
✅ Massive scale (billions of records)
✅ High throughput writes
✅ Simple key-value lookups
✅ Eventual consistency acceptable
```

---

## 11. Real-World Patterns

### Pattern 1: Polyglot Persistence

Use multiple database types for different needs:

```typescript
class UserService {
    private postgres: Pool;           // User profiles (relational)
    private redis: RedisClient;        // Sessions (cache)
    private mongodb: MongoClient;      // Activity logs (document)
    private elasticsearch: Client;     // Search (full-text)
    
    async getUserProfile(userId: string) {
        // 1. Check cache
        const cached = await this.redis.get(`user:${userId}`);
        if (cached) return JSON.parse(cached);
        
        // 2. Query PostgreSQL
        const result = await this.postgres.query(
            'SELECT * FROM users WHERE id = $1',
            [userId]
        );
        
        // 3. Cache result
        await this.redis.setex(
            `user:${userId}`,
            3600,
            JSON.stringify(result.rows[0])
        );
        
        return result.rows[0];
    }
    
    async logActivity(userId: string, activity: any) {
        // Store in MongoDB (flexible schema, high writes)
        await this.mongodb.db('myapp').collection('activities').insertOne({
            userId,
            activity,
            timestamp: new Date()
        });
    }
    
    async searchUsers(query: string) {
        // Search in Elasticsearch
        const result = await this.elasticsearch.search({
            index: 'users',
            body: {
                query: {
                    multi_match: {
                        query: query,
                        fields: ['name', 'email', 'bio']
                    }
                }
            }
        });
        
        return result.hits.hits.map(hit => hit._source);
    }
}
```

### Pattern 2: CQRS with Different Databases

```typescript
// Write Model - PostgreSQL (normalized, ACID)
class OrderWriteModel {
    async createOrder(order: Order): Promise<void> {
        await postgres.query('BEGIN');
        
        // Insert order
        await postgres.query(
            'INSERT INTO orders (id, customer_id, total) VALUES ($1, $2, $3)',
            [order.id, order.customerId, order.total]
        );
        
        // Insert order items
        for (const item of order.items) {
            await postgres.query(
                'INSERT INTO order_items (order_id, product_id, quantity) VALUES ($1, $2, $3)',
                [order.id, item.productId, item.quantity]
            );
        }
        
        await postgres.query('COMMIT');
    }
}

// Read Model - MongoDB (denormalized, fast reads)
class OrderReadModel {
    async getOrder(orderId: string): Promise<any> {
        // Single query, denormalized document
        return await mongodb.db('myapp').collection('orders').findOne({
            _id: orderId
        });
        // Returns: { _id, customer: {...}, items: [...], total, ... }
        // Everything in one document - no JOINs needed!
    }
}

// Synchronization: Update read model when write model changes
eventBus.on('OrderCreated', async (event) => {
    // Build denormalized document
    const order = await buildOrderDocument(event.orderId);
    
    // Store in MongoDB
    await mongodb.db('myapp').collection('orders').insertOne(order);
});
```

---

## Chapter 12 Summary

### Key Concepts

1. **Relational Databases** - Tables, JOINs, ACID, schema
2. **Normalization** - 1NF, 2NF, 3NF to reduce redundancy
3. **Indexes** - B-tree, Hash, Full-text for fast queries
4. **ACID** - Atomicity, Consistency, Isolation, Durability
5. **Replication** - Master-slave for read scaling
6. **Sharding** - Horizontal partitioning for write scaling
7. **NoSQL** - Document, Key-Value, Column, Graph
8. **CAP Theorem** - Consistency, Availability, Partition Tolerance

### Database Scaling Strategies

| Strategy | Scales | Complexity | Use Case |
|----------|--------|------------|----------|
| **Vertical Scaling** | Up only | Low | Small apps |
| **Replication** | Reads | Medium | Read-heavy |
| **Sharding** | Writes | High | Write-heavy |
| **NoSQL** | Both | Medium | Specific needs |

### SQL vs NoSQL Quick Guide

| Feature | SQL | NoSQL |
|---------|-----|-------|
| **Schema** | Fixed | Flexible |
| **Queries** | Complex JOINs | Simple lookups |
| **Transactions** | ACID | Eventually consistent |
| **Scaling** | Vertical + Read replicas | Horizontal |
| **Use Case** | Traditional apps | Web scale |

### Interview Tips

**Common Questions:**
1. "Explain database normalization"
2. "What is sharding?"
3. "SQL vs NoSQL - when to use each?"
4. "Explain CAP theorem"
5. "How do you scale a database?"

**How to Answer:**
- Draw diagrams (master-slave, sharding)
- Give concrete examples
- Discuss trade-offs
- Mention real databases (PostgreSQL, MongoDB, Cassandra)
- Know when NOT to shard/replicate

### Best Practices

1. **Index wisely** - Index columns used in WHERE/JOIN
2. **Monitor slow queries** - Use EXPLAIN to optimize
3. **Use connection pooling** - Don't create connections per request
4. **Shard when needed** - Not prematurely
5. **Choose right database** - SQL for complex queries, NoSQL for scale
6. **Plan for replication lag** - Read from master after write if needed
7. **Backup regularly** - Test restore process

### Next Steps

Chapter 13 will cover **Message Queues & Async Processing** - decoupling components with queues, handling background jobs, and building resilient systems.