# Chapter 32: CI/CD Pipelines

## Table of Contents
1. Introduction to CI/CD
2. Continuous Integration (CI)
3. Continuous Delivery vs Continuous Deployment
4. Build Pipelines
5. Testing Strategies
6. Deployment Strategies
7. Blue-Green Deployment
8. Canary Releases
9. Feature Flags
10. Infrastructure as Code
11. Pipeline Implementation Examples

---

## 1. Introduction to CI/CD

**Continuous Integration (CI):** Automatically build and test code changes.

**Continuous Delivery (CD):** Automatically prepare code for release (manual deploy).

**Continuous Deployment (CD):** Automatically deploy to production (no manual step).

### Traditional vs CI/CD

```
Traditional:
Developer writes code (days/weeks)
  → Manual merge (conflicts!)
  → Manual testing (slow)
  → Manual deployment (risky)
  → Deploy monthly/quarterly
  
Result: Slow, risky, painful deployments

CI/CD:
Developer commits code (many times/day)
  → Automatic merge and test (fast)
  → Automatic build (consistent)
  → Automatic deploy (safe)
  → Deploy multiple times/day
  
Result: Fast, safe, frequent deployments
```

### Benefits

```
✅ Faster time to market (deploy in minutes, not months)
✅ Reduced risk (small changes easier to debug)
✅ Higher quality (automated testing)
✅ Better collaboration (frequent integration)
✅ Faster feedback (know immediately if broken)
```

---

## 2. Continuous Integration (CI)

**Definition:** Developers integrate code into shared repository frequently, triggering automated builds and tests.

### CI Pipeline

```
1. Developer commits code to Git
   ↓
2. Webhook triggers CI server
   ↓
3. CI server pulls latest code
   ↓
4. Run linters (code quality)
   ↓
5. Run unit tests
   ↓
6. Run integration tests
   ↓
7. Build application
   ↓
8. Run security scans
   ↓
9. If all pass → Success ✓
   If any fail → Notify developer ✗
```

### GitHub Actions CI Example

```yaml
# ============================================
# .github/workflows/ci.yml
# ============================================

name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  # Job 1: Lint and Format Check
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run ESLint
        run: npm run lint
      
      - name: Check formatting
        run: npm run format:check
  
  # Job 2: Unit Tests
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run unit tests
        run: npm test
      
      - name: Generate coverage report
        run: npm run test:coverage
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/coverage.xml
      
      - name: Check coverage threshold
        run: |
          COVERAGE=$(cat coverage/coverage-summary.json | jq '.total.lines.pct')
          if (( $(echo "$COVERAGE < 80" | bc -l) )); then
            echo "Coverage $COVERAGE% is below 80% threshold"
            exit 1
          fi
  
  # Job 3: Integration Tests
  integration:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run migrations
        run: npm run db:migrate
        env:
          DATABASE_URL: postgresql://postgres:postgres@postgres:5432/test
      
      - name: Run integration tests
        run: npm run test:integration
        env:
          DATABASE_URL: postgresql://postgres:postgres@postgres:5432/test
          REDIS_URL: redis://redis:6379
  
  # Job 4: Security Scan
  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Run Snyk security scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      
      - name: Run Trivy vulnerability scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          severity: 'HIGH,CRITICAL'
  
  # Job 5: Build Docker Image
  build:
    runs-on: ubuntu-latest
    needs: [lint, test, integration, security]  # Wait for all to pass
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: |
            myapp/api:latest
            myapp/api:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Image vulnerability scan
        run: |
          docker run --rm aquasec/trivy image myapp/api:${{ github.sha }}
  
  # Job 6: Notify
  notify:
    runs-on: ubuntu-latest
    needs: [build]
    if: always()
    
    steps:
      - name: Slack notification
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'CI Pipeline ${{ job.status }}'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

---

## 3. Continuous Delivery vs Continuous Deployment

### Continuous Delivery

```
Code → CI → Build → Test → Stage → [MANUAL APPROVAL] → Production

Human decides when to deploy to production
Deployment process automated
```

### Continuous Deployment

```
Code → CI → Build → Test → Stage → Production (automatic)

No human intervention
Every commit that passes tests goes to production
```

### Implementation

```yaml
# ============================================
# Continuous Delivery (Manual approval)
# ============================================

# .github/workflows/cd.yml
name: Continuous Delivery

on:
  push:
    branches: [ main ]

jobs:
  deploy-staging:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Deploy to staging
        run: |
          kubectl set image deployment/api api=myapp/api:${{ github.sha }} -n staging
          kubectl rollout status deployment/api -n staging
  
  # Manual approval required
  approve-production:
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    environment:
      name: production
      url: https://api.example.com
    steps:
      - name: Waiting for approval
        run: echo "Deployment to production requires approval"
  
  deploy-production:
    runs-on: ubuntu-latest
    needs: [approve-production]
    steps:
      - name: Deploy to production
        run: |
          kubectl set image deployment/api api=myapp/api:${{ github.sha }} -n production
          kubectl rollout status deployment/api -n production

# ============================================
# Continuous Deployment (Fully automated)
# ============================================

name: Continuous Deployment

on:
  push:
    branches: [ main ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Run all tests
        run: npm test
      
      - name: Build Docker image
        run: docker build -t myapp/api:${{ github.sha }} .
      
      - name: Push to registry
        run: docker push myapp/api:${{ github.sha }}
      
      # Automatically deploy to staging
      - name: Deploy to staging
        run: |
          kubectl set image deployment/api api=myapp/api:${{ github.sha }} -n staging
      
      - name: Run smoke tests on staging
        run: npm run test:smoke -- --env=staging
      
      # Automatically deploy to production (no approval!)
      - name: Deploy to production
        run: |
          kubectl set image deployment/api api=myapp/api:${{ github.sha }} -n production
      
      - name: Run smoke tests on production
        run: npm run test:smoke -- --env=production
      
      - name: Notify team
        run: |
          curl -X POST ${{ secrets.SLACK_WEBHOOK }} \
            -H 'Content-Type: application/json' \
            -d '{"text":"Deployed ${{ github.sha }} to production"}'
```

---

## 6. Deployment Strategies

### Rolling Update

**Definition:** Gradually replace old version with new version.

```
Initial state:
[v1] [v1] [v1] [v1]

Step 1: Replace first instance
[v2] [v1] [v1] [v1]  ← Wait for health check

Step 2: Replace second instance
[v2] [v2] [v1] [v1]  ← Wait for health check

Step 3: Replace third instance
[v2] [v2] [v2] [v1]  ← Wait for health check

Step 4: Replace last instance
[v2] [v2] [v2] [v2]  ← Complete

Pros: Zero downtime, gradual rollout
Cons: Both versions running simultaneously
```

**Kubernetes Rolling Update:**

```yaml
# ============================================
# Rolling Update Configuration
# ============================================

apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-server
spec:
  replicas: 4
  
  # Rolling update strategy
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  # Max 1 pod down at a time
      maxSurge: 1  # Max 1 extra pod during update
  
  template:
    metadata:
      labels:
        app: api
        version: v2
    spec:
      containers:
      - name: api
        image: myapp/api:v2
        
        # Readiness probe (must pass before pod receives traffic)
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
          failureThreshold: 3
        
        # Liveness probe (restart if fails)
        livenessProbe:
          httpGet:
            path: /health/live
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10

# Deploy
kubectl apply -f deployment.yaml

# Watch rollout
kubectl rollout status deployment/api-server

# Rollback if issues
kubectl rollout undo deployment/api-server
```

---

## 7. Blue-Green Deployment

**Definition:** Run two identical environments, switch traffic atomically.

```
Blue (v1 - current production):
[v1] [v1] [v1] [v1]  ← 100% traffic

Green (v2 - new version):
[v2] [v2] [v2] [v2]  ← 0% traffic (testing)

Test Green thoroughly

Switch traffic:
Blue:  [v1] [v1] [v1] [v1]  ← 0% traffic
Green: [v2] [v2] [v2] [v2]  ← 100% traffic

If issues: Switch back to Blue instantly
```

### Implementation

```bash
# ============================================
# Blue-Green with Kubernetes
# ============================================

# Current production (Blue)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-blue
  labels:
    version: blue
spec:
  replicas: 4
  selector:
    matchLabels:
      app: api
      version: blue
  template:
    metadata:
      labels:
        app: api
        version: blue
    spec:
      containers:
      - name: api
        image: myapp/api:v1

---
# New version (Green)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-green
  labels:
    version: green
spec:
  replicas: 4
  selector:
    matchLabels:
      app: api
      version: green
  template:
    metadata:
      labels:
        app: api
        version: green
    spec:
      containers:
      - name: api
        image: myapp/api:v2

---
# Service (points to active version)
apiVersion: v1
kind: Service
metadata:
  name: api-service
spec:
  selector:
    app: api
    version: blue  # Currently pointing to blue
  ports:
  - port: 80
    targetPort: 3000

# ============================================
# Deployment Script
# ============================================

#!/bin/bash

# 1. Deploy green (new version)
kubectl apply -f api-green.yaml

# 2. Wait for green to be ready
kubectl wait --for=condition=available deployment/api-green --timeout=300s

# 3. Run smoke tests on green
./run-smoke-tests.sh http://api-green-internal:3000

# 4. If tests pass, switch traffic
if [ $? -eq 0 ]; then
    echo "Tests passed, switching to green"
    
    # Update service to point to green
    kubectl patch service api-service -p '{"spec":{"selector":{"version":"green"}}}'
    
    echo "Traffic switched to green"
    
    # 5. Monitor for 10 minutes
    sleep 600
    
    # 6. If stable, delete blue
    echo "Deleting old blue deployment"
    kubectl delete deployment api-blue
    
else
    echo "Tests failed, keeping blue active"
    kubectl delete deployment api-green
    exit 1
fi
```

---

## 8. Canary Releases

**Definition:** Gradually shift traffic from old to new version.

```
Stage 1: 95% old, 5% new (test with small traffic)
Stage 2: 75% old, 25% new (if metrics good)
Stage 3: 50% old, 50% new
Stage 4: 0% old, 100% new (complete)

Monitor metrics at each stage
Rollback if issues detected
```

### Canary with Istio

```yaml
# ============================================
# Canary Deployment with Istio
# ============================================

# Deployment v1 (stable)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-v1
spec:
  replicas: 9
  selector:
    matchLabels:
      app: api
      version: v1
  template:
    metadata:
      labels:
        app: api
        version: v1
    spec:
      containers:
      - name: api
        image: myapp/api:v1

---
# Deployment v2 (canary)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-v2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: api
      version: v2
  template:
    metadata:
      labels:
        app: api
        version: v2
    spec:
      containers:
      - name: api
        image: myapp/api:v2

---
# Virtual Service (traffic split)
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: api
spec:
  hosts:
  - api
  http:
  - route:
    - destination:
        host: api
        subset: v1
      weight: 90  # 90% to v1
    - destination:
        host: api
        subset: v2
      weight: 10  # 10% to v2 (canary)

---
# Destination Rule
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: api
spec:
  host: api
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
```

**Automated Canary Script:**

```python
# ============================================
# Automated Canary Deployment
# ============================================

import time
import requests

class CanaryDeployment:
    def __init__(self):
        self.metrics_url = 'http://prometheus:9090/api/v1/query'
    
    def get_error_rate(self, version):
        """Get error rate for specific version"""
        query = f'rate(http_requests_total{{version="{version}",status=~"5.."}}[5m]) / rate(http_requests_total{{version="{version}"}}[5m])'
        
        response = requests.get(self.metrics_url, params={'query': query})
        result = response.json()
        
        if result['data']['result']:
            return float(result['data']['result'][0]['value'][1])
        return 0
    
    def get_latency_p95(self, version):
        """Get p95 latency for version"""
        query = f'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{{version="{version}"}}[5m]))'
        
        response = requests.get(self.metrics_url, params={'query': query})
        result = response.json()
        
        if result['data']['result']:
            return float(result['data']['result'][0]['value'][1])
        return 0
    
    def update_traffic_split(self, v1_weight, v2_weight):
        """Update Istio virtual service weights"""
        import subprocess
        
        subprocess.run([
            'kubectl', 'patch', 'virtualservice', 'api',
            '--type=json',
            '-p', f'[{{"op":"replace","path":"/spec/http/0/route/0/weight","value":{v1_weight}}},{{"op":"replace","path":"/spec/http/0/route/1/weight","value":{v2_weight}}}]'
        ])
        
        print(f"Traffic split updated: v1={v1_weight}%, v2={v2_weight}%")
    
    def deploy_canary(self):
        """Automated canary deployment"""
        stages = [
            (95, 5),   # 5% canary
            (90, 10),  # 10% canary
            (75, 25),  # 25% canary
            (50, 50),  # 50% canary
            (0, 100)   # 100% canary (complete)
        ]
        
        for v1_weight, v2_weight in stages:
            print(f"\n=== Canary Stage: {v2_weight}% ===")
            
            # Update traffic split
            self.update_traffic_split(v1_weight, v2_weight)
            
            # Wait for metrics to stabilize
            print("Waiting 5 minutes for metrics...")
            time.sleep(300)
            
            # Check metrics
            v2_error_rate = self.get_error_rate('v2')
            v2_latency = self.get_latency_p95('v2')
            
            v1_error_rate = self.get_error_rate('v1')
            v1_latency = self.get_latency_p95('v1')
            
            print(f"v2 error rate: {v2_error_rate:.4f}")
            print(f"v2 p95 latency: {v2_latency:.3f}s")
            
            # Compare with v1
            if v2_error_rate > v1_error_rate * 1.5:  # 50% more errors
                print("❌ Error rate too high - rolling back")
                self.update_traffic_split(100, 0)
                raise Exception("Canary deployment failed")
            
            if v2_latency > v1_latency * 1.5:  # 50% slower
                print("❌ Latency too high - rolling back")
                self.update_traffic_split(100, 0)
                raise Exception("Canary deployment failed")
            
            print(f"✓ Metrics acceptable at {v2_weight}%")
        
        print("\n=== Canary deployment complete! ===")
        
        # Cleanup old version
        subprocess.run(['kubectl', 'delete', 'deployment', 'api-v1'])

# Run canary
canary = CanaryDeployment()
canary.deploy_canary()
```

---

## 9. Feature Flags

**Definition:** Toggle features on/off without deploying code.

### Implementation

```typescript
// ============================================
// Feature Flag Service
// ============================================

interface FeatureFlag {
  name: string;
  enabled: boolean;
  rollout_percentage?: number;
  user_whitelist?: string[];
  user_blacklist?: string[];
}

class FeatureFlagService {
  private redis: Redis;
  
  constructor() {
    this.redis = new Redis();
  }
  
  async isEnabled(flagName: string, userId?: string): Promise<boolean> {
    // Get flag configuration
    const flagData = await this.redis.get(`flag:${flagName}`);
    
    if (!flagData) {
      return false;  // Flag doesn't exist - disabled
    }
    
    const flag: FeatureFlag = JSON.parse(flagData);
    
    // Global toggle
    if (!flag.enabled) {
      return false;
    }
    
    // User whitelist (early access)
    if (userId && flag.user_whitelist?.includes(userId)) {
      return true;
    }
    
    // User blacklist (exclude specific users)
    if (userId && flag.user_blacklist?.includes(userId)) {
      return false;
    }
    
    // Percentage rollout
    if (flag.rollout_percentage !== undefined) {
      if (userId) {
        // Consistent hashing for stable rollout
        const hash = this.hashUserId(userId);
        const bucket = hash % 100;
        return bucket < flag.rollout_percentage;
      }
      
      // Random if no user ID
      return Math.random() * 100 < flag.rollout_percentage;
    }
    
    return true;
  }
  
  private hashUserId(userId: string): number {
    let hash = 0;
    for (let i = 0; i < userId.length; i++) {
      hash = ((hash << 5) - hash) + userId.charCodeAt(i);
      hash = hash & hash;
    }
    return Math.abs(hash);
  }
  
  async setFlag(flagName: string, config: FeatureFlag): Promise<void> {
    await this.redis.set(`flag:${flagName}`, JSON.stringify(config));
  }
  
  async enableForPercentage(flagName: string, percentage: number): Promise<void> {
    const flag = await this.getFlag(flagName);
    flag.rollout_percentage = percentage;
    await this.setFlag(flagName, flag);
  }
}

// ============================================
// Usage in Application
// ============================================

const featureFlags = new FeatureFlagService();

app.get('/api/products', async (req, res) => {
  const userId = req.user?.id;
  
  // Check if new recommendation engine enabled
  const useNewRecommendations = await featureFlags.isEnabled(
    'new_recommendation_engine',
    userId
  );
  
  const products = await getProducts();
  
  if (useNewRecommendations) {
    // Use new ML-based recommendations
    products.recommendations = await getMLRecommendations(userId);
  } else {
    // Use old rule-based recommendations
    products.recommendations = await getRuleBasedRecommendations(userId);
  }
  
  res.json(products);
});

// ============================================
// Gradual Rollout
// ============================================

// Day 1: Enable for 5% of users
await featureFlags.setFlag('new_recommendation_engine', {
  name: 'new_recommendation_engine',
  enabled: true,
  rollout_percentage: 5
});

// Day 3: Increase to 25% (metrics look good)
await featureFlags.enableForPercentage('new_recommendation_engine', 25);

// Day 5: 50%
await featureFlags.enableForPercentage('new_recommendation_engine', 50);

// Day 7: 100% (full rollout)
await featureFlags.enableForPercentage('new_recommendation_engine', 100);

// If issues at any stage: Disable immediately
await featureFlags.setFlag('new_recommendation_engine', {
  name: 'new_recommendation_engine',
  enabled: false  // Instant rollback!
});
```

---

## 10. Infrastructure as Code

### Terraform Example

```hcl
# ============================================
# Infrastructure as Code with Terraform
# ============================================

# Provider
provider "aws" {
  region = "us-east-1"
}

# VPC
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  
  tags = {
    Name = "production-vpc"
  }
}

# Subnets
resource "aws_subnet" "public" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 1}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]
  
  tags = {
    Name = "public-subnet-${count.index + 1}"
  }
}

# Load Balancer
resource "aws_lb" "main" {
  name               = "api-lb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.lb.id]
  subnets            = aws_subnet.public[*].id
}

# Auto Scaling Group
resource "aws_launch_template" "api" {
  name_prefix   = "api-"
  image_id      = data.aws_ami.amazon_linux_2.id
  instance_type = "t3.medium"
  
  user_data = base64encode(<<-EOF
    #!/bin/bash
    yum update -y
    yum install -y docker
    systemctl start docker
    docker run -d -p 3000:3000 myapp/api:${var.app_version}
  EOF
  )
}

resource "aws_autoscaling_group" "api" {
  name                = "api-asg"
  vpc_zone_identifier = aws_subnet.public[*].id
  target_group_arns   = [aws_lb_target_group.api.arn]
  
  min_size         = 2
  max_size         = 10
  desired_capacity = 4
  
  launch_template {
    id      = aws_launch_template.api.id
    version = "$Latest"
  }
  
  # Health check
  health_check_type         = "ELB"
  health_check_grace_period = 300
  
  # Tags
  tag {
    key                 = "Name"
    value               = "api-server"
    propagate_at_launch = true
  }
}

# Auto Scaling Policies
resource "aws_autoscaling_policy" "scale_up" {
  name                   = "scale-up"
  autoscaling_group_name = aws_autoscaling_group.api.name
  adjustment_type        = "ChangeInCapacity"
  scaling_adjustment     = 2
  cooldown               = 300
}

resource "aws_autoscaling_policy" "scale_down" {
  name                   = "scale-down"
  autoscaling_group_name = aws_autoscaling_group.api.name
  adjustment_type        = "ChangeInCapacity"
  scaling_adjustment     = -1
  cooldown               = 300
}

# CloudWatch Alarms
resource "aws_cloudwatch_metric_alarm" "high_cpu" {
  alarm_name          = "api-high-cpu"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/EC2"
  period              = "120"
  statistic           = "Average"
  threshold           = "70"
  
  dimensions = {
    AutoScalingGroupName = aws_autoscaling_group.api.name
  }
  
  alarm_actions = [aws_autoscaling_policy.scale_up.arn]
}

# Variables
variable "app_version" {
  description = "Application version to deploy"
  type        = string
  default     = "v1.0.0"
}

# Outputs
output "load_balancer_dns" {
  value = aws_lb.main.dns_name
}
```

**Deploy with Terraform:**

```bash
# Initialize
terraform init

# Plan changes
terraform plan -var="app_version=v1.2.0"

# Apply changes
terraform apply -var="app_version=v1.2.0"

# Infrastructure versioned in Git
# Reproducible deployments
# Review changes before applying
```

---

## 11. Pipeline Implementation Examples

### Complete CI/CD Pipeline (GitLab CI)

```yaml
# ============================================
# .gitlab-ci.yml - Complete Pipeline
# ============================================

stages:
  - lint
  - test
  - build
  - deploy-staging
  - test-staging
  - deploy-production

variables:
  DOCKER_IMAGE: registry.gitlab.com/myapp/api
  KUBECONFIG: /root/.kube/config

# ============================================
# Stage 1: Lint
# ============================================

lint:
  stage: lint
  image: node:18
  script:
    - npm ci
    - npm run lint
    - npm run format:check
  only:
    - merge_requests
    - main

# ============================================
# Stage 2: Test
# ============================================

unit-tests:
  stage: test
  image: node:18
  services:
    - postgres:14
    - redis:7
  variables:
    POSTGRES_DB: test
    POSTGRES_USER: test
    POSTGRES_PASSWORD: test
  script:
    - npm ci
    - npm run db:migrate
    - npm run test:unit
    - npm run test:coverage
  coverage: '/Lines\s*:\s*(\d+\.\d+)%/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura-coverage.xml

integration-tests:
  stage: test
  image: node:18
  services:
    - postgres:14
    - redis:7
  script:
    - npm ci
    - npm run test:integration
  only:
    - merge_requests
    - main

# ============================================
# Stage 3: Build
# ============================================

build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    # Build image
    - docker build -t $DOCKER_IMAGE:$CI_COMMIT_SHA .
    - docker tag $DOCKER_IMAGE:$CI_COMMIT_SHA $DOCKER_IMAGE:latest
    
    # Scan for vulnerabilities
    - docker run --rm aquasec/trivy image $DOCKER_IMAGE:$CI_COMMIT_SHA
    
    # Push to registry
    - docker push $DOCKER_IMAGE:$CI_COMMIT_SHA
    - docker push $DOCKER_IMAGE:latest
  only:
    - main

# ============================================
# Stage 4: Deploy to Staging
# ============================================

deploy-staging:
  stage: deploy-staging
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context staging
    - kubectl set image deployment/api api=$DOCKER_IMAGE:$CI_COMMIT_SHA -n staging
    - kubectl rollout status deployment/api -n staging --timeout=5m
  environment:
    name: staging
    url: https://staging.example.com
  only:
    - main

# ============================================
# Stage 5: Test Staging
# ============================================

smoke-tests-staging:
  stage: test-staging
  image: node:18
  script:
    - npm ci
    - npm run test:smoke -- --env=staging
  only:
    - main

load-tests:
  stage: test-staging
  image: grafana/k6:latest
  script:
    - k6 run --vus 100 --duration 5m load-test.js
  only:
    - main

# ============================================
# Stage 6: Deploy to Production
# ============================================

deploy-production:
  stage: deploy-production
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context production
    
    # Blue-Green deployment
    - kubectl apply -f k8s/deployment-green.yaml
    - kubectl wait --for=condition=available deployment/api-green -n production --timeout=5m
    
    # Run smoke tests on green
    - ./scripts/smoke-test.sh https://api-green-internal.example.com
    
    # Switch traffic to green
    - kubectl patch service api -n production -p '{"spec":{"selector":{"version":"green"}}}'
    
    # Monitor for 10 minutes
    - sleep 600
    
    # Delete blue if stable
    - kubectl delete deployment api-blue -n production || true
    
  environment:
    name: production
    url: https://api.example.com
  when: manual  # Require manual trigger
  only:
    - main

# ============================================
# Notifications
# ============================================

notify-success:
  stage: .post
  script:
    - 'curl -X POST $SLACK_WEBHOOK -H "Content-Type: application/json" -d "{\"text\":\"Pipeline succeeded for $CI_COMMIT_SHA\"}"'
  when: on_success

notify-failure:
  stage: .post
  script:
    - 'curl -X POST $SLACK_WEBHOOK -H "Content-Type: application/json" -d "{\"text\":\"Pipeline FAILED for $CI_COMMIT_SHA\"}"'
  when: on_failure
```

---

## Chapter 32 Summary

### Key Concepts

1. **CI** - Continuous Integration (automated build + test)
2. **CD** - Continuous Delivery (ready to deploy)
3. **CD** - Continuous Deployment (auto-deploy)
4. **Rolling Update** - Gradual instance replacement
5. **Blue-Green** - Atomic traffic switch
6. **Canary** - Gradual traffic shift
7. **Feature Flags** - Runtime feature toggle
8. **Infrastructure as Code** - Version control infrastructure
9. **Quality Gates** - Automated checks before deploy

### Deployment Strategies Comparison

| Strategy | Downtime | Rollback Speed | Complexity | Use Case |
|----------|----------|----------------|------------|----------|
| **Rolling** | None | Slow | Low | Standard deployments |
| **Blue-Green** | None | Instant | Medium | Risk-averse |
| **Canary** | None | Fast | High | Gradual validation |
| **Feature Flags** | None | Instant | Medium | A/B testing, gradual rollout |

### CI/CD Best Practices

**Build Stage:**
- [ ] Fast builds (< 10 minutes)
- [ ] Parallel test execution
- [ ] Caching dependencies
- [ ] Consistent build environment (Docker)

**Test Stage:**
- [ ] Unit tests (fast, < 5 min)
- [ ] Integration tests (medium, < 15 min)
- [ ] E2E tests (slow, < 30 min)
- [ ] > 80% code coverage
- [ ] Automated test data setup

**Deployment:**
- [ ] Zero-downtime deployments
- [ ] Automated rollback
- [ ] Smoke tests post-deploy
- [ ] Gradual rollout (canary)
- [ ] Feature flags for risk mitigation

**Monitoring:**
- [ ] Track deployment metrics
- [ ] Alert on deployment failures
- [ ] Monitor error rates post-deploy
- [ ] Track deployment frequency

### Pipeline Metrics

```
Key Metrics to Track:

1. Deployment Frequency
   - How often do you deploy?
   - Elite: Multiple per day
   - High: Weekly to monthly
   - Low: Monthly to yearly

2. Lead Time for Changes
   - Code commit → Production
   - Elite: < 1 hour
   - High: 1 day to 1 week
   - Low: 1 month to 6 months

3. Mean Time to Recovery (MTTR)
   - Time to recover from failure
   - Elite: < 1 hour
   - High: < 1 day
   - Low: 1 week to 1 month

4. Change Failure Rate
   - % of deployments causing issues
   - Elite: 0-15%
   - High: 16-30%
   - Low: 31-45%
```

### Interview Tips

**Common Questions:**
1. "Explain CI/CD pipeline"
2. "Blue-Green vs Canary deployment?"
3. "How do you ensure deployment safety?"
4. "What is Infrastructure as Code?"

**How to Answer:**
- Draw pipeline flow diagram
- Explain each stage (build, test, deploy)
- Compare deployment strategies with pros/cons
- Mention specific tools (Jenkins, GitHub Actions, ArgoCD)
- Discuss quality gates and rollback strategies

### Tools Overview

| Category | Tools |
|----------|-------|
| **CI/CD** | Jenkins, GitLab CI, GitHub Actions, CircleCI |
| **Container** | Docker, Podman |
| **Orchestration** | Kubernetes, ECS, Docker Swarm |
| **IaC** | Terraform, CloudFormation, Pulumi |
| **Config Mgmt** | Ansible, Chef, Puppet |
| **GitOps** | ArgoCD, Flux |
| **Feature Flags** | LaunchDarkly, Unleash, Split |

Congratulations! You've completed the entire 32-chapter Software Architecture masterclass! You now have comprehensive knowledge from fundamentals to advanced distributed systems!