# Chapter 33: Infrastructure as Code

## Table of Contents
1. Introduction to Infrastructure as Code
2. Terraform Fundamentals
3. AWS CloudFormation
4. Pulumi (Multi-Language IaC)
5. Configuration Management (Ansible)
6. Immutable Infrastructure
7. State Management
8. Modules and Reusability
9. Testing Infrastructure Code
10. GitOps
11. Best Practices

---

## 1. Introduction to Infrastructure as Code

**Definition:** Infrastructure as Code (IaC) is managing and provisioning infrastructure through machine-readable files rather than manual configuration.

### The Problem with Manual Infrastructure

```
Manual Process:
1. SSH into server
2. Run commands:
   - apt-get install nginx
   - Configure nginx.conf
   - Start nginx
3. Repeat for each server
4. Document in wiki (often outdated)

Problems:
❌ Not reproducible (works on my machine!)
❌ Configuration drift (servers diverge over time)
❌ No audit trail
❌ Slow (minutes per server)
❌ Error-prone (typos, missed steps)
❌ Hard to scale (100 servers?)
```

### IaC Solution

```
Infrastructure as Code:
1. Write configuration file
2. Run: terraform apply
3. Infrastructure created automatically

Benefits:
✅ Reproducible (same result every time)
✅ Version controlled (Git)
✅ Code review process
✅ Documented in code
✅ Fast (parallel provisioning)
✅ Testable
✅ Scalable (100 servers = same effort as 1)
```

---

## 2. Terraform Fundamentals

**Terraform:** Infrastructure as Code tool for building, changing, and versioning infrastructure.

### Basic Concepts

**1. Providers**
```hcl
# Connect to cloud provider
provider "aws" {
  region = "us-east-1"
}

provider "google" {
  project = "my-project"
  region  = "us-central1"
}
```

**2. Resources**
```hcl
# Define infrastructure components
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.medium"
  
  tags = {
    Name = "WebServer"
  }
}
```

**3. Variables**
```hcl
# variables.tf
variable "instance_type" {
  description = "EC2 instance type"
  type        = string
  default     = "t3.medium"
}

variable "environment" {
  description = "Environment name"
  type        = string
}

# Use in resource
resource "aws_instance" "web" {
  instance_type = var.instance_type
  
  tags = {
    Environment = var.environment
  }
}
```

**4. Outputs**
```hcl
# outputs.tf
output "instance_ip" {
  value = aws_instance.web.public_ip
}

output "instance_id" {
  value = aws_instance.web.id
}
```

### Complete Example: VPC with EC2

```hcl
# ============================================
# main.tf - Complete Infrastructure
# ============================================

terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
  
  # Remote state storage
  backend "s3" {
    bucket = "myapp-terraform-state"
    key    = "production/terraform.tfstate"
    region = "us-east-1"
    
    # State locking
    dynamodb_table = "terraform-state-lock"
    encrypt        = true
  }
}

provider "aws" {
  region = var.aws_region
}

# ============================================
# VPC
# ============================================

resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name        = "${var.project_name}-vpc"
    Environment = var.environment
  }
}

# Internet Gateway
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
  
  tags = {
    Name = "${var.project_name}-igw"
  }
}

# Public Subnets
resource "aws_subnet" "public" {
  count                   = 2
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.${count.index + 1}.0/24"
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true
  
  tags = {
    Name = "${var.project_name}-public-${count.index + 1}"
    Tier = "Public"
  }
}

# Private Subnets
resource "aws_subnet" "private" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 10}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]
  
  tags = {
    Name = "${var.project_name}-private-${count.index + 1}"
    Tier = "Private"
  }
}

# ============================================
# Security Groups
# ============================================

resource "aws_security_group" "web" {
  name        = "${var.project_name}-web-sg"
  description = "Security group for web servers"
  vpc_id      = aws_vpc.main.id
  
  # Inbound HTTP
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  # Inbound HTTPS
  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  # Outbound (all)
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  tags = {
    Name = "${var.project_name}-web-sg"
  }
}

# ============================================
# EC2 Instances
# ============================================

resource "aws_instance" "web" {
  count         = var.instance_count
  ami           = data.aws_ami.ubuntu.id
  instance_type = var.instance_type
  subnet_id     = aws_subnet.public[count.index % 2].id
  
  vpc_security_group_ids = [aws_security_group.web.id]
  
  # User data script
  user_data = templatefile("${path.module}/user-data.sh", {
    app_version = var.app_version
  })
  
  # IAM role
  iam_instance_profile = aws_iam_instance_profile.web.name
  
  tags = {
    Name        = "${var.project_name}-web-${count.index + 1}"
    Environment = var.environment
  }
}

# ============================================
# Load Balancer
# ============================================

resource "aws_lb" "main" {
  name               = "${var.project_name}-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.web.id]
  subnets            = aws_subnet.public[*].id
  
  tags = {
    Name = "${var.project_name}-alb"
  }
}

resource "aws_lb_target_group" "web" {
  name     = "${var.project_name}-tg"
  port     = 80
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id
  
  health_check {
    path                = "/health"
    healthy_threshold   = 2
    unhealthy_threshold = 10
    timeout             = 5
    interval            = 30
  }
}

resource "aws_lb_listener" "http" {
  load_balancer_arn = aws_lb.main.arn
  port              = "80"
  protocol          = "HTTP"
  
  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.web.arn
  }
}

# Attach instances to target group
resource "aws_lb_target_group_attachment" "web" {
  count            = var.instance_count
  target_group_arn = aws_lb_target_group.web.arn
  target_id        = aws_instance.web[count.index].id
  port             = 80
}

# ============================================
# RDS Database
# ============================================

resource "aws_db_instance" "main" {
  identifier           = "${var.project_name}-db"
  engine               = "postgres"
  engine_version       = "14.7"
  instance_class       = "db.t3.medium"
  allocated_storage    = 100
  storage_encrypted    = true
  
  db_name  = var.db_name
  username = var.db_username
  password = var.db_password
  
  vpc_security_group_ids = [aws_security_group.database.id]
  db_subnet_group_name   = aws_db_subnet_group.main.name
  
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "mon:04:00-mon:05:00"
  
  multi_az = true
  
  skip_final_snapshot = false
  final_snapshot_identifier = "${var.project_name}-final-snapshot"
  
  tags = {
    Name = "${var.project_name}-db"
  }
}

# ============================================
# Outputs
# ============================================

output "load_balancer_dns" {
  value       = aws_lb.main.dns_name
  description = "DNS name of load balancer"
}

output "database_endpoint" {
  value       = aws_db_instance.main.endpoint
  sensitive   = true
  description = "Database endpoint"
}
```

### Terraform Commands

```bash
# ============================================
# Terraform Workflow
# ============================================

# Initialize (download providers)
terraform init

# Validate syntax
terraform validate

# Format code
terraform fmt -recursive

# Plan changes (dry run)
terraform plan -out=tfplan

# Review plan
# Shows what will be created/updated/deleted

# Apply changes
terraform apply tfplan

# Show current state
terraform show

# List resources
terraform state list

# Destroy infrastructure
terraform destroy

# ============================================
# Using Variables
# ============================================

# Create terraform.tfvars
cat > terraform.tfvars <<EOF
aws_region     = "us-east-1"
environment    = "production"
instance_count = 4
instance_type  = "t3.medium"
app_version    = "v1.2.0"
EOF

# Or pass via command line
terraform apply \
  -var="environment=staging" \
  -var="instance_count=2"
```

---

## 3. AWS CloudFormation

**Definition:** AWS-native Infrastructure as Code using JSON or YAML templates.

### CloudFormation Template

```yaml
# ============================================
# cloudformation-template.yaml
# ============================================

AWSTemplateFormatVersion: '2010-09-09'
Description: 'Web application infrastructure'

# ============================================
# Parameters (inputs)
# ============================================

Parameters:
  Environment:
    Type: String
    Default: production
    AllowedValues:
      - development
      - staging
      - production
  
  InstanceType:
    Type: String
    Default: t3.medium
    AllowedValues:
      - t3.small
      - t3.medium
      - t3.large
  
  KeyPairName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: EC2 key pair for SSH access

# ============================================
# Mappings (lookup tables)
# ============================================

Mappings:
  RegionMap:
    us-east-1:
      AMI: ami-0c55b159cbfafe1f0
    us-west-2:
      AMI: ami-0d1cd67c26f5fca19
    eu-west-1:
      AMI: ami-0dad359ff462124ca

# ============================================
# Resources
# ============================================

Resources:
  # VPC
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-vpc'
  
  # Internet Gateway
  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-igw'
  
  AttachGateway:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref InternetGateway
  
  # Public Subnet
  PublicSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.1.0/24
      MapPublicIpOnLaunch: true
      AvailabilityZone: !Select [0, !GetAZs '']
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-public-subnet'
  
  # Security Group
  WebSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub '${AWS::StackName}-web-sg'
      GroupDescription: Security group for web servers
      VpcId: !Ref VPC
      
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
      
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
  
  # Launch Template
  LaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateName: !Sub '${AWS::StackName}-template'
      LaunchTemplateData:
        ImageId: !FindInMap [RegionMap, !Ref 'AWS::Region', AMI]
        InstanceType: !Ref InstanceType
        KeyName: !Ref KeyPairName
        
        SecurityGroupIds:
          - !Ref WebSecurityGroup
        
        UserData:
          Fn::Base64: !Sub |
            #!/bin/bash
            yum update -y
            yum install -y docker
            systemctl start docker
            docker run -d -p 80:3000 myapp/api:latest
        
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub '${AWS::StackName}-web'
  
  # Auto Scaling Group
  AutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      AutoScalingGroupName: !Sub '${AWS::StackName}-asg'
      VPCZoneIdentifier:
        - !Ref PublicSubnet
      
      LaunchTemplate:
        LaunchTemplateId: !Ref LaunchTemplate
        Version: !GetAtt LaunchTemplate.LatestVersionNumber
      
      MinSize: 2
      MaxSize: 10
      DesiredCapacity: 4
      
      HealthCheckType: ELB
      HealthCheckGracePeriod: 300
      
      TargetGroupARNs:
        - !Ref TargetGroup
      
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-asg'
          PropagateAtLaunch: true
  
  # Application Load Balancer
  LoadBalancer:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub '${AWS::StackName}-alb'
      Type: application
      Scheme: internet-facing
      SecurityGroups:
        - !Ref WebSecurityGroup
      Subnets:
        - !Ref PublicSubnet
  
  TargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: !Sub '${AWS::StackName}-tg'
      Port: 80
      Protocol: HTTP
      VpcId: !Ref VPC
      
      HealthCheckPath: /health
      HealthCheckIntervalSeconds: 30
      HealthyThresholdCount: 2
      UnhealthyThresholdCount: 3
  
  Listener:
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      LoadBalancerArn: !Ref LoadBalancer
      Port: 80
      Protocol: HTTP
      
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref TargetGroup

# ============================================
# Outputs
# ============================================

Outputs:
  LoadBalancerURL:
    Description: URL of load balancer
    Value: !Sub 'http://${LoadBalancer.DNSName}'
    Export:
      Name: !Sub '${AWS::StackName}-lb-url'
  
  VPCId:
    Description: VPC ID
    Value: !Ref VPC
    Export:
      Name: !Sub '${AWS::StackName}-vpc-id'
```

**Deploy CloudFormation:**

```bash
# Create stack
aws cloudformation create-stack \
  --stack-name myapp-production \
  --template-body file://cloudformation-template.yaml \
  --parameters \
    ParameterKey=Environment,ParameterValue=production \
    ParameterKey=InstanceType,ParameterValue=t3.medium \
    ParameterKey=KeyPairName,ParameterValue=my-key \
  --capabilities CAPABILITY_IAM

# Update stack
aws cloudformation update-stack \
  --stack-name myapp-production \
  --template-body file://cloudformation-template.yaml

# Delete stack
aws cloudformation delete-stack \
  --stack-name myapp-production

# Describe stack
aws cloudformation describe-stacks \
  --stack-name myapp-production
```

---

## 4. Pulumi (Multi-Language IaC)

**Definition:** Infrastructure as Code using real programming languages (TypeScript, Python, Go).

### Pulumi Example (TypeScript)

```typescript
// ============================================
// index.ts - Pulumi Infrastructure
// ============================================

import * as pulumi from "@pulumi/pulumi";
import * as aws from "@pulumi/aws";

// Configuration
const config = new pulumi.Config();
const environment = config.require("environment");
const instanceCount = config.getNumber("instanceCount") || 4;

// VPC
const vpc = new aws.ec2.Vpc("main-vpc", {
    cidrBlock: "10.0.0.0/16",
    enableDnsHostnames: true,
    enableDnsSupport: true,
    tags: {
        Name: `${pulumi.getStack()}-vpc`,
        Environment: environment
    }
});

// Internet Gateway
const igw = new aws.ec2.InternetGateway("main-igw", {
    vpcId: vpc.id,
    tags: { Name: `${pulumi.getStack()}-igw` }
});

// Public Subnet
const publicSubnet = new aws.ec2.Subnet("public-subnet", {
    vpcId: vpc.id,
    cidrBlock: "10.0.1.0/24",
    mapPublicIpOnLaunch: true,
    availabilityZone: "us-east-1a",
    tags: { Name: `${pulumi.getStack()}-public-subnet` }
});

// Security Group
const webSg = new aws.ec2.SecurityGroup("web-sg", {
    vpcId: vpc.id,
    description: "Security group for web servers",
    
    ingress: [
        { protocol: "tcp", fromPort: 80, toPort: 80, cidrBlocks: ["0.0.0.0/0"] },
        { protocol: "tcp", fromPort: 443, toPort: 443, cidrBlocks: ["0.0.0.0/0"] }
    ],
    
    egress: [
        { protocol: "-1", fromPort: 0, toPort: 0, cidrBlocks: ["0.0.0.0/0"] }
    ],
    
    tags: { Name: `${pulumi.getStack()}-web-sg` }
});

// Get latest Ubuntu AMI
const ubuntu = aws.ec2.getAmi({
    mostRecent: true,
    owners: ["099720109477"], // Canonical
    filters: [
        { name: "name", values: ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"] }
    ]
});

// EC2 Instances (using loop)
const instances: aws.ec2.Instance[] = [];

for (let i = 0; i < instanceCount; i++) {
    const instance = new aws.ec2.Instance(`web-${i}`, {
        ami: ubuntu.then(ami => ami.id),
        instanceType: "t3.medium",
        subnetId: publicSubnet.id,
        vpcSecurityGroupIds: [webSg.id],
        
        userData: `#!/bin/bash
            apt-get update
            apt-get install -y docker.io
            systemctl start docker
            docker run -d -p 80:3000 myapp/api:latest
        `,
        
        tags: {
            Name: `${pulumi.getStack()}-web-${i}`,
            Environment: environment
        }
    });
    
    instances.push(instance);
}

// Load Balancer
const alb = new aws.lb.LoadBalancer("main-alb", {
    internal: false,
    loadBalancerType: "application",
    securityGroups: [webSg.id],
    subnets: [publicSubnet.id],
    tags: { Name: `${pulumi.getStack()}-alb` }
});

const targetGroup = new aws.lb.TargetGroup("web-tg", {
    port: 80,
    protocol: "HTTP",
    vpcId: vpc.id,
    
    healthCheck: {
        path: "/health",
        interval: 30,
        timeout: 5,
        healthyThreshold: 2,
        unhealthyThreshold: 3
    }
});

// Attach instances to target group
instances.forEach((instance, i) => {
    new aws.lb.TargetGroupAttachment(`web-tg-attachment-${i}`, {
        targetGroupArn: targetGroup.arn,
        targetId: instance.id,
        port: 80
    });
});

const listener = new aws.lb.Listener("web-listener", {
    loadBalancerArn: alb.arn,
    port: 80,
    protocol: "HTTP",
    
    defaultActions: [{
        type: "forward",
        targetGroupArn: targetGroup.arn
    }]
});

// ============================================
// Exports
// ============================================

export const vpcId = vpc.id;
export const loadBalancerUrl = alb.dnsName;
export const instanceIds = instances.map(i => i.id);
```

**Deploy with Pulumi:**

```bash
# Install Pulumi
curl -fsSL https://get.pulumi.com | sh

# Create new project
pulumi new aws-typescript

# Set configuration
pulumi config set environment production
pulumi config set instanceCount 4

# Preview changes
pulumi preview

# Deploy
pulumi up

# View outputs
pulumi stack output loadBalancerUrl

# Destroy
pulumi destroy
```

**Pulumi Advantages:**
- Real programming language (loops, conditionals, functions)
- Type safety
- IDE autocomplete
- Reusable components (npm packages)
- Testable with unit tests

---

## 5. Configuration Management (Ansible)

**Definition:** Automate configuration of servers after provisioning.

### Ansible Playbook

```yaml
# ============================================
# playbook.yml - Configure Web Servers
# ============================================

---
- name: Configure web servers
  hosts: webservers
  become: yes
  
  vars:
    app_version: "v1.2.0"
    node_env: "production"
    app_port: 3000
  
  tasks:
    # ==================
    # System Setup
    # ==================
    
    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600
    
    - name: Install required packages
      apt:
        name:
          - docker.io
          - docker-compose
          - python3-pip
        state: present
    
    - name: Start Docker service
      systemd:
        name: docker
        state: started
        enabled: yes
    
    # ==================
    # Application Deployment
    # ==================
    
    - name: Pull Docker image
      docker_image:
        name: "myapp/api:{{ app_version }}"
        source: pull
    
    - name: Stop old container
      docker_container:
        name: api
        state: absent
      ignore_errors: yes
    
    - name: Run application container
      docker_container:
        name: api
        image: "myapp/api:{{ app_version }}"
        state: started
        restart_policy: always
        ports:
          - "{{ app_port }}:3000"
        env:
          NODE_ENV: "{{ node_env }}"
          DATABASE_URL: "{{ database_url }}"
          REDIS_URL: "{{ redis_url }}"
        volumes:
          - /var/log/app:/app/logs
    
    # ==================
    # Nginx Setup
    # ==================
    
    - name: Install Nginx
      apt:
        name: nginx
        state: present
    
    - name: Configure Nginx
      template:
        src: nginx.conf.j2
        dest: /etc/nginx/sites-available/api
        mode: '0644'
      notify: Reload Nginx
    
    - name: Enable site
      file:
        src: /etc/nginx/sites-available/api
        dest: /etc/nginx/sites-enabled/api
        state: link
      notify: Reload Nginx
    
    # ==================
    # Monitoring
    # ==================
    
    - name: Install Node Exporter (Prometheus)
      get_url:
        url: https://github.com/prometheus/node_exporter/releases/download/v1.3.1/node_exporter-1.3.1.linux-amd64.tar.gz
        dest: /tmp/node_exporter.tar.gz
    
    - name: Extract Node Exporter
      unarchive:
        src: /tmp/node_exporter.tar.gz
        dest: /opt/
        remote_src: yes
    
    - name: Create systemd service for Node Exporter
      copy:
        dest: /etc/systemd/system/node_exporter.service
        content: |
          [Unit]
          Description=Node Exporter
          
          [Service]
          ExecStart=/opt/node_exporter-1.3.1/node_exporter
          
          [Install]
          WantedBy=multi-user.target
    
    - name: Start Node Exporter
      systemd:
        name: node_exporter
        state: started
        enabled: yes
  
  # ==================
  # Handlers
  # ==================
  
  handlers:
    - name: Reload Nginx
      systemd:
        name: nginx
        state: reloaded
```

**Nginx Template (Jinja2):**

```nginx
# ============================================
# templates/nginx.conf.j2
# ============================================

upstream backend {
    server localhost:{{ app_port }};
}

server {
    listen 80;
    server_name {{ inventory_hostname }};
    
    location / {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_cache_bypass $http_upgrade;
    }
    
    location /health {
        access_log off;
        proxy_pass http://backend/health;
    }
}
```

**Run Ansible:**

```bash
# ============================================
# Inventory file (hosts.ini)
# ============================================

[webservers]
web1 ansible_host=54.123.45.67 ansible_user=ubuntu
web2 ansible_host=54.123.45.68 ansible_user=ubuntu
web3 ansible_host=54.123.45.69 ansible_user=ubuntu

[webservers:vars]
database_url=postgresql://db.example.com:5432/myapp
redis_url=redis://cache.example.com:6379

# ============================================
# Run playbook
# ============================================

# Check syntax
ansible-playbook playbook.yml --syntax-check

# Dry run
ansible-playbook -i hosts.ini playbook.yml --check

# Execute
ansible-playbook -i hosts.ini playbook.yml

# Execute on specific host
ansible-playbook -i hosts.ini playbook.yml --limit web1

# Execute specific tasks (tags)
ansible-playbook -i hosts.ini playbook.yml --tags "docker"
```

---

## 6. Immutable Infrastructure

**Definition:** Never modify infrastructure. Replace instead of update.

### Mutable vs Immutable

```
Mutable (Traditional):
Server created → Updated over time
                → Configuration drifts
                → "Snowflake servers"

v1.0: Install app
v1.1: Update app
v1.2: Patch bug
v1.3: Update dependency
...
Result: Server state unknown, hard to reproduce

Immutable (Modern):
v1.0: Create server with v1.0
v1.1: Create NEW server with v1.1, destroy old
v1.2: Create NEW server with v1.2, destroy old

Result: Always know exact state, reproducible
```

### Implementation with Packer

```hcl
# ============================================
# packer-template.pkr.hcl - Build AMI
# ============================================

packer {
  required_plugins {
    amazon = {
      version = ">= 1.0.0"
      source  = "github.com/hashicorp/amazon"
    }
  }
}

variable "app_version" {
  type    = string
  default = "v1.0.0"
}

source "amazon-ebs" "ubuntu" {
  ami_name      = "myapp-api-${var.app_version}"
  instance_type = "t3.medium"
  region        = "us-east-1"
  
  source_ami_filter {
    filters = {
      name                = "ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"
      root-device-type    = "ebs"
      virtualization-type = "hvm"
    }
    most_recent = true
    owners      = ["099720109477"]
  }
  
  ssh_username = "ubuntu"
  
  tags = {
    Name        = "myapp-api"
    Version     = "${var.app_version}"
    BuildDate   = "{{ timestamp }}"
  }
}

build {
  sources = ["source.amazon-ebs.ubuntu"]
  
  # Install dependencies
  provisioner "shell" {
    inline = [
      "sudo apt-get update",
      "sudo apt-get install -y docker.io docker-compose",
      "sudo systemctl enable docker",
      "sudo systemctl start docker"
    ]
  }
  
  # Copy application files
  provisioner "file" {
    source      = "docker-compose.yml"
    destination = "/tmp/docker-compose.yml"
  }
  
  # Pull Docker image
  provisioner "shell" {
    inline = [
      "sudo docker pull myapp/api:${var.app_version}",
      "sudo mv /tmp/docker-compose.yml /opt/app/docker-compose.yml"
    ]
  }
  
  # Create systemd service
  provisioner "file" {
    source      = "api.service"
    destination = "/tmp/api.service"
  }
  
  provisioner "shell" {
    inline = [
      "sudo mv /tmp/api.service /etc/systemd/system/api.service",
      "sudo systemctl enable api.service"
    ]
  }
  
  # Cleanup
  provisioner "shell" {
    inline = [
      "sudo apt-get clean",
      "sudo rm -rf /tmp/*"
    ]
  }
}
```

**Build and Deploy:**

```bash
# Build AMI with Packer
packer build -var="app_version=v1.2.0" packer-template.pkr.hcl

# Output: AMI ID: ami-0abc123def456

# Deploy with Terraform (immutable)
terraform apply -var="ami_id=ami-0abc123def456"

# Terraform creates NEW instances with new AMI
# Destroys old instances
# No in-place updates!
```

---

## 7. State Management

### Terraform State

```hcl
# ============================================
# Remote State Configuration
# ============================================

terraform {
  backend "s3" {
    bucket         = "myapp-terraform-state"
    key            = "production/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    
    # State locking (prevent concurrent modifications)
    dynamodb_table = "terraform-state-lock"
  }
}

# Create S3 bucket for state
resource "aws_s3_bucket" "terraform_state" {
  bucket = "myapp-terraform-state"
  
  lifecycle {
    prevent_destroy = true  # Don't accidentally delete state!
  }
}

resource "aws_s3_bucket_versioning" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  
  versioning_configuration {
    status = "Enabled"
  }
}

# DynamoDB table for locking
resource "aws_dynamodb_table" "terraform_lock" {
  name         = "terraform-state-lock"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"
  
  attribute {
    name = "LockID"
    type = "S"
  }
}
```

### State Commands

```bash
# View state
terraform state list

# Show specific resource
terraform state show aws_instance.web

# Move resource (rename)
terraform state mv aws_instance.old aws_instance.new

# Remove from state (keep resource, just untrack)
terraform state rm aws_instance.temp

# Import existing resource
terraform import aws_instance.web i-1234567890abcdef0

# Pull remote state
terraform state pull > terraform.tfstate.backup
```

---

## 8. Modules and Reusability

### Creating Terraform Modules

```hcl
# ============================================
# modules/vpc/main.tf
# ============================================

variable "vpc_cidr" {
  type = string
}

variable "project_name" {
  type = string
}

variable "environment" {
  type = string
}

resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  
  tags = {
    Name        = "${var.project_name}-${var.environment}-vpc"
    Environment = var.environment
  }
}

resource "aws_subnet" "public" {
  count                   = 2
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(var.vpc_cidr, 8, count.index)
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true
  
  tags = {
    Name = "${var.project_name}-public-${count.index + 1}"
  }
}

output "vpc_id" {
  value = aws_vpc.main.id
}

output "public_subnet_ids" {
  value = aws_subnet.public[*].id
}

# ============================================
# Using Module
# ============================================

# main.tf
module "vpc" {
  source = "./modules/vpc"
  
  vpc_cidr     = "10.0.0.0/16"
  project_name = "myapp"
  environment  = "production"
}

module "web_servers" {
  source = "./modules/ec2"
  
  vpc_id            = module.vpc.vpc_id
  subnet_ids        = module.vpc.public_subnet_ids
  instance_count    = 4
  instance_type     = "t3.medium"
}

# Modules promote reusability
# Can share modules across projects
# Terraform Registry has public modules
```

---

## 9. Testing Infrastructure Code

### Terratest (Go)

```go
// ============================================
// terraform_test.go
// ============================================

package test

import (
    "testing"
    "github.com/gruntwork-io/terratest/modules/terraform"
    "github.com/gruntwork-io/terratest/modules/aws"
    "github.com/stretchr/testify/assert"
)

func TestTerraformVPC(t *testing.T) {
    t.Parallel()
    
    // Terraform options
    terraformOptions := terraform.WithDefaultRetryableErrors(t, &terraform.Options{
        TerraformDir: "../",
        
        Vars: map[string]interface{}{
            "environment":    "test",
            "instance_count": 2,
        },
    })
    
    // Cleanup
    defer terraform.Destroy(t, terraformOptions)
    
    // Initialize and apply
    terraform.InitAndApply(t, terraformOptions)
    
    // Get outputs
    vpcId := terraform.Output(t, terraformOptions, "vpc_id")
    loadBalancerUrl := terraform.Output(t, terraformOptions, "load_balancer_url")
    
    // Validate VPC exists
    vpc := aws.GetVpcById(t, vpcId, "us-east-1")
    assert.Equal(t, "10.0.0.0/16", *vpc.CidrBlock)
    
    // Validate load balancer responds
    http_helper.HttpGetWithRetry(
        t,
        "http://" + loadBalancerUrl + "/health",
        nil,
        200,
        "OK",
        30,
        5*time.Second,
    )
}

// Run tests
// go test -v -timeout 30m
```

---

## 10. GitOps

**Definition:** Use Git as single source of truth for infrastructure and applications.

### ArgoCD (Kubernetes GitOps)

```yaml
# ============================================
# Git Repository Structure
# ============================================

myapp-gitops/
├── base/
│   ├── deployment.yaml
│   ├── service.yaml
│   └── kustomization.yaml
├── overlays/
│   ├── staging/
│   │   ├── kustomization.yaml
│   │   └── patch-replicas.yaml
│   └── production/
│       ├── kustomization.yaml
│       └── patch-replicas.yaml

# ============================================
# base/deployment.yaml
# ============================================

apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-server
spec:
  replicas: 2  # Base configuration
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
      - name: api
        image: myapp/api:v1.0.0
        ports:
        - containerPort: 3000

# ============================================
# overlays/production/kustomization.yaml
# ============================================

apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

bases:
  - ../../base

# Override for production
patchesStrategicMerge:
  - patch-replicas.yaml

images:
  - name: myapp/api
    newTag: v1.2.0  # Production version

# ============================================
# ArgoCD Application
# ============================================

apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-production
  namespace: argocd
spec:
  project: default
  
  source:
    repoURL: https://github.com/myorg/myapp-gitops
    targetRevision: main
    path: overlays/production
  
  destination:
    server: https://kubernetes.default.svc
    namespace: production
  
  syncPolicy:
    automated:
      prune: true      # Delete resources not in Git
      selfHeal: true   # Sync if cluster state drifts
      allowEmpty: false
    
    syncOptions:
      - CreateNamespace=true
    
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m

# GitOps workflow:
# 1. Developer updates Git (changes image tag)
# 2. ArgoCD detects change
# 3. ArgoCD syncs cluster to match Git
# 4. Deployment updated automatically
#
# Git = Source of Truth
# Cluster converges to Git state
```

---

## Chapter 33 Summary

### Key Concepts

1. **Infrastructure as Code** - Manage infrastructure with code
2. **Terraform** - Multi-cloud IaC tool
3. **CloudFormation** - AWS-native IaC
4. **Pulumi** - IaC with real programming languages
5. **Ansible** - Configuration management
6. **Immutable Infrastructure** - Replace, don't update
7. **State Management** - Track infrastructure state
8. **Modules** - Reusable infrastructure components
9. **GitOps** - Git as source of truth

### IaC Tools Comparison

| Tool | Language | Cloud | Best For |
|------|----------|-------|----------|
| **Terraform** | HCL | Multi-cloud | General purpose |
| **CloudFormation** | YAML/JSON | AWS only | AWS-native |
| **Pulumi** | TypeScript/Python/Go | Multi-cloud | Developers preferring real code |
| **Ansible** | YAML | Any | Configuration management |
| **CDK** | TypeScript/Python | AWS | AWS with programming |

### Benefits of IaC

**1. Consistency**
```
Same code → Same infrastructure
No configuration drift
Reproducible environments
```

**2. Speed**
```
Manual: Hours to provision
IaC: Minutes to provision
```

**3. Collaboration**
```
Code review infrastructure changes
Team visibility
Knowledge sharing
```

**4. Disaster Recovery**
```
Lost data center?
Run: terraform apply
Infrastructure rebuilt in minutes
```

### Best Practices

1. **Version control** - All IaC in Git
2. **Remote state** - Store state in S3/cloud
3. **State locking** - Prevent concurrent changes
4. **Modules** - DRY principles
5. **Environments** - Separate staging/production
6. **Plan before apply** - Review changes
7. **Automated testing** - Test infrastructure code
8. **Documentation** - Comment complex logic
9. **Secrets management** - Don't commit secrets
10. **Immutable infrastructure** - Replace, don't patch

### Interview Tips

**Common Questions:**
1. "What is Infrastructure as Code?"
2. "Terraform vs CloudFormation?"
3. "Explain immutable infrastructure"
4. "How do you manage Terraform state?"

**How to Answer:**
- Define IaC clearly (infrastructure defined in code)
- Compare tools with examples
- Explain benefits (reproducibility, speed, version control)
- Discuss state management importance
- Mention GitOps approach

### Next Steps

Chapter 34 will cover **Containerization & Orchestration** - Docker fundamentals, Kubernetes architecture, container networking, and orchestrating containers at scale.