# Chapter 4: Multi-Dimensional Greedy Problems

## 4.1 Greedy with Multiple Criteria

Problems where decisions depend on multiple attributes simultaneously - the art is choosing which criterion to prioritize.

### Pattern 1: Primary/Secondary Sort

**Problem: Queue Reconstruction by Height (LeetCode 406)**

Deep dive into why this specific ordering works.

```python
def reconstruct_queue(people):
    """
    Reconstruct queue based on two criteria:
    - people[i] = [h_i, k_i]
    - h_i = height of person i
    - k_i = number of people in front with height >= h_i
    
    Multi-Criteria Greedy Strategy:
    1. Primary: Sort by height (descending) - process tall to short
    2. Secondary: Sort by k (ascending) - smaller k values first
    3. Insert each person at index k
    
    Why this order?
    - Taller people don't affect k values of shorter people
    - When processing person with height h, all taller people already placed
    - k tells us exactly where to insert among current queue
    
    Time: O(n²) due to insertions
    Space: O(n)
    """
    # Sort: tallest first, if same height, smaller k first
    people.sort(key=lambda x: (-x[0], x[1]))
    
    print("=" * 60)
    print("MULTI-CRITERIA SORTING DEMONSTRATION")
    print("=" * 60)
    print("\nOriginal people: [height, k_value]")
    print(people)
    
    print("\nAfter sorting (tall→short, small k→large k):")
    for i, (h, k) in enumerate(people):
        print(f"  Person {i}: height={h}, k={k}")
    
    result = []
    print("\n" + "=" * 60)
    print("INSERTION PROCESS")
    print("=" * 60)
    
    for h, k in people:
        result.insert(k, [h, k])
        print(f"\nInsert [{h},{k}] at position {k}:")
        print(f"  Result: {result}")
        
        # Verify k value is correct
        taller_count = sum(1 for person in result[:result.index([h, k])] if person[0] >= h)
        print(f"  Verification: {taller_count} people >= {h} are in front ✓")
    
    print("\n" + "=" * 60)
    print(f"FINAL QUEUE: {result}")
    print("=" * 60)
    
    return result

# Detailed Example
people = [[7,0], [4,4], [7,1], [5,0], [6,1], [5,2]]
result = reconstruct_queue(people)

# Why this works - step by step proof
print("\n\nWHY THIS WORKS:")
print("-" * 60)
print("""
Key Insight: When we insert person with height h at position k,
all people already in the queue are >= h (because we sorted by height desc).

Example walkthrough:
1. Insert [7,0] at 0: [[7,0]]
   - No one taller, k=0 correct ✓

2. Insert [7,1] at 1: [[7,0], [7,1]]
   - One person (7) >= 7 in front, k=1 correct ✓

3. Insert [6,1] at 1: [[7,0], [6,1], [7,1]]
   - One person (7) >= 6 in front, k=1 correct ✓
   - The [7,1] person shifts but their k is still correct!

4. Insert [5,0] at 0: [[5,0], [7,0], [6,1], [7,1]]
   - Zero people >= 5 in front, k=0 correct ✓
   - Everyone taller shifts, but their k values remain valid!

This works because:
- Shorter people don't affect k of taller people (ignored in count)
- When we place person h, all >= h are already placed
- Position k is exactly correct among those >= h
""")
```

### Pattern 2: Ratio-Based Greedy

**Problem: Car Fleet (LeetCode 853)**

```python
def car_fleet(target, position, speed):
    """
    Cars driving to target. Car behind catches up, they form fleet (slower speed).
    Find number of fleets reaching target.
    
    Multi-Criteria:
    - Position: where car starts
    - Speed: how fast it travels
    - Time to target: position and speed combined
    
    Greedy Strategy:
    1. Sort cars by position (closest to target first)
    2. Calculate time to reach target for each
    3. If car behind is faster (reaches earlier), it forms fleet with car ahead
    
    Time: O(n log n)
    Space: O(n)
    """
    if not position:
        return 0
    
    # Create (position, time_to_target) pairs
    cars = []
    for i in range(len(position)):
        time_to_target = (target - position[i]) / speed[i]
        cars.append((position[i], time_to_target))
    
    # Sort by position (descending - closest to target first)
    cars.sort(reverse=True)
    
    print(f"Target: {target}")
    print("\nCars sorted by position (closest to target first):")
    for i, (pos, time) in enumerate(cars):
        print(f"  Car {i}: position={pos}, time_to_target={time:.2f}h")
    
    fleets = 0
    current_time = 0
    
    print("\nFleet formation:")
    for pos, time in cars:
        if time > current_time:
            # This car takes longer, forms new fleet
            fleets += 1
            current_time = time
            print(f"  Position {pos}: New fleet #{fleets} (time={time:.2f}h)")
        else:
            print(f"  Position {pos}: Catches up with fleet #{fleets}")
    
    return fleets

# Example
target = 12
position = [10, 8, 0, 5, 3]
speed = [2, 4, 1, 1, 3]

result = car_fleet(target, position, speed)
print(f"\nTotal fleets: {result}")

# Detailed analysis:
print("\n" + "=" * 60)
print("DETAILED ANALYSIS")
print("=" * 60)
cars_analysis = [
    (10, 2, 1.0),   # (target-10)/2 = 1h
    (8, 4, 1.0),    # (target-8)/4 = 1h
    (5, 1, 7.0),    # (target-5)/1 = 7h
    (3, 3, 3.0),    # (target-3)/3 = 3h
    (0, 1, 12.0),   # (target-0)/1 = 12h
]
print("\nTime to reach target 12:")
for pos, spd, time in cars_analysis:
    print(f"  Start: {pos}, Speed: {spd} → Time: {time}h")

print("\nFleet formation (process closest to target first):")
print("  Car at 10 (1h) → Fleet 1")
print("  Car at 8 (1h) → Joins Fleet 1 (same time)")
print("  Car at 5 (7h) → Fleet 2 (takes longer than Fleet 1)")
print("  Car at 3 (3h) → Joins Fleet 2 (catches up to slower fleet)")
print("  Car at 0 (12h) → Fleet 3 (takes longer than Fleet 2)")
```

### Pattern 3: Weighted Interval Scheduling

**Problem: Maximum Profit in Job Scheduling (LeetCode 1235)**

This combines intervals with profit values - pure multi-criteria challenge.

```python
def job_scheduling(start_time, end_time, profit):
    """
    Schedule jobs to maximize profit (non-overlapping).
    
    Multi-Criteria Challenge:
    - Duration: end - start
    - Profit: value of job
    - End time: when job finishes
    
    This needs DP, but greedy insight helps:
    - Sort by end time (like activity selection)
    - But must consider profit, not just count
    - Can't just take highest profit per time (counterexample exists)
    
    Time: O(n log n)
    Space: O(n)
    """
    jobs = sorted(zip(start_time, end_time, profit), key=lambda x: x[1])
    n = len(jobs)
    
    print("Jobs sorted by end time:")
    for i, (s, e, p) in enumerate(jobs):
        print(f"  Job {i}: [{s}, {e}] profit={p}, ratio={p/(e-s):.2f}")
    
    # DP approach (greedy alone doesn't work here!)
    dp = [0] * (n + 1)  # dp[i] = max profit using jobs 0..i-1
    
    print("\nDP Process (showing why pure greedy fails):")
    
    for i in range(1, n + 1):
        s, e, p = jobs[i-1]
        
        # Option 1: Don't take current job
        dp[i] = dp[i-1]
        
        # Option 2: Take current job
        # Find latest non-overlapping job
        j = i - 1
        while j > 0 and jobs[j-1][1] > s:
            j -= 1
        
        take_profit = dp[j] + p
        dp[i] = max(dp[i], take_profit)
        
        print(f"  Job {i-1} [{s},{e}] p={p}: skip={dp[i-1]}, take={take_profit} → dp[{i}]={dp[i]}")
    
    return dp[n]

# Example showing greedy failure
start = [1, 2, 3, 3]
end = [3, 4, 5, 6]
profit = [50, 10, 40, 70]

result = job_scheduling(start, end, profit)
print(f"\nMaximum profit: {result}")

print("\n" + "=" * 60)
print("WHY PURE GREEDY FAILS")
print("=" * 60)
print("""
Greedy by end time: Take [1,3] p=50, then [3,5] p=40 → profit=90
Greedy by profit: Take [3,6] p=70 alone → profit=70
Greedy by ratio: Take [1,3] p=50, ratio=25 → profit=50

Optimal (DP): Take [1,3] p=50, then [3,6] p=70 → profit=120

The problem has optimal substructure but NOT greedy choice property!
Each choice affects future possibilities in complex ways.
Need DP to consider all combinations.
""")
```

---

## 4.2 Greedy on Graphs

Graphs add spatial relationships to greedy decisions. Classic algorithms like Dijkstra and Kruskal are greedy!

### Pattern 1: Minimum Spanning Tree (Kruskal's Algorithm)

```python
class UnionFind:
    def __init__(self, n):
        self.parent = list(range(n))
        self.rank = [0] * n
    
    def find(self, x):
        if self.parent[x] != x:
            self.parent[x] = self.find(self.parent[x])
        return self.parent[x]
    
    def union(self, x, y):
        px, py = self.find(x), self.find(y)
        if px == py:
            return False
        if self.rank[px] < self.rank[py]:
            px, py = py, px
        self.parent[py] = px
        if self.rank[px] == self.rank[py]:
            self.rank[px] += 1
        return True

def min_cost_connect_points(points):
    """
    Connect all points with minimum total cost (Manhattan distance).
    
    Greedy Strategy (Kruskal's MST):
    1. Generate all edges with costs
    2. Sort edges by cost (ascending)
    3. Greedily add edge if it connects different components
    4. Stop when all points connected
    
    Time: O(n² log n) - n² edges, sort them
    Space: O(n²)
    """
    n = len(points)
    
    # Generate all edges with costs
    edges = []
    for i in range(n):
        for j in range(i + 1, n):
            cost = abs(points[i][0] - points[j][0]) + abs(points[i][1] - points[j][1])
            edges.append((cost, i, j))
    
    # Sort by cost (greedy choice: add cheapest edge possible)
    edges.sort()
    
    print(f"Total points: {n}")
    print(f"Total possible edges: {len(edges)}")
    print(f"\nTop 10 cheapest edges:")
    for i, (cost, u, v) in enumerate(edges[:10]):
        print(f"  Edge {i}: {u}↔{v}, cost={cost}")
    
    # Use Union-Find to detect cycles
    uf = UnionFind(n)
    total_cost = 0
    edges_used = 0
    
    print(f"\n" + "=" * 60)
    print("MST CONSTRUCTION (Kruskal's Algorithm)")
    print("=" * 60)
    
    for cost, u, v in edges:
        # Greedy: try to add this edge
        if uf.union(u, v):
            total_cost += cost
            edges_used += 1
            print(f"Add edge {u}↔{v}, cost={cost}, total={total_cost}")
            
            if edges_used == n - 1:
                print(f"\nMST complete! Used {edges_used} edges for {n} points.")
                break
        else:
            print(f"Skip edge {u}↔{v}, cost={cost} (would create cycle)")
    
    return total_cost

# Example
points = [[0,0], [2,2], [3,10], [5,2], [7,0]]
result = min_cost_connect_points(points)
print(f"\nMinimum cost to connect all points: {result}")

print("\n" + "=" * 60)
print("WHY GREEDY WORKS FOR MST")
print("=" * 60)
print("""
Proof (Cut Property):

Consider any cut (partition of vertices into two sets S and T).
Let e be the minimum weight edge crossing the cut.

Claim: e is in some MST.

Proof by exchange:
1. Suppose MST M doesn't contain e
2. M must have some path from S to T (it's a spanning tree)
3. This path must cross the cut with some edge e'
4. Remove e' and add e
5. Cost decrease: weight(e') ≥ weight(e) (e is minimum crossing cut)
6. Still connected (e connects what e' disconnected)
7. Therefore, M' = M - e' + e is also an MST

Kruskal's algorithm always picks minimum weight edge that doesn't create cycle.
This is equivalent to picking minimum edge crossing some cut.
By cut property, this edge is in some MST.
By induction, Kruskal's produces an MST.
""")
```

### Pattern 2: Shortest Path (Dijkstra's Algorithm)

```python
import heapq

def network_delay_time(times, n, k):
    """
    Find time for signal to reach all nodes from node k.
    
    Greedy Strategy (Dijkstra):
    1. Start from source k
    2. Always explore nearest unvisited node
    3. Update distances to neighbors
    4. Repeat until all reachable nodes visited
    
    Works only with non-negative edge weights!
    
    Time: O(E log V)
    Space: O(V + E)
    """
    # Build adjacency list
    graph = {i: [] for i in range(1, n + 1)}
    for u, v, w in times:
        graph[u].append((v, w))
    
    print(f"Graph adjacency list:")
    for node in sorted(graph.keys()):
        print(f"  {node} → {graph[node]}")
    
    # Dijkstra's algorithm
    distances = {i: float('inf') for i in range(1, n + 1)}
    distances[k] = 0
    
    # Min-heap: (distance, node)
    heap = [(0, k)]
    visited = set()
    
    print(f"\n" + "=" * 60)
    print(f"DIJKSTRA'S ALGORITHM (Start from node {k})")
    print("=" * 60)
    
    while heap:
        dist, node = heapq.heappop(heap)
        
        if node in visited:
            continue
        
        visited.add(node)
        print(f"\nVisit node {node} (distance={dist})")
        
        # Explore neighbors
        for neighbor, weight in graph[node]:
            new_dist = dist + weight
            
            if new_dist < distances[neighbor]:
                distances[neighbor] = new_dist
                heapq.heappush(heap, (new_dist, neighbor))
                print(f"  Update {neighbor}: distance={new_dist}")
            else:
                print(f"  Skip {neighbor}: new_dist={new_dist} >= current={distances[neighbor]}")
    
    print(f"\n" + "=" * 60)
    print("FINAL DISTANCES")
    print("=" * 60)
    for node in sorted(distances.keys()):
        dist_str = str(distances[node]) if distances[node] != float('inf') else "∞"
        print(f"  Node {node}: {dist_str}")
    
    max_dist = max(distances.values())
    return max_dist if max_dist != float('inf') else -1

# Example
times = [[2,1,1], [2,3,1], [3,4,1]]
n = 4
k = 2

result = network_delay_time(times, n, k)
print(f"\nTime to reach all nodes: {result}")

print("\n" + "=" * 60)
print("WHY DIJKSTRA'S IS GREEDY")
print("=" * 60)
print("""
Greedy Choice: Always explore nearest unvisited node.

Why this works (with non-negative weights):

1. When we visit node v with distance d, d is optimal
   Proof: Suppose shorter path exists through unvisited node u
   → Distance to u > d (else u would be visited first)
   → Path through u to v has cost > d (non-negative weights)
   → Contradiction! So d is optimal for v

2. Once a node is visited, its distance never changes
   → Greedy choice is final
   → This is the greedy choice property!

3. With negative weights, this fails:
   Example: A→B: 1, A→C: 100, C→B: -200
   Greedy visits B first (dist=1)
   But path A→C→B has cost -100 (better!)
""")
```

### Pattern 3: Modified Dijkstra for Probability

**LeetCode 1514: Path with Maximum Probability**

```python
import heapq

def max_probability(n, edges, succ_prob, start, end):
    """
    Find path with maximum probability from start to end.
    
    Greedy Modification:
    - Use max-heap instead of min-heap
    - Multiply probabilities instead of adding distances
    - Everything else similar to Dijkstra
    
    Time: O(E log V)
    Space: O(V + E)
    """
    # Build graph
    graph = {i: [] for i in range(n)}
    for i, (u, v) in enumerate(edges):
        prob = succ_prob[i]
        graph[u].append((v, prob))
        graph[v].append((u, prob))
    
    # Max-heap: (negative_probability, node) - negate for max behavior
    max_prob = [0.0] * n
    max_prob[start] = 1.0
    heap = [(-1.0, start)]
    
    print(f"Finding path from {start} to {end}")
    print(f"\nGraph structure:")
    for node in sorted(graph.keys()):
        if graph[node]:
            print(f"  {node} → {graph[node]}")
    
    print(f"\n" + "=" * 60)
    print("MODIFIED DIJKSTRA FOR PROBABILITY")
    print("=" * 60)
    
    while heap:
        prob, node = heapq.heappop(heap)
        prob = -prob  # Convert back to positive
        
        print(f"\nVisit node {node} (probability={prob:.4f})")
        
        if node == end:
            print(f"→ Reached destination!")
            return prob
        
        if prob < max_prob[node]:
            print(f"  Skip (already have better path)")
            continue
        
        for neighbor, edge_prob in graph[node]:
            new_prob = prob * edge_prob
            
            if new_prob > max_prob[neighbor]:
                max_prob[neighbor] = new_prob
                heapq.heappush(heap, (-new_prob, neighbor))
                print(f"  Update {neighbor}: prob={new_prob:.4f}")
    
    return 0.0

# Example
n = 3
edges = [[0,1], [1,2], [0,2]]
succ_prob = [0.5, 0.5, 0.2]
start = 0
end = 2

result = max_probability(n, edges, succ_prob, start, end)
print(f"\nMaximum probability: {result:.4f}")

print("\nPath analysis:")
print("  Direct: 0→2 probability = 0.2")
print("  Indirect: 0→1→2 probability = 0.5 × 0.5 = 0.25")
print("  Best path: 0→1→2 with probability 0.25")
```

---

## 4.3 Greedy with Constraints

Constraints add complexity - greedy choice must respect limits.

### Pattern: Reorganize String (Frequency + Adjacency Constraint)

**LeetCode 767: Reorganize String**

```python
from collections import Counter
import heapq

def reorganize_string(s):
    """
    Rearrange string so no two adjacent characters are same.
    
    Constraints:
    - Can't place same character consecutively
    - Must use all characters
    
    Greedy Strategy:
    1. Use character with highest frequency
    2. But respect adjacency constraint
    3. Use second-most frequent if necessary
    
    Time: O(n log k) where k = unique characters
    Space: O(k)
    """
    # Count frequencies
    freq = Counter(s)
    
    # Check if possible
    max_freq = max(freq.values())
    if max_freq > (len(s) + 1) // 2:
        print(f"Impossible: max frequency {max_freq} > {(len(s) + 1) // 2}")
        return ""
    
    # Max heap of (frequency, character)
    heap = [(-count, char) for char, count in freq.items()]
    heapq.heapify(heap)
    
    result = []
    prev_count, prev_char = 0, ''
    
    print(f"Input: {s}")
    print(f"Frequencies: {dict(freq)}")
    print(f"\n" + "=" * 60)
    print("GREEDY REORGANIZATION")
    print("=" * 60)
    
    while heap:
        # Get most frequent available character
        count, char = heapq.heappop(heap)
        count = -count
        
        result.append(char)
        print(f"\nStep {len(result)}: Add '{char}' (freq={count})")
        print(f"  Result so far: {''.join(result)}")
        
        # Add back previous character if it has remaining count
        if prev_count < 0:
            heapq.heappush(heap, (prev_count, prev_char))
            print(f"  Add back '{prev_char}' (freq={-prev_count}) to heap")
        
        # Save current for next iteration
        prev_count = -(count - 1) if count > 1 else 0
        prev_char = char
        
        if prev_count < 0:
            print(f"  Save '{prev_char}' (freq={-prev_count}) for next iteration")
    
    return ''.join(result)

# Example
s = "aab"
result = reorganize_string(s)
print(f"\n" + "=" * 60)
print(f"Original: {s}")
print(f"Reorganized: {result}")
print("=" * 60)

# More complex example
s2 = "aaab"
print(f"\n\nTrying: {s2}")
result2 = reorganize_string(s2)
if result2:
    print(f"Result: {result2}")
else:
    print("Impossible to reorganize!")

print("\n" + "=" * 60)
print("WHY THIS GREEDY WORKS")
print("=" * 60)
print("""
Key Insights:

1. If max frequency > ⌈n/2⌉, impossible
   Example: "aaab" → max_freq(a)=3 > ⌈4/2⌉=2
   Need at least 3 positions for 'a', but only 2 non-adjacent positions

2. Always use most frequent character (when possible)
   Why? Spreads out high-frequency characters early
   Avoids getting stuck with too many of one character

3. Alternate between two most frequent
   Creates maximum spacing between same characters

4. Save one occurrence for next round
   Ensures we can always alternate
""")
```

---

## Summary: Multi-Dimensional Decision Making

```python
# Framework for multi-criteria problems:

def solve_multi_criteria_problem(problem_description):
    """
    Step-by-step approach for multiple criteria
    """
    
    steps = """
    1. IDENTIFY ALL CRITERIA
       - What attributes affect the decision?
       - Which are primary vs secondary?
    
    2. DETERMINE SORTING ORDER
       - Try different sort orders
       - Test with examples
       - Look for counterexamples
    
    3. HANDLE CONSTRAINTS
       - What rules must be satisfied?
       - How do constraints affect greedy choice?
    
    4. VERIFY GREEDY CHOICE PROPERTY
       - Can you prove local optimal → global optimal?
       - Are there interdependencies that break greedy?
    
    5. CHOOSE DATA STRUCTURES
       - Heap for dynamic "best" element
       - Union-Find for graph connectivity
       - Stack for maintaining order
    """
    
    return steps

# Common multi-criteria patterns:
MULTI_PATTERNS = {
    "Sort Primary + Secondary": ["Queue reconstruction", "Job scheduling"],
    "Ratio-based": ["Fractional knapsack", "Car fleet"],
    "Graph + Value": ["MST", "Shortest path with cost"],
    "Frequency + Constraint": ["Reorganize string", "Task scheduler"],
}
```

### Practice Problems for Chapter 4

1. **Medium**: Queue Reconstruction by Height (LC 406)
2. **Hard**: Maximum Profit in Job Scheduling (LC 1235)
3. **Medium**: Min Cost to Connect All Points (LC 1584)
4. **Medium**: Network Delay Time (LC 743)
5. **Medium**: Path with Maximum Probability (LC 1514)
6. **Medium**: Reorganize String (LC 767)
7. **Medium**: Car Fleet (LC 853)

Master multi-dimensional thinking - it's what separates good from great!