# Chapter 18: Time & Space Complexity Summary - Complete Analysis

## Overview
Understanding complexity is crucial for:
- Choosing the right algorithm
- Optimizing solutions
- Discussing trade-offs in interviews
- Passing system design requirements

---

## 18.1 Common Operations Complexity

### Binary Search Tree (BST)

| Operation | Average Case | Worst Case | Best Case |
|-----------|--------------|------------|-----------|
| **Search** | O(log n) | O(n) | O(1) |
| **Insert** | O(log n) | O(n) | O(1) |
| **Delete** | O(log n) | O(n) | O(1) |
| **Find Min/Max** | O(log n) | O(n) | O(1) |
| **Inorder Successor** | O(log n) | O(n) | O(1) |
| **Space** | O(n) | O(n) | O(n) |

**Explanation**:

**Average Case (Balanced Tree)**:
```python
def search(root, key):
    """
    Each comparison eliminates ~half the tree.
    Time: O(log n)
    """
    while root:
        if key == root.val:
            return root
        elif key < root.val:
            root = root.left
        else:
            root = root.right
    return None
```

**Worst Case (Skewed Tree)**:
```
Becomes a linked list:
1
 \
  2
   \
    3
     \
      4
Time: O(n) for search
```

**Why This Matters**: Always ask if tree is balanced in interviews!

---

### Self-Balancing Trees (AVL, Red-Black)

| Operation | Time Complexity | Notes |
|-----------|-----------------|-------|
| **Search** | O(log n) | Guaranteed |
| **Insert** | O(log n) | Includes rebalancing |
| **Delete** | O(log n) | Includes rebalancing |
| **Find Min/Max** | O(log n) | - |
| **Range Query** | O(log n + k) | k = result size |

**Height Bounds**:
- AVL: Height ≤ 1.44 × log₂(n)
- Red-Black: Height ≤ 2 × log₂(n)

**Code Example**:
```python
def avl_insert(root, key):
    """
    Standard BST insert + O(1) rotations
    Total: O(log n)
    """
    # BST insert: O(log n)
    node = bst_insert(root, key)
    
    # Update heights: O(log n)
    update_heights(node)
    
    # Rebalance: O(1) rotations × O(log n) path
    rebalance(node)
    
    return root
```

---

### Heap (Priority Queue)

| Operation | Time Complexity | Space | Notes |
|-----------|-----------------|-------|-------|
| **Insert** | O(log n) | O(n) | Heapify up |
| **Extract Min/Max** | O(log n) | O(n) | Heapify down |
| **Peek Min/Max** | O(1) | O(n) | - |
| **Build Heap** | **O(n)** | O(n) | Bottom-up |
| **Decrease Key** | O(log n) | - | Update + heapify |
| **Delete** | O(log n) | - | Replace + heapify |

**Critical Understanding**:

**Why Build Heap is O(n) NOT O(n log n)**:

```python
def build_heap(arr):
    """
    Start from last non-leaf, heapify down.
    
    Analysis:
    - Leaves (n/2): 0 operations
    - Next level (n/4): 1 operation each
    - Next level (n/8): 2 operations each
    - ...
    - Root: log n operations
    
    Total = n/4×1 + n/8×2 + n/16×3 + ... = O(n)
    """
    n = len(arr)
    
    # Start from last non-leaf
    for i in range(n // 2 - 1, -1, -1):
        heapify_down(arr, i, n)
```

**Mathematical Proof**:
```
Sum = Σ(i=0 to log n) [(n / 2^(i+1)) × i]
    = n × Σ(i=1 to ∞) [i / 2^i]
    = n × 2
    = O(n)
```

---

### Trie (Prefix Tree)

| Operation | Time Complexity | Space | Notes |
|-----------|-----------------|-------|-------|
| **Insert** | O(L) | O(L×N×Σ) | L=word length |
| **Search** | O(L) | - | L=word length |
| **Delete** | O(L) | - | L=word length |
| **Prefix Search** | O(L + K) | - | K=matches |
| **Space Total** | O(N×L×Σ) | - | N=words, Σ=alphabet size |

**Code Example**:
```python
class TrieNode:
    def __init__(self):
        self.children = {}  # O(Σ) space per node
        self.is_end = False

class Trie:
    def insert(self, word):
        """
        Time: O(L) - visit each character once
        Space: O(L) - worst case, all new nodes
        """
        node = self.root
        for char in word:  # L iterations
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.is_end = True
```

**Space Optimization**:
- Compressed Trie (Radix Tree): O(N) nodes instead of O(N×L)
- Array vs HashMap: Trade space for speed

---

## 18.2 Traversal Complexities

### Recursive Traversals

| Traversal | Time | Space (Call Stack) | Notes |
|-----------|------|-------------------|-------|
| **Preorder** | O(n) | O(h) | Best: O(log n), Worst: O(n) |
| **Inorder** | O(n) | O(h) | Best: O(log n), Worst: O(n) |
| **Postorder** | O(n) | O(h) | Best: O(log n), Worst: O(n) |

**Code Analysis**:
```python
def inorder(root):
    """
    Time: O(n) - visit each node once
    Space: O(h) - maximum call stack depth
    
    Balanced tree: h = log n → O(log n) space
    Skewed tree: h = n → O(n) space
    """
    if not root:
        return
    
    inorder(root.left)   # Recurse left
    process(root)         # O(1) work
    inorder(root.right)  # Recurse right
```

**Recurrence Relation**:
```
T(n) = T(left) + T(right) + O(1)
     = T(n-1) + O(1)           [worst case: skewed]
     = O(n)

T(n) = 2T(n/2) + O(1)          [best case: balanced]
     = O(n)                     [by Master theorem]
```

---

### Iterative Traversals

| Traversal | Time | Space (Stack) | Notes |
|-----------|------|---------------|-------|
| **Preorder** | O(n) | O(h) | Stack holds path |
| **Inorder** | O(n) | O(h) | Stack holds path |
| **Postorder** | O(n) | O(h) | May need 2 stacks |

```python
def inorder_iterative(root):
    """
    Space: O(h) for explicit stack
    Same as recursive space complexity
    """
    stack = []
    current = root
    
    while current or stack:
        # Go left: push path onto stack
        while current:
            stack.append(current)  # O(h) space
            current = current.left
        
        current = stack.pop()
        process(current)
        current = current.right
    
    # Maximum stack size = height of tree
```

---

### BFS (Level Order)

| Aspect | Complexity | Notes |
|--------|------------|-------|
| **Time** | O(n) | Visit each node once |
| **Space** | O(w) | w = maximum width |

**Width Analysis**:
```
Perfect binary tree:
   Level 0: 1 node     (2^0)
   Level 1: 2 nodes    (2^1)
   Level 2: 4 nodes    (2^2)
   ...
   Level h: 2^h nodes

Max width = 2^h ≈ n/2 for last level

Space: O(2^h) = O(n/2) = O(n) worst case
```

**Code**:
```python
def bfs(root):
    """
    Space: O(w) where w is maximum width
    
    Best case (skewed): O(1) - one node per level
    Worst case (perfect): O(n/2) - last level
    Average case: O(n/2) for balanced tree
    """
    queue = deque([root])
    
    while queue:
        # Queue holds entire level
        level_size = len(queue)  # Up to O(n/2)
        
        for _ in range(level_size):
            node = queue.popleft()
            process(node)
            
            if node.left:
                queue.append(node.left)
            if node.right:
                queue.append(node.right)
```

---

### Morris Traversal

| Aspect | Complexity | Notes |
|--------|------------|-------|
| **Time** | O(n) | Each edge visited ≤ 3 times |
| **Space** | **O(1)** | No stack/queue! |

**Why O(1) Space?**
```python
def morris_inorder(root):
    """
    Use threaded binary tree concept.
    Temporarily modify tree, then restore.
    
    Time: O(n) even though nested loops
    - Each edge traversed at most 3 times
    - Total: 3n edges → O(n)
    
    Space: O(1) - only pointers, no stack
    """
    current = root
    
    while current:
        if not current.left:
            process(current)
            current = current.right
        else:
            # Find predecessor
            pred = current.left
            while pred.right and pred.right != current:
                pred = pred.right
            
            if not pred.right:
                pred.right = current  # Create thread
                current = current.left
            else:
                pred.right = None     # Remove thread
                process(current)
                current = current.right
```

---

## 18.3 Advanced Data Structures

### Segment Tree

| Operation | Time | Space | Notes |
|-----------|------|-------|-------|
| **Build** | O(n) | O(4n) ≈ O(n) | Bottom-up construction |
| **Query** | O(log n) | - | Split into log n ranges |
| **Update** | O(log n) | - | Update log n nodes |
| **Range Update** | O(log n) | O(n) | With lazy propagation |

**Build Complexity Proof**:
```python
def build(arr):
    """
    Tree levels:
    - Leaves: n nodes
    - Level above: n/2 nodes
    - Level above: n/4 nodes
    - ...
    - Root: 1 node
    
    Total = n + n/2 + n/4 + ... + 1
          = n × (1 + 1/2 + 1/4 + ...)
          = n × 2
          = O(n)
    """
    pass
```

**Query Complexity**:
```python
def query(node, start, end, L, R):
    """
    At each level, visit ≤ 4 nodes
    Total levels = log n
    Time: O(4 × log n) = O(log n)
    
    Why ≤ 4 nodes per level?
    - 2 nodes where range starts
    - 2 nodes where range ends
    - Complete overlap nodes (free)
    """
    pass
```

---

### Fenwick Tree (Binary Indexed Tree)

| Operation | Time | Space | Notes |
|-----------|------|-------|-------|
| **Build** | O(n log n) naive | O(n) | O(n) possible with optimization |
| **Update** | O(log n) | - | Follow parent links |
| **Prefix Sum** | O(log n) | - | Follow parent links |
| **Range Query** | O(log n) | - | Two prefix sums |

**Why O(log n)?**
```python
def update(i, delta):
    """
    Update i and all ancestors.
    
    Number of ancestors = number of 1-bits in path
    Maximum = log n (binary representation length)
    
    Example: i = 12 = 1100₂
    Updates: 12 → 16 → 32 → ...
    Count: log n steps
    """
    while i <= n:
        bit[i] += delta
        i += i & (-i)  # Add LSB
```

---

## 18.4 Space Complexity Deep Dive

### Recursive vs Iterative Space

**Recursive**:
```python
def height(node):
    """
    Space = Call stack depth = O(h)
    
    Each call stores:
    - Return address
    - Local variables
    - Parameters
    
    Total: O(h) × (constant per call)
    """
    if not node:
        return 0
    return 1 + max(height(node.left), height(node.right))
```

**Iterative**:
```python
def height_iterative(node):
    """
    Space = Explicit stack size = O(h)
    
    Same complexity as recursive,
    but more control over stack size
    """
    stack = [(node, 0)]
    max_height = 0
    
    while stack:
        node, h = stack.pop()
        max_height = max(max_height, h)
        
        if node.left:
            stack.append((node.left, h + 1))
        if node.right:
            stack.append((node.right, h + 1))
    
    return max_height
```

---

### Auxiliary Space vs Total Space

**Auxiliary Space**: Extra space beyond input
**Total Space**: Input + Auxiliary

```python
def inorder(root):
    """
    Input space: O(n) for tree
    Auxiliary space: O(h) for call stack
    Total space: O(n + h) ≈ O(n)
    
    In interviews, usually discuss auxiliary space
    """
    result = []  # Auxiliary: O(n) for output
    
    def dfs(node):  # Auxiliary: O(h) for stack
        if not node:
            return
        dfs(node.left)
        result.append(node.val)
        dfs(node.right)
    
    dfs(root)
    return result
```

---

## 18.5 Complexity Comparison Table

### Search Operations

| Structure | Search | Insert | Delete | Space |
|-----------|--------|--------|--------|-------|
| Unsorted Array | O(n) | O(1) | O(n) | O(n) |
| Sorted Array | O(log n) | O(n) | O(n) | O(n) |
| Linked List | O(n) | O(1) | O(n) | O(n) |
| BST (balanced) | O(log n) | O(log n) | O(log n) | O(n) |
| BST (skewed) | O(n) | O(n) | O(n) | O(n) |
| Hash Table | O(1) avg | O(1) avg | O(1) avg | O(n) |
| Trie | O(L) | O(L) | O(L) | O(N×L×Σ) |

---

### Range Query Structures

| Structure | Build | Point Update | Range Query | Range Update |
|-----------|-------|--------------|-------------|--------------|
| Prefix Sum | O(n) | O(n) | O(1) | O(n) |
| Segment Tree | O(n) | O(log n) | O(log n) | O(log n)* |
| Fenwick Tree | O(n log n) | O(log n) | O(log n) | - |
| Sparse Table | O(n log n) | - | O(1) | - |
| Square Root | O(n) | O(1) | O(√n) | O(√n) |

*With lazy propagation

---

## 18.6 Interview Complexity Checklist

### What to Analyze

1. **Time Complexity**:
   - Best case
   - Average case
   - Worst case

2. **Space Complexity**:
   - Auxiliary space
   - Call stack (recursion)
   - Additional structures (HashMap, etc.)

3. **Trade-offs**:
   - Time vs Space
   - Average vs Worst case
   - Preprocessing vs Query

### Common Optimizations

| From | To | Technique |
|------|----|-----------| 
| O(n²) | O(n log n) | Sorting, BST |
| O(n²) | O(n) | HashMap |
| O(n log n) | O(n) | Counting sort, Radix sort |
| O(n) space | O(log n) | Iterative instead of BFS |
| O(log n) space | O(1) | Morris traversal |

---

## 18.7 Practice Problems by Complexity

### O(n) Linear Time
- Tree traversals (all types)
- Find maximum/minimum
- Count nodes
- Sum of all nodes

### O(n log n) Time
- Build balanced BST from sorted array
- Vertical order traversal (with sorting)
- Merge K sorted lists

### O(log n) Time (per operation)
- BST search
- Segment tree query
- Binary lifting LCA

### O(1) Space
- Morris traversal
- Iterative with constant pointers

### O(n²) Time (Avoid if possible!)
- Construct tree from traversals (without HashMap)
- Check all pairs of nodes

Remember: In interviews, always discuss complexity even if not asked explicitly!