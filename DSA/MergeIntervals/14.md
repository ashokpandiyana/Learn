# Chapter 14: Real-World Applications & Mastery

## 14.1 Industry Applications

### Application 1: Calendar & Scheduling Systems

**Real-World System:** Google Calendar, Outlook Calendar

**Core Problems:**
1. Conflict detection when booking meetings
2. Finding available time slots across multiple calendars
3. Recurring events management
4. Resource (room) allocation

**Production Implementation:**

```python
class CalendarSystem:
    """
    Production-grade calendar system
    Handles millions of events efficiently
    """
    
    def __init__(self):
        # User ID -> sorted list of events
        self.user_calendars = {}
        
        # Room ID -> sorted list of bookings
        self.room_calendars = {}
        
        # Event ID -> Event details
        self.events = {}
    
    def book_meeting(self, organizer_id, attendee_ids, start, end, 
                     room_id=None, title="Meeting"):
        """
        Book a meeting with conflict detection
        
        Returns: (success, event_id or error_message)
        """
        # Check organizer availability
        if not self._is_available(organizer_id, start, end):
            return (False, f"Organizer {organizer_id} has conflict")
        
        # Check all attendees availability
        for attendee_id in attendee_ids:
            if not self._is_available(attendee_id, start, end):
                return (False, f"Attendee {attendee_id} has conflict")
        
        # Check room availability
        if room_id:
            if not self._is_room_available(room_id, start, end):
                return (False, f"Room {room_id} is not available")
        
        # Create event
        event_id = self._generate_event_id()
        event = {
            'id': event_id,
            'title': title,
            'start': start,
            'end': end,
            'organizer': organizer_id,
            'attendees': attendee_ids,
            'room': room_id
        }
        
        self.events[event_id] = event
        
        # Add to all calendars
        self._add_to_calendar(organizer_id, start, end, event_id)
        for attendee_id in attendee_ids:
            self._add_to_calendar(attendee_id, start, end, event_id)
        
        if room_id:
            self._add_to_room_calendar(room_id, start, end, event_id)
        
        return (True, event_id)
    
    def find_available_slots(self, user_ids, duration, 
                            start_search, end_search):
        """
        Find time slots when all users are available
        
        Real-world optimization: Use caching, incremental updates
        
        Time: O(n log n) where n = total events in search window
        """
        # Get all busy times for all users
        all_busy = []
        
        for user_id in user_ids:
            user_events = self._get_events_in_range(
                user_id, start_search, end_search
            )
            all_busy.extend(user_events)
        
        # Sort and merge overlapping busy times
        all_busy.sort()
        merged_busy = self._merge_intervals(all_busy)
        
        # Find gaps that fit duration
        available_slots = []
        current_time = start_search
        
        for busy_start, busy_end in merged_busy:
            if current_time < busy_start:
                # Gap found
                gap_duration = busy_start - current_time
                if gap_duration >= duration:
                    available_slots.append([current_time, busy_start])
            current_time = max(current_time, busy_end)
        
        # Check final gap
        if current_time < end_search:
            if end_search - current_time >= duration:
                available_slots.append([current_time, end_search])
        
        return available_slots
    
    def suggest_meeting_times(self, user_ids, duration, 
                             preferences=None):
        """
        AI-powered meeting time suggestions
        
        Real-world: Use ML models trained on:
        - Historical meeting patterns
        - User preferences
        - Time zones
        - Work hours
        """
        # Simple version: Find slots and rank by preferences
        
        # Default preferences
        if not preferences:
            preferences = {
                'preferred_hours': (9, 17),  # 9 AM - 5 PM
                'avoid_lunch': (12, 13),     # Noon - 1 PM
                'buffer_time': 15             # 15 min between meetings
            }
        
        # Find available slots for next 2 weeks
        import time
        now = int(time.time())
        two_weeks = now + (14 * 24 * 60 * 60)
        
        slots = self.find_available_slots(user_ids, duration, now, two_weeks)
        
        # Rank slots
        ranked_slots = self._rank_slots(slots, preferences)
        
        return ranked_slots[:5]  # Top 5 suggestions
    
    def _is_available(self, user_id, start, end):
        """Check if user has no conflicts"""
        if user_id not in self.user_calendars:
            return True
        
        events = self.user_calendars[user_id]
        
        # Binary search for potentially conflicting events
        # In production: use interval tree for O(log n) query
        for event_start, event_end, _ in events:
            if not (end <= event_start or start >= event_end):
                return False
        
        return True
    
    def _is_room_available(self, room_id, start, end):
        """Check if room is available"""
        if room_id not in self.room_calendars:
            return True
        
        bookings = self.room_calendars[room_id]
        for booking_start, booking_end, _ in bookings:
            if not (end <= booking_start or start >= booking_end):
                return False
        
        return True
    
    def _merge_intervals(self, intervals):
        """Merge overlapping intervals"""
        if not intervals:
            return []
        
        intervals.sort()
        merged = [intervals[0]]
        
        for current in intervals[1:]:
            last = merged[-1]
            if current[0] <= last[1]:
                last[1] = max(last[1], current[1])
            else:
                merged.append(current)
        
        return merged
    
    def _rank_slots(self, slots, preferences):
        """Rank slots by preferences"""
        scored_slots = []
        
        for start, end in slots:
            score = 0
            
            # Prefer slots in work hours
            start_hour = (start % (24 * 3600)) // 3600
            if preferences['preferred_hours'][0] <= start_hour <= preferences['preferred_hours'][1]:
                score += 10
            
            # Avoid lunch time
            if not (preferences['avoid_lunch'][0] <= start_hour <= preferences['avoid_lunch'][1]):
                score += 5
            
            # Prefer earlier slots
            score -= start // (24 * 3600)  # Days from now
            
            scored_slots.append((score, [start, end]))
        
        scored_slots.sort(reverse=True)
        return [slot for _, slot in scored_slots]
    
    def _add_to_calendar(self, user_id, start, end, event_id):
        """Add event to user calendar"""
        if user_id not in self.user_calendars:
            self.user_calendars[user_id] = []
        self.user_calendars[user_id].append([start, end, event_id])
        self.user_calendars[user_id].sort()
    
    def _add_to_room_calendar(self, room_id, start, end, event_id):
        """Add booking to room calendar"""
        if room_id not in self.room_calendars:
            self.room_calendars[room_id] = []
        self.room_calendars[room_id].append([start, end, event_id])
        self.room_calendars[room_id].sort()
    
    def _get_events_in_range(self, user_id, start, end):
        """Get all events for user in time range"""
        if user_id not in self.user_calendars:
            return []
        
        events = []
        for event_start, event_end, event_id in self.user_calendars[user_id]:
            if not (event_end <= start or event_start >= end):
                events.append([event_start, event_end])
        
        return events
    
    def _generate_event_id(self):
        """Generate unique event ID"""
        import random
        return f"event_{random.randint(1000000, 9999999)}"


# Demo
def demo_calendar_system():
    """Demonstrate calendar system"""
    print("="*60)
    print("REAL-WORLD APPLICATION: Calendar System")
    print("="*60)
    
    cal = CalendarSystem()
    
    # Simulate booking meetings
    print("\n1. Book meeting: Alice + Bob, 9:00-10:00")
    success, result = cal.book_meeting(
        organizer_id="alice",
        attendee_ids=["bob"],
        start=9 * 3600,   # 9 AM
        end=10 * 3600,    # 10 AM
        title="Project Sync"
    )
    print(f"   Result: {success}, Event ID: {result}")
    
    print("\n2. Try to book conflicting meeting: Alice, 9:30-10:30")
    success, result = cal.book_meeting(
        organizer_id="alice",
        attendee_ids=[],
        start=9.5 * 3600,
        end=10.5 * 3600,
        title="Team Meeting"
    )
    print(f"   Result: {success}, Reason: {result}")
    
    print("\n3. Find available slots for Alice + Bob (1 hour)")
    slots = cal.find_available_slots(
        user_ids=["alice", "bob"],
        duration=3600,
        start_search=0,
        end_search=24 * 3600
    )
    print(f"   Available slots: {len(slots)}")
    for slot in slots[:3]:
        start_hour = slot[0] // 3600
        end_hour = slot[1] // 3600
        print(f"     {start_hour:02d}:00 - {end_hour:02d}:00")

demo_calendar_system()
```

**Production Optimizations:**
1. **Interval Trees** for O(log n) conflict detection
2. **Caching** frequently accessed calendars
3. **Sharding** by user ID for horizontal scaling
4. **Async processing** for large meeting invitations
5. **Machine Learning** for smart suggestions

---

### Application 2: Cloud Resource Management

**Real-World System:** AWS Auto-scaling, Kubernetes Resource Scheduler

**Core Problems:**
1. Allocate minimum servers for traffic patterns
2. Schedule batch jobs without conflicts
3. Optimize resource utilization

**Production Implementation:**

```python
class CloudResourceScheduler:
    """
    Schedule tasks on cloud instances
    Minimize cost while meeting SLAs
    """
    
    def __init__(self, instance_cost_per_hour):
        self.instance_cost = instance_cost_per_hour
        self.tasks = []
        self.schedule = []
    
    def add_task(self, task_id, start_time, duration, cpu_required):
        """Add task to be scheduled"""
        self.tasks.append({
            'id': task_id,
            'start': start_time,
            'end': start_time + duration,
            'cpu': cpu_required
        })
    
    def optimize_schedule(self, instance_cpu_capacity):
        """
        Minimize number of instances needed
        
        This is Meeting Rooms II with resource capacity
        
        Time: O(n log n)
        """
        if not self.tasks:
            return 0, []
        
        # Create events for CPU usage changes
        events = []
        for task in self.tasks:
            events.append((task['start'], task['cpu'], 'start', task['id']))
            events.append((task['end'], -task['cpu'], 'end', task['id']))
        
        events.sort()
        
        current_cpu = 0
        max_cpu = 0
        cpu_timeline = []
        
        for time, cpu_change, event_type, task_id in events:
            current_cpu += cpu_change
            max_cpu = max(max_cpu, current_cpu)
            cpu_timeline.append((time, current_cpu))
        
        # Calculate instances needed
        instances_needed = (max_cpu + instance_cpu_capacity - 1) // instance_cpu_capacity
        
        return instances_needed, cpu_timeline
    
    def calculate_cost(self, instances_needed, time_start, time_end):
        """Calculate total cost"""
        hours = (time_end - time_start) / 3600
        return instances_needed * hours * self.instance_cost
    
    def suggest_task_delays(self, instance_limit, instance_cpu_capacity):
        """
        Suggest delaying tasks to fit within instance limit
        
        Real-world: Complex optimization problem
        Use heuristics or constraint solver
        """
        # Simple heuristic: delay non-urgent tasks
        instances_needed, timeline = self.optimize_schedule(instance_cpu_capacity)
        
        if instances_needed <= instance_limit:
            return []  # No delays needed
        
        # Find peak periods
        peaks = []
        for i, (time, cpu) in enumerate(timeline):
            if cpu > instance_limit * instance_cpu_capacity:
                peaks.append(time)
        
        # Suggest delaying tasks during peak
        suggestions = []
        for task in self.tasks:
            for peak_time in peaks:
                if task['start'] <= peak_time <= task['end']:
                    # Suggest delaying this task
                    delay = 3600  # 1 hour
                    suggestions.append({
                        'task_id': task['id'],
                        'delay_by': delay,
                        'reason': f'Peak usage at {peak_time}'
                    })
                    break
        
        return suggestions


# Demo
def demo_cloud_scheduler():
    """Demonstrate cloud resource scheduling"""
    print("\n" + "="*60)
    print("REAL-WORLD APPLICATION: Cloud Resource Scheduler")
    print("="*60)
    
    scheduler = CloudResourceScheduler(instance_cost_per_hour=1.0)
    
    # Add tasks (start_time, duration, cpu_required)
    tasks = [
        ("job1", 0, 7200, 4),      # 0-2h, needs 4 CPU
        ("job2", 1800, 5400, 8),   # 0.5-2h, needs 8 CPU
        ("job3", 3600, 3600, 6),   # 1-2h, needs 6 CPU
        ("job4", 7200, 3600, 4),   # 2-3h, needs 4 CPU
    ]
    
    print("\nTasks:")
    for task_id, start, duration, cpu in tasks:
        scheduler.add_task(task_id, start, duration, cpu)
        print(f"  {task_id}: {start//3600}h-{(start+duration)//3600}h, "
              f"{cpu} CPU")
    
    # Optimize
    instance_capacity = 8  # 8 CPUs per instance
    instances, timeline = scheduler.optimize_schedule(instance_capacity)
    
    print(f"\nOptimal schedule:")
    print(f"  Instances needed: {instances}")
    print(f"  Instance capacity: {instance_capacity} CPU")
    
    print(f"\n  CPU usage timeline:")
    for time, cpu in timeline[:10]:  # Show first 10 events
        hour = time // 3600
        instances_used = (cpu + instance_capacity - 1) // instance_capacity
        print(f"    {hour}h: {cpu} CPU ({instances_used} instances)")
    
    # Calculate cost
    cost = scheduler.calculate_cost(instances, 0, 10800)  # 3 hours
    print(f"\n  Total cost: ${cost:.2f}")

demo_cloud_scheduler()
```

**Real-World Considerations:**
1. **Auto-scaling policies** - scale up/down based on load
2. **Spot instances** - use cheaper instances when available
3. **Task priorities** - critical tasks get resources first
4. **Geographic distribution** - schedule across regions
5. **Power management** - minimize idle time

---

### Application 3: Video Streaming & Content Delivery

**Real-World System:** YouTube, Netflix CDN

**Core Problems:**
1. Schedule video segments for pre-loading
2. Optimize bandwidth allocation
3. Cache management with time windows

**Production Implementation:**

```python
class VideoStreamOptimizer:
    """
    Optimize video streaming and caching
    """
    
    def __init__(self, total_bandwidth_mbps):
        self.total_bandwidth = total_bandwidth_mbps
        self.active_streams = []
        self.cached_segments = {}
    
    def can_start_stream(self, video_id, quality_mbps, start_time, duration):
        """
        Check if we have bandwidth for new stream
        
        Uses Meeting Rooms II pattern
        """
        # Create interval for new stream
        new_stream = [start_time, start_time + duration, quality_mbps]
        
        # Calculate bandwidth at each time point
        events = []
        for stream in self.active_streams:
            events.append((stream[0], stream[2]))   # Start
            events.append((stream[1], -stream[2]))  # End
        
        events.append((new_stream[0], new_stream[2]))
        events.append((new_stream[1], -new_stream[2]))
        
        events.sort()
        
        current_bandwidth = 0
        for time, change in events:
            current_bandwidth += change
            if current_bandwidth > self.total_bandwidth:
                return False
        
        return True
    
    def optimize_cache_segments(self, video_segments, cache_size_gb):
        """
        Select which video segments to cache
        
        Weighted interval scheduling:
        - Weight = popularity * size
        - Constraint = cache size
        
        Real-world: Use LRU, LFU, or ML-based eviction
        """
        # Simple greedy: sort by popularity/size ratio
        segments_with_score = []
        
        for segment in video_segments:
            video_id = segment['video_id']
            segment_id = segment['segment_id']
            size_mb = segment['size_mb']
            popularity = segment['views_per_hour']
            time_range = segment['time_range']  # [start, end]
            
            # Score = views per MB
            score = popularity / size_mb if size_mb > 0 else 0
            
            segments_with_score.append({
                'id': f"{video_id}_{segment_id}",
                'size': size_mb,
                'score': score,
                'time_range': time_range,
                'popularity': popularity
            })
        
        # Sort by score (greedy)
        segments_with_score.sort(key=lambda x: x['score'], reverse=True)
        
        # Select segments that fit in cache
        cached = []
        total_size = 0
        cache_size_mb = cache_size_gb * 1024
        
        for segment in segments_with_score:
            if total_size + segment['size'] <= cache_size_mb:
                cached.append(segment)
                total_size += segment['size']
        
        return cached, total_size
    
    def schedule_preload(self, user_watch_history, video_segments):
        """
        Schedule video segment pre-loading
        
        Predict what user will watch next
        Pre-load during low bandwidth times
        """
        # Simple prediction: next segment in same video
        # Real-world: Use ML model for prediction
        
        preload_schedule = []
        
        # Sort by priority (predicted watch time)
        for video_id, current_segment in user_watch_history:
            next_segment = current_segment + 1
            
            # Find segment info
            for segment in video_segments:
                if (segment['video_id'] == video_id and 
                    segment['segment_id'] == next_segment):
                    
                    preload_schedule.append({
                        'video_id': video_id,
                        'segment_id': next_segment,
                        'priority': 1,  # High priority
                        'size_mb': segment['size_mb']
                    })
        
        return preload_schedule


# Demo
def demo_video_optimizer():
    """Demonstrate video streaming optimization"""
    print("\n" + "="*60)
    print("REAL-WORLD APPLICATION: Video Streaming Optimizer")
    print("="*60)
    
    optimizer = VideoStreamOptimizer(total_bandwidth_mbps=1000)
    
    print("\n1. Check if new stream can start:")
    print("   Scenario: 100 Mbps stream, 1 hour duration")
    
    can_start = optimizer.can_start_stream(
        video_id="video123",
        quality_mbps=100,
        start_time=0,
        duration=3600
    )
    print(f"   Can start: {can_start}")
    
    print("\n2. Optimize cache segments:")
    segments = [
        {'video_id': 'v1', 'segment_id': 1, 'size_mb': 50, 
         'views_per_hour': 1000, 'time_range': [0, 300]},
        {'video_id': 'v1', 'segment_id': 2, 'size_mb': 50, 
         'views_per_hour': 800, 'time_range': [300, 600]},
        {'video_id': 'v2', 'segment_id': 1, 'size_mb': 100, 
         'views_per_hour': 500, 'time_range': [0, 300]},
    ]
    
    cached, total_size = optimizer.optimize_cache_segments(
        segments, cache_size_gb=0.1  # 100 MB
    )
    
    print(f"   Cache size: 100 MB")
    print(f"   Cached segments: {len(cached)}")
    print(f"   Total size: {total_size:.1f} MB")
    for seg in cached:
        print(f"     {seg['id']}: {seg['size']:.0f}MB, "
              f"score={seg['score']:.1f}")

demo_video_optimizer()
```

**Production Optimizations:**
1. **Adaptive Bitrate Streaming** - adjust quality based on bandwidth
2. **Multi-CDN** - use multiple CDNs for redundancy
3. **Predictive Pre-loading** - ML models predict next content
4. **Edge Caching** - cache at edge locations near users
5. **P2P Delivery** - leverage peer-to-peer for popular content

---

## 14.2 System Design with Intervals

### Design: Distributed Task Scheduler

**Requirements:**
- Schedule millions of tasks per second
- Ensure no conflicts
- Minimize resource usage
- Handle failures gracefully

**Architecture:**

```python
"""
DISTRIBUTED TASK SCHEDULER ARCHITECTURE

Components:
1. API Gateway - receives task submissions
2. Scheduler Service - finds optimal schedule
3. Resource Manager - tracks available resources
4. Executor Service - runs tasks
5. State Store - persists schedules (Redis/Cassandra)

Data Flow:
Client â†’ API Gateway â†’ Scheduler â†’ Resource Manager â†’ Executor
                            â†“
                       State Store

Interval Patterns Used:
- Meeting Rooms II: Resource allocation
- Sweep Line: Timeline management
- Range Module: Dynamic availability tracking
"""

class DistributedScheduler:
    """
    Distributed task scheduler design
    """
    
    def __init__(self):
        # Partition tasks by time window for scalability
        # Each partition handles 1-hour window
        self.time_partitions = {}  # hour -> TaskPartition
        
        # Resource tracking per data center
        self.resource_managers = {}  # dc_id -> ResourceManager
        
        # Global state
        self.task_queue = []
    
    def submit_task(self, task):
        """
        Submit task for scheduling
        
        In production:
        - Use message queue (Kafka, RabbitMQ)
        - Async processing
        - Retry on failure
        """
        # Determine partition
        hour = task['start_time'] // 3600
        
        if hour not in self.time_partitions:
            self.time_partitions[hour] = TaskPartition(hour)
        
        partition = self.time_partitions[hour]
        partition.add_task(task)
        
        return task['id']
    
    def schedule_partition(self, hour):
        """
        Schedule all tasks in a time partition
        
        Run periodically (e.g., every 5 minutes)
        """
        if hour not in self.time_partitions:
            return
        
        partition = self.time_partitions[hour]
        tasks = partition.get_pending_tasks()
        
        # Find optimal resource allocation
        schedule = self._optimize_schedule(tasks)
        
        # Assign to executors
        for task, executor in schedule:
            self._assign_to_executor(task, executor)
    
    def _optimize_schedule(self, tasks):
        """
        Optimize task-to-resource mapping
        
        Uses Meeting Rooms II algorithm
        """
        # Group by resource requirements
        by_cpu = {}
        for task in tasks:
            cpu = task['cpu_required']
            if cpu not in by_cpu:
                by_cpu[cpu] = []
            by_cpu[cpu].append(task)
        
        schedule = []
        
        # Schedule each group
        for cpu_req, task_group in by_cpu.items():
            # Find minimum executors needed
            executors = self._find_min_executors(task_group, cpu_req)
            
            for task, executor_id in zip(task_group, executors):
                schedule.append((task, executor_id))
        
        return schedule
    
    def _find_min_executors(self, tasks, cpu_per_executor):
        """Find minimum executors using Meeting Rooms II"""
        import heapq
        
        tasks.sort(key=lambda x: x['start_time'])
        
        # Heap of (end_time, executor_id)
        executors = []
        executor_assignments = []
        next_executor_id = 0
        
        for task in tasks:
            # Check if any executor is free
            if executors and executors[0][0] <= task['start_time']:
                end_time, executor_id = heapq.heappop(executors)
                heapq.heappush(executors, 
                             (task['end_time'], executor_id))
                executor_assignments.append(executor_id)
            else:
                # Need new executor
                executor_id = next_executor_id
                next_executor_id += 1
                heapq.heappush(executors,
                             (task['end_time'], executor_id))
                executor_assignments.append(executor_id)
        
        return executor_assignments
    
    def _assign_to_executor(self, task, executor_id):
        """Assign task to executor"""
        # In production: use gRPC, HTTP, or message queue
        print(f"Assigned task {task['id']} to executor {executor_id}")


class TaskPartition:
    """
    Time-based partition for scalability
    Each partition handles 1-hour window
    """
    
    def __init__(self, hour):
        self.hour = hour
        self.tasks = []
        self.scheduled = False
    
    def add_task(self, task):
        self.tasks.append(task)
    
    def get_pending_tasks(self):
        return [t for t in self.tasks if not t.get('scheduled')]


# Demo
def demo_distributed_scheduler():
    """Demonstrate distributed scheduler"""
    print("\n" + "="*60)
    print("SYSTEM DESIGN: Distributed Task Scheduler")
    print("="*60)
    
    scheduler = DistributedScheduler()
    
    print("\n1. Submit tasks:")
    tasks = [
        {'id': 't1', 'start_time': 0, 'end_time': 3600, 
         'cpu_required': 2},
        {'id': 't2', 'start_time': 1800, 'end_time': 5400, 
         'cpu_required': 2},
        {'id': 't3', 'start_time': 3600, 'end_time': 7200, 
         'cpu_required': 2},
    ]
    
    for task in tasks:
        task_id = scheduler.submit_task(task)
        print(f"   Submitted: {task_id}")
    
    print("\n2. Schedule partition (hour 0):")
    scheduler.schedule_partition(0)
    
    print("\n3. System design considerations:")
    print("   - Partition by time for horizontal scaling")
    print("   - Use message queue for async task submission")
    print("   - Implement leader election for coordination")
    print("   - Use distributed locking for resource allocation")
    print("   - Persist state in distributed database")
    print("   - Monitor with metrics and alerts")

demo_distributed_scheduler()
```

**Scaling Strategies:**
1. **Time-based partitioning** - different services handle different time windows
2. **Consistent hashing** - distribute tasks across schedulers
3. **Eventual consistency** - accept slight delays for availability
4. **Circuit breakers** - handle service failures gracefully
5. **Rate limiting** - prevent overload

---

## 14.3 Advanced Optimization Techniques

### Technique 1: Segment Trees for Dynamic Intervals

```python
class SegmentTree:
    """
    Advanced data structure for range queries and updates
    
    Operations: O(log n)
    Space: O(n)
    
    Use when:
    - Need range queries (min, max, sum)
    - Need dynamic updates
    - Intervals change frequently
    """
    
    def __init__(self, n):
        self.n = n
        self.tree = [0] * (4 * n)  # 4n is sufficient
        self.lazy = [0] * (4 * n)  # Lazy propagation
    
    def update_range(self, left, right, value):
        """
        Add value to range [left, right]
        Uses lazy propagation for O(log n)
        """
        self._update_range(0, 0, self.n - 1, left, right, value)
    
    def query_range(self, left, right):
        """Query maximum value in range [left, right]"""
        return self._query_range(0, 0, self.n - 1, left, right)
    
    def _update_range(self, node, start, end, left, right, value):
        """Internal update with lazy propagation"""
        # Apply pending updates
        if self.lazy[node] != 0:
            self.tree[node] += self.lazy[node]
            if start != end:
                self.lazy[2*node + 1] += self.lazy[node]
                self.lazy[2*node + 2] += self.lazy[node]
            self.lazy[node] = 0
        
        # No overlap
        if start > end or start > right or end < left:
            return
        
        # Complete overlap
        if start >= left and end <= right:
            self.tree[node] += value
            if start != end:
                self.lazy[2*node + 1] += value
                self.lazy[2*node + 2] += value
            return
        
        # Partial overlap - recurse
        mid = (start + end) // 2
        self._update_range(2*node + 1, start, mid, left, right, value)
        self._update_range(2*node + 2, mid + 1, end, left, right, value)
        self.tree[node] = max(self.tree[2*node + 1], self.tree[2*node + 2])
    
    def _query_range(self, node, start, end, left, right):
        """Internal query"""
        # Apply pending updates
        if self.lazy[node] != 0:
            self.tree[node] += self.lazy[node]
            if start != end:
                self.lazy[2*node + 1] += self.lazy[node]
                self.lazy[2*node + 2] += self.lazy[node]
            self.lazy[node] = 0
        
        # No overlap
        if start > end or start > right or end < left:
            return float('-inf')
        
        # Complete overlap
        if start >= left and end <= right:
            return self.tree[node]
        
        # Partial overlap
        mid = (start + end) // 2
        left_max = self._query_range(2*node + 1, start, mid, left, right)
        right_max = self._query_range(2*node + 2, mid + 1, end, left, right)
        return max(left_max, right_max)


# Demo
def demo_segment_tree():
    """Demonstrate segment tree for intervals"""
    print("\n" + "="*60)
    print("ADVANCED: Segment Tree for Dynamic Intervals")
    print("="*60)
    
    # Track room usage over time
    # Time slots: 0-9
    st = SegmentTree(10)
    
    print("\n1. Add bookings (using segment tree):")
    bookings = [
        (0, 5, 2),   # 2 rooms during 0-5
        (3, 7, 3),   # 3 rooms during 3-7
        (2, 4, 1),   # 1 room during 2-4
    ]
    
    for start, end, rooms in bookings:
        st.update_range(start, end, rooms)
        print(f"   Add {rooms} rooms for time [{start}, {end}]")
    
    print("\n2. Query peak usage:")
    for i in range(10):
        peak = st.query_range(i, i)
        print(f"   Time {i}: {int(peak)} rooms")
    
    print("\n3. Query range:")
    peak_3_to_5 = st.query_range(3, 5)
    print(f"   Peak usage during [3, 5]: {int(peak_3_to_5)} rooms")

demo_segment_tree()
```

**When to Use Segment Trees:**
- Dynamic range updates (adding/removing intervals)
- Range queries (min, max, sum) in O(log n)
- Online algorithms (can't preprocess all data)

---

## 14.4 Interview Mastery Roadmap

### 8-Week Intensive Training Plan

```
WEEK 1-2: FOUNDATIONS
â”œâ”€ Day 1-3: Review basic patterns
â”‚  â€¢ Merge Intervals (10 problems)
â”‚  â€¢ Insert Interval (5 problems)
â”‚  â€¢ Time: 2 hours/day
â”‚
â”œâ”€ Day 4-7: Intersection & Detection
â”‚  â€¢ Two-list intersection (5 problems)
â”‚  â€¢ Meeting Rooms I (10 variations)
â”‚  â€¢ Time: 2 hours/day
â”‚
â””â”€ Weekend: Mock interview practice
   â€¢ 2 problems in 45 minutes
   â€¢ Record yourself explaining

WEEK 3-4: INTERMEDIATE
â”œâ”€ Day 1-3: Resource Allocation
â”‚  â€¢ Meeting Rooms II (15 problems)
â”‚  â€¢ Capacity problems (10 problems)
â”‚  â€¢ Time: 2.5 hours/day
â”‚
â”œâ”€ Day 4-7: Optimization Problems
â”‚  â€¢ Activity Selection (10 problems)
â”‚  â€¢ Greedy algorithms (15 problems)
â”‚  â€¢ Time: 3 hours/day
â”‚
â””â”€ Weekend: System design practice
   â€¢ Design calendar system
   â€¢ Design resource scheduler

WEEK 5-6: ADVANCED
â”œâ”€ Day 1-3: Weighted Scheduling
â”‚  â€¢ DP problems (10 problems)
â”‚  â€¢ Complex constraints (5 problems)
â”‚  â€¢ Time: 3 hours/day
â”‚
â”œâ”€ Day 4-7: Data Structures
â”‚  â€¢ Range Module (5 problems)
â”‚  â€¢ Segment Trees (5 problems)
â”‚  â€¢ Time: 3 hours/day
â”‚
â””â”€ Weekend: Hard problem marathon
   â€¢ 10 hard problems
   â€¢ Focus on optimization

WEEK 7-8: MASTERY
â”œâ”€ Day 1-3: Real-world applications
â”‚  â€¢ Calendar systems
â”‚  â€¢ Cloud scheduling
â”‚  â€¢ Stream processing
â”‚  â€¢ Time: 2 hours/day
â”‚
â”œâ”€ Day 4-7: Interview simulation
â”‚  â€¢ Daily mock interviews
â”‚  â€¢ Communication practice
â”‚  â€¢ Edge case focus
â”‚  â€¢ Time: 1.5 hours/day
â”‚
â””â”€ Weekend: Final review
   â€¢ Review all patterns
   â€¢ Practice explaining
   â€¢ Confidence building
```

### Progress Tracking Checklist

```python
class MasteryTracker:
    """Track your progress through mastery levels"""
    
    LEVELS = {
        'beginner': {
            'requirements': [
                'Can implement basic merge intervals',
                'Understand O(n log n) complexity',
                'Can handle sorted inputs',
                'Recognize merge pattern'
            ],
            'problems_solved': 20,
            'success_rate': 0.7
        },
        'intermediate': {
            'requirements': [
                'Can solve Meeting Rooms II variants',
                'Understand sweep line technique',
                'Can optimize from O(nÂ²) to O(n log n)',
                'Recognize resource allocation pattern'
            ],
            'problems_solved': 50,
            'success_rate': 0.75
        },
        'advanced': {
            'requirements': [
                'Can solve weighted scheduling with DP',
                'Can design Range Module',
                'Understand segment trees',
                'Can handle real-world constraints'
            ],
            'problems_solved': 80,
            'success_rate': 0.80
        },
        'expert': {
            'requirements': [
                'Can solve any interval problem in interview',
                'Can explain multiple solutions',
                'Can optimize for production',
                'Can design distributed systems'
            ],
            'problems_solved': 100,
            'success_rate': 0.90
        }
    }
    
    def check_level(self, problems_solved, success_rate, skills):
        """Determine current mastery level"""
        for level in ['expert', 'advanced', 'intermediate', 'beginner']:
            requirements = self.LEVELS[level]
            
            if (problems_solved >= requirements['problems_solved'] and
                success_rate >= requirements['success_rate']):
                return level
        
        return 'novice'
    
    def print_roadmap(self):
        """Print complete roadmap"""
        print("="*60)
        print("MASTERY ROADMAP")
        print("="*60)
        
        for level, details in self.LEVELS.items():
            print(f"\n{level.upper()}:")
            print(f"  Problems: {details['problems_solved']}+")
            print(f"  Success rate: {details['success_rate']*100}%+")
            print("  Requirements:")
            for req in details['requirements']:
                print(f"    â€¢ {req}")


# Print roadmap
tracker = MasteryTracker()
tracker.print_roadmap()
```

---

## 14.5 Beyond Interviews: Production Best Practices

### Production Code Quality

```python
"""
PRODUCTION-READY INTERVAL CODE

Key differences from interview code:
1. Comprehensive error handling
2. Input validation
3. Logging and monitoring
4. Performance optimization
5. Documentation
6. Testing
"""

import logging
from typing import List, Tuple, Optional
from dataclasses import dataclass

@dataclass
class Interval:
    """Strongly-typed interval representation"""
    start: int
    end: int
    
    def __post_init__(self):
        """Validate on construction"""
        if self.start > self.end:
            raise ValueError(f"Invalid interval: start ({self.start}) > end ({self.end})")
    
    def overlaps_with(self, other: 'Interval') -> bool:
        """Check if this interval overlaps with another"""
        return self.start <= other.end and other.start <= self.end
    
    def merge_with(self, other: 'Interval') -> 'Interval':
        """Merge with another overlapping interval"""
        if not self.overlaps_with(other):
            raise ValueError("Cannot merge non-overlapping intervals")
        
        return Interval(
            start=min(self.start, other.start),
            end=max(self.end, other.end)
        )


class ProductionIntervalMerger:
    """
    Production-ready interval merger with full error handling
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def merge_intervals(self, intervals: List[Interval]) -> List[Interval]:
        """
        Merge overlapping intervals
        
        Args:
            intervals: List of intervals to merge
        
        Returns:
            List of non-overlapping intervals
        
        Raises:
            ValueError: If input contains invalid intervals
            TypeError: If input is not a list of Intervals
        
        Time: O(n log n)
        Space: O(n)
        """
        # Input validation
        if not isinstance(intervals, list):
            raise TypeError("Input must be a list")
        
        if not intervals:
            self.logger.info("Empty input, returning empty result")
            return []
        
        # Validate all intervals
        for i, interval in enumerate(intervals):
            if not isinstance(interval, Interval):
                raise TypeError(f"Element {i} is not an Interval")
        
        self.logger.info(f"Merging {len(intervals)} intervals")
        
        try:
            # Sort by start time
            sorted_intervals = sorted(intervals, key=lambda x: x.start)
            
            # Merge
            merged = [sorted_intervals[0]]
            merge_count = 0
            
            for current in sorted_intervals[1:]:
                last = merged[-1]
                
                if current.overlaps_with(last):
                    # Merge
                    merged[-1] = last.merge_with(current)
                    merge_count += 1
                else:
                    # No overlap
                    merged.append(current)
            
            self.logger.info(
                f"Merged {merge_count} intervals, "
                f"result has {len(merged)} intervals"
            )
            
            return merged
            
        except Exception as e:
            self.logger.error(f"Error during merge: {e}")
            raise


# Demo production code
def demo_production_code():
    """Demonstrate production-ready code"""
    print("\n" + "="*60)
    print("PRODUCTION BEST PRACTICES")
    print("="*60)
    
    # Setup logging
    logging.basicConfig(level=logging.INFO)
    
    merger = ProductionIntervalMerger()
    
    print("\n1. Valid input:")
    try:
        intervals = [
            Interval(1, 3),
            Interval(2, 6),
            Interval(8, 10)
        ]
        result = merger.merge_intervals(intervals)
        print(f"   Result: {result}")
    except Exception as e:
        print(f"   Error: {e}")
    
    print("\n2. Invalid interval (start > end):")
    try:
        invalid = Interval(5, 2)
    except ValueError as e:
        print(f"   Caught error: {e}")
    
    print("\n3. Invalid input type:")
    try:
        result = merger.merge_intervals("not a list")
    except TypeError as e:
        print(f"   Caught error: {e}")

demo_production_code()
```

---

## Final Mastery Checklist

### Technical Skills âœ“
- [ ] Can solve 90%+ of interval problems
- [ ] Know all 8 core patterns by heart
- [ ] Can optimize to O(n log n) or better
- [ ] Understand when to use each data structure
- [ ] Can handle all edge cases systematically

### Communication Skills âœ“
- [ ] Can explain approach before coding
- [ ] Think aloud while coding
- [ ] Ask clarifying questions naturally
- [ ] Handle feedback gracefully
- [ ] Explain trade-offs clearly

### System Design Skills âœ“
- [ ] Can design calendar systems
- [ ] Can design resource schedulers
- [ ] Understand scaling challenges
- [ ] Know production optimizations
- [ ] Can discuss real-world constraints

### Problem-Solving Skills âœ“
- [ ] Recognize patterns in <30 seconds
- [ ] Can solve medium problems in 20 minutes
- [ ] Can solve hard problems in 35 minutes
- [ ] Handle unknown variations
- [ ] Debug efficiently

### Production Skills âœ“
- [ ] Write clean, maintainable code
- [ ] Add proper error handling
- [ ] Consider performance at scale
- [ ] Think about monitoring/observability
- [ ] Understand deployment considerations

---

## Conclusion: Your Path to Mastery

**You've completed the comprehensive interval patterns guide!**

### What You've Learned:
1. **13 chapters** covering fundamentals to advanced topics
2. **100+ code examples** with detailed explanations
3. **50+ problems** with complete solutions
4. **Real-world applications** in production systems
5. **Interview strategies** for success

### Next Steps:
1. **Practice daily** - solve 1-2 problems per day
2. **Mock interviews** - practice explaining solutions
3. **Build projects** - implement real systems
4. **Teach others** - best way to solidify knowledge
5. **Stay current** - follow new patterns and techniques

### Remember:
- **Patterns > Memorization** - understand why, not just how
- **Communication matters** - explaining is as important as coding
- **Practice deliberately** - focus on weak areas
- **Stay persistent** - mastery takes time

**You're now ready to ace any interval problem in technical interviews!** ðŸš€

Good luck on your interview journey!