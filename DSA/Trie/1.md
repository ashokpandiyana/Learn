# Chapter 1: Foundations of Trie Data Structure

## 1.1 What is a Trie?

### Conceptual Understanding

A **Trie** (pronounced "try") is a tree-based data structure specifically designed for storing and retrieving strings efficiently. The name comes from "re**trie**val", emphasizing its primary purpose.

**Core Principle**: Tries store strings by breaking them into characters, where each character occupies a node, and **common prefixes are shared**.

### Visual Example

Let's insert the words: "cat", "car", "card", "dog", "dodge"

```
                    ROOT
                   /    \
                  c      d
                  |      |
                  a      o
                 / \     |
                t   r    g
                    |    |
                    d    e*
                    |
                    *
                    
Legend: * = end of word marker
```

**Key Observations:**
1. "cat", "car", and "card" share the prefix "ca"
2. "dog" and "dodge" share the prefix "do"
3. The path from root to any * represents a complete word
4. Intermediate nodes might also be words (like "car" is a word, and "card" extends it)

### Why Tries Excel

**1. Prefix Queries**: O(m) time where m = prefix length
```
Finding all words starting with "ca":
- Traverse to 'c' ‚Üí 'a'
- Collect all words in that subtree
- Result: "cat", "car", "card"
```

**2. Memory Efficiency** (for shared prefixes):
```
Without Trie: "cat", "car", "card" = 10 characters stored
With Trie: Only 7 unique character nodes needed
```

**3. No Hash Collisions**: Unlike hash tables, tries have predictable O(m) lookup

### Comparison with Other Data Structures

| Operation | Array | Hash Table | BST | Trie |
|-----------|-------|------------|-----|------|
| Insert word | O(n) | O(m) avg | O(m log n) | O(m) |
| Search word | O(n*m) | O(m) avg | O(m log n) | O(m) |
| Prefix search | O(n*m) | O(n*m) | O(n*m) | O(p) |
| Sorted order | O(n log n) | ‚ùå | ‚úÖ | ‚úÖ |
| Space | O(n*m) | O(n*m) | O(n*m) | O(ALPHABET*n*m) |

*n = number of words, m = average word length, p = prefix length*

---

## 1.2 Basic Structure & Node Design

### The TrieNode: Two Approaches

#### Approach 1: Array-Based Children (Fixed Alphabet)

**Best for**: Lowercase English letters, digits, or any fixed small alphabet

```python
class TrieNode:
    def __init__(self):
        # Array for 26 lowercase letters
        self.children = [None] * 26
        self.is_end_of_word = False
    
    def get_index(self, char):
        """Convert character to array index"""
        return ord(char) - ord('a')
```

**Advantages:**
- ‚úÖ O(1) child lookup
- ‚úÖ Simple indexing
- ‚úÖ Cache-friendly (contiguous memory)

**Disadvantages:**
- ‚ùå Wastes space if alphabet is sparse
- ‚ùå Fixed alphabet size

**Memory Analysis:**
- Each node: 26 pointers + 1 boolean = ~208 bytes (on 64-bit system)
- For 1000 words, avg length 6: ~6000 nodes = ~1.2 MB

#### Approach 2: HashMap-Based Children (Flexible Alphabet)

**Best for**: Unicode, mixed case, special characters, or unknown alphabet

```python
class TrieNode:
    def __init__(self):
        # Dictionary for dynamic alphabet
        self.children = {}
        self.is_end_of_word = False
```

**Advantages:**
- ‚úÖ Space-efficient for sparse alphabets
- ‚úÖ Works with any character set
- ‚úÖ Only stores existing children

**Disadvantages:**
- ‚ùå O(1) average, but with hash overhead
- ‚ùå Additional memory per dict entry

**Memory Analysis:**
- Each node: dict overhead (~240 bytes) + entries
- For same 1000 words: significantly less if alphabet usage is sparse

### Essential Node Components

```python
class EnhancedTrieNode:
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False
        
        # Optional but useful additions:
        self.word_count = 0        # How many words pass through here
        self.word = None            # Store the complete word at end nodes
        self.frequency = 0          # For ranking/autocomplete
```

### Character-to-Index Mapping Strategies

#### Strategy 1: Lowercase English Only
```python
def char_to_index(char):
    return ord(char) - ord('a')  # 'a'=0, 'b'=1, ..., 'z'=25
```

#### Strategy 2: Both Cases
```python
def char_to_index(char):
    if 'a' <= char <= 'z':
        return ord(char) - ord('a')  # 0-25
    if 'A' <= char <= 'Z':
        return ord(char) - ord('A') + 26  # 26-51
    # Need 52-element array
```

#### Strategy 3: Alphanumeric
```python
def char_to_index(char):
    if '0' <= char <= '9':
        return ord(char) - ord('0')  # 0-9
    if 'a' <= char <= 'z':
        return ord(char) - ord('a') + 10  # 10-35
    # Need 36-element array
```

---

## 1.3 Memory vs Speed Tradeoffs

### The Space-Time Tradeoff Spectrum

```
Array-based (26)          Hybrid              HashMap-based
     |                      |                       |
Fast lookup            Balanced            Space efficient
High memory           Medium                Low memory
O(1) access           O(1) avg              O(1) avg
Fixed alphabet       Semi-flexible          Any alphabet
```

### Real-World Decision Framework

**Use Array-Based When:**
- Alphabet is small and fixed (‚â§ 128 characters)
- Speed is critical (real-time systems)
- Memory is not a constraint
- Most characters in alphabet are used
- Example: English dictionary, DNA sequences (ACGT)

**Use HashMap-Based When:**
- Alphabet is large or unknown (Unicode)
- Memory is limited
- Alphabet is sparse (few characters actually used)
- Need flexibility for special characters
- Example: Multi-language support, code completion with symbols

**Use Hybrid Approach When:**
- Common characters get array slots
- Rare characters go in a HashMap
- Example: Common English + occasional emojis

### Practical Example: English Dictionary

Let's analyze storing 100,000 English words:

```python
# Scenario 1: Array-based
nodes_needed = 100000 * 6  # avg word length
memory_per_node = 26 * 8 + 8  # 26 pointers + boolean
total = nodes_needed * memory_per_node
# ‚âà 125 MB

# Scenario 2: HashMap-based (avg 5 children per node)
nodes_needed = 100000 * 6
memory_per_node = 240 + (5 * 32)  # dict overhead + 5 entries
total = nodes_needed * memory_per_node
# ‚âà 240 MB (more due to dict overhead)

# But with high prefix sharing:
# Actual unique nodes ‚âà 30% of theoretical maximum
# Array: 37.5 MB
# HashMap: 72 MB (still higher, but more flexible)
```

---

## 1.4 Key Properties & Invariants

### Property 1: Position Defines the Key
Unlike BST where nodes contain keys, in a Trie:
- The **path** from root to node defines the string
- Nodes themselves don't store complete strings (usually)

```
Example: Finding "car"
Root ‚Üí c ‚Üí a ‚Üí r (end marker found)
The string is formed by traversing: 'c', 'a', 'r'
```

### Property 2: Prefix Property
```
If word W1 is a prefix of W2, then:
- W1's end marker comes before W2's end marker
- All nodes of W1 are ancestors of W2's end node
```

Example:
```
"car" is a prefix of "card"
    c
    |
    a
    |
    r* ‚Üê "car" ends here
    |
    d* ‚Üê "card" ends here
```

### Property 3: Common Prefixes = Shared Paths
```
All words with prefix "pre" share the same nodes for 'p', 'r', 'e'
This is the memory efficiency source
```

### Critical Implementation Detail: End-of-Word Marker

**Why is it necessary?**

```python
# Without marker - WRONG
trie.insert("car")
trie.insert("card")
trie.search("car")  # How do we know "car" exists vs just being a prefix?

# With marker - CORRECT
class TrieNode:
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False  # This flag is crucial!
```

**Visual Example:**
```
Inserting "an", "and", "ant"

       ROOT
        |
        a
        |
        n*      ‚Üê "an" is a word (marker = True)
       / \
      d*  t*    ‚Üê "and" and "ant" are words
```

Without the marker at 'n', we couldn't distinguish "an" as a complete word vs just a prefix.

---

## 1.5 Complete Implementation Example

```python
class TrieNode:
    """Array-based implementation for lowercase English letters"""
    def __init__(self):
        self.children = [None] * 26
        self.is_end_of_word = False
        self.word_count = 0  # Number of words with this prefix
    
    def get_index(self, char):
        return ord(char) - ord('a')
    
    def has_child(self, char):
        idx = self.get_index(char)
        return self.children[idx] is not None
    
    def get_child(self, char):
        idx = self.get_index(char)
        return self.children[idx]
    
    def add_child(self, char):
        idx = self.get_index(char)
        if self.children[idx] is None:
            self.children[idx] = TrieNode()
        return self.children[idx]


class Trie:
    """Complete Trie implementation with essential operations"""
    def __init__(self):
        self.root = TrieNode()
        self.word_count = 0
    
    def insert(self, word):
        """Insert a word into the trie - O(m) where m is word length"""
        node = self.root
        
        for char in word:
            node.word_count += 1
            node = node.add_child(char)
        
        node.word_count += 1
        if not node.is_end_of_word:
            self.word_count += 1
        node.is_end_of_word = True
    
    def search(self, word):
        """Check if exact word exists - O(m)"""
        node = self._find_node(word)
        return node is not None and node.is_end_of_word
    
    def starts_with(self, prefix):
        """Check if any word starts with prefix - O(p)"""
        return self._find_node(prefix) is not None
    
    def _find_node(self, prefix):
        """Helper: traverse to node representing prefix"""
        node = self.root
        
        for char in prefix:
            if not node.has_child(char):
                return None
            node = node.get_child(char)
        
        return node
    
    def count_words_with_prefix(self, prefix):
        """Count how many words start with prefix"""
        node = self._find_node(prefix)
        return node.word_count if node else 0


# Usage Example
if __name__ == "__main__":
    trie = Trie()
    
    # Build dictionary
    words = ["cat", "car", "card", "care", "careful", "dog", "dodge", "door"]
    for word in words:
        trie.insert(word)
    
    # Test operations
    print(trie.search("car"))           # True
    print(trie.search("care"))          # True
    print(trie.search("careful"))       # True
    print(trie.search("careless"))      # False
    print(trie.starts_with("car"))      # True
    print(trie.starts_with("do"))       # True
    print(trie.count_words_with_prefix("car"))  # 4 words
```

---

## üß† Understanding Check

Before moving to Chapter 2, verify your understanding:

1. **Can you explain**: Why does a Trie need an `is_end_of_word` flag? What happens without it?

2. **Design question**: You're building autocomplete for a code editor with variable names. Would you use array-based or HashMap-based children? Why?

3. **Visual exercise**: Draw the Trie after inserting: "app", "apple", "apply", "ape"

4. **Complexity**: If you have n words with average length m, and alphabet size k, what's the space complexity of the Trie in the worst case?

5. **Real scenario**: Why might searching in a Trie be faster than binary search on a sorted array of strings, even though both are O(log n) operations?

Ready to explore Chapter 2 on Core Operations? Let me know if you want to discuss any of these concepts further!
