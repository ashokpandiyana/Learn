# Chapter 1: Prerequisites for Frontend Developers

> **Goal**: Bridge your frontend knowledge to backend fundamentals needed for distributed systems

---

## 1.1 Backend Fundamentals with Python

### Why Python for Distributed Systems?

As a frontend developer, you're used to JavaScript's async model. Python offers similar capabilities with cleaner syntax and is widely used in:
- Backend services (Instagram, Spotify, Netflix)
- Data pipelines (Airflow, Spark)
- Infrastructure tools (Ansible, SaltStack)
- ML/AI systems (TensorFlow, PyTorch)

### 1.1.1 Virtual Environments

**Problem**: Different projects need different package versions. Unlike `node_modules`, Python installs packages globally by default.

**Solution**: Virtual environments isolate dependencies per project.

```bash
# Create a virtual environment
python -m venv myproject_env

# Activate it
# On macOS/Linux:
source myproject_env/bin/activate

# On Windows:
myproject_env\Scripts\activate

# Your terminal now shows:
(myproject_env) $ 

# Install packages (isolated to this env)
pip install fastapi uvicorn

# Save dependencies (like package.json)
pip freeze > requirements.txt

# On another machine, install all dependencies:
pip install -r requirements.txt
```

**Modern Alternative - Poetry** (recommended):
```bash
# Install poetry
pip install poetry

# Create new project
poetry new myproject

# Add dependencies (like npm install)
poetry add fastapi uvicorn

# Activate shell
poetry shell
```

### 1.1.2 Async Programming in Python

**Frontend Analogy**: You know `async/await` in JavaScript. Python has the same!

```javascript
// JavaScript (what you know)
async function fetchUser(userId) {
    const response = await fetch(`/api/users/${userId}`);
    const user = await response.json();
    return user;
}
```

```python
# Python equivalent
import asyncio
import aiohttp

async def fetch_user(user_id: int):
    async with aiohttp.ClientSession() as session:
        async with session.get(f'/api/users/{user_id}') as response:
            user = await response.json()
            return user

# Running async code
asyncio.run(fetch_user(123))
```

**Key Differences from JavaScript**:

| Aspect | JavaScript | Python |
|--------|------------|--------|
| Event Loop | Built into runtime | Must use `asyncio` |
| Running async | Automatic in browser/Node | Need `asyncio.run()` |
| HTTP Client | `fetch` built-in | Need `aiohttp` library |
| Concurrency | Single-threaded | Can use threads too |

**Concurrent Requests** (like `Promise.all`):

```python
import asyncio
import aiohttp

async def fetch_url(session, url):
    async with session.get(url) as response:
        return await response.json()

async def fetch_all_users(user_ids: list[int]):
    async with aiohttp.ClientSession() as session:
        # Create tasks (like Promise.all)
        tasks = [
            fetch_url(session, f'http://api.example.com/users/{uid}')
            for uid in user_ids
        ]
        # Wait for all to complete
        results = await asyncio.gather(*tasks)
        return results

# Fetch 100 users concurrently
users = asyncio.run(fetch_all_users(range(1, 101)))
```

### 1.1.3 Type Hints and Pydantic

**Frontend Analogy**: Like TypeScript for Python!

```python
# Without types (like plain JavaScript)
def greet(name):
    return f"Hello, {name}"

# With type hints (like TypeScript)
def greet(name: str) -> str:
    return f"Hello, {name}"

# Complex types
from typing import Optional, List, Dict

def process_users(
    users: List[Dict[str, str]], 
    limit: Optional[int] = None
) -> List[str]:
    names = [user['name'] for user in users]
    if limit:
        return names[:limit]
    return names
```

**Pydantic for Validation** (like Zod/Yup):

```python
from pydantic import BaseModel, EmailStr, Field
from typing import Optional
from datetime import datetime

# Define your data shape (like TypeScript interface)
class UserCreate(BaseModel):
    username: str = Field(..., min_length=3, max_length=50)
    email: EmailStr
    age: int = Field(..., ge=0, le=150)
    bio: Optional[str] = None

# Automatic validation!
try:
    user = UserCreate(
        username="jo",  # Too short - will raise error!
        email="invalid-email",  # Invalid format!
        age=200  # Too high!
    )
except Exception as e:
    print(e)
    # username: String should have at least 3 characters
    # email: value is not a valid email address
    # age: Input should be less than or equal to 150

# Valid data
user = UserCreate(
    username="johndoe",
    email="john@example.com",
    age=25
)
print(user.model_dump())  # {'username': 'johndoe', 'email': 'john@example.com', 'age': 25, 'bio': None}
```

### 1.1.4 FastAPI - Your Backend Framework

**Why FastAPI?**
- Async by default (crucial for distributed systems)
- Automatic API documentation
- Type validation with Pydantic
- Similar to Express.js in simplicity

```python
from fastapi import FastAPI, HTTPException, Query
from pydantic import BaseModel
from typing import Optional, List

app = FastAPI()

# In-memory database (we'll replace with real DB later)
users_db = {}

# Data models
class UserCreate(BaseModel):
    username: str
    email: str

class User(BaseModel):
    id: int
    username: str
    email: str

# Routes (like Express routes)
@app.get("/")
async def root():
    return {"message": "Hello World"}

# GET with path parameter
@app.get("/users/{user_id}", response_model=User)
async def get_user(user_id: int):
    if user_id not in users_db:
        raise HTTPException(status_code=404, detail="User not found")
    return users_db[user_id]

# GET with query parameters
@app.get("/users", response_model=List[User])
async def list_users(
    skip: int = Query(0, ge=0),
    limit: int = Query(10, ge=1, le=100)
):
    users = list(users_db.values())
    return users[skip:skip + limit]

# POST - create resource
@app.post("/users", response_model=User, status_code=201)
async def create_user(user: UserCreate):
    user_id = len(users_db) + 1
    new_user = User(id=user_id, **user.model_dump())
    users_db[user_id] = new_user
    return new_user

# PUT - update resource
@app.put("/users/{user_id}", response_model=User)
async def update_user(user_id: int, user: UserCreate):
    if user_id not in users_db:
        raise HTTPException(status_code=404, detail="User not found")
    updated_user = User(id=user_id, **user.model_dump())
    users_db[user_id] = updated_user
    return updated_user

# DELETE - remove resource
@app.delete("/users/{user_id}", status_code=204)
async def delete_user(user_id: int):
    if user_id not in users_db:
        raise HTTPException(status_code=404, detail="User not found")
    del users_db[user_id]
    return None
```

**Run the server**:
```bash
pip install fastapi uvicorn
uvicorn main:app --reload

# Visit http://localhost:8000/docs for auto-generated Swagger UI!
```

---

## 1.2 Networking Essentials

### 1.2.1 The OSI Model (Simplified)

Think of sending a letter through multiple post offices:

```
┌─────────────────────────────────────────────────────────────┐
│  Layer 7: APPLICATION    │  HTTP, WebSocket, gRPC          │
│  (What you usually work with in frontend/backend)          │
├─────────────────────────────────────────────────────────────┤
│  Layer 6: PRESENTATION   │  SSL/TLS encryption, JSON       │
├─────────────────────────────────────────────────────────────┤
│  Layer 5: SESSION        │  Connections, authentication    │
├─────────────────────────────────────────────────────────────┤
│  Layer 4: TRANSPORT      │  TCP (reliable), UDP (fast)     │
│  (Ports live here: 80, 443, 5432)                          │
├─────────────────────────────────────────────────────────────┤
│  Layer 3: NETWORK        │  IP addresses, routing          │
├─────────────────────────────────────────────────────────────┤
│  Layer 2: DATA LINK      │  MAC addresses, switches        │
├─────────────────────────────────────────────────────────────┤
│  Layer 1: PHYSICAL       │  Cables, WiFi signals           │
└─────────────────────────────────────────────────────────────┘
```

**For distributed systems, focus on Layers 4-7.**

### 1.2.2 TCP vs UDP

```
TCP (Transmission Control Protocol)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
✓ Guaranteed delivery (retries if lost)
✓ Ordered packets (arrives in sequence)
✓ Connection-based (handshake first)
✗ Slower due to overhead

Use for: HTTP, databases, file transfer
         Most distributed system communication!


UDP (User Datagram Protocol)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
✓ Fast (no handshake)
✓ Low overhead
✗ No delivery guarantee
✗ Packets may arrive out of order

Use for: Video streaming, gaming, DNS
```

**TCP Three-Way Handshake**:
```
Client                          Server
   │                               │
   │──── SYN (seq=100) ──────────>│  "Hey, want to talk?"
   │                               │
   │<─── SYN-ACK (seq=300,ack=101)│  "Sure! I hear you"
   │                               │
   │──── ACK (ack=301) ──────────>│  "Great, I hear you too"
   │                               │
   │      Connection Established   │
```

### 1.2.3 HTTP Deep Dive

**HTTP/1.1 vs HTTP/2 vs HTTP/3**:

```
HTTP/1.1 (1997)
┌─────────────────┐
│ Request 1       │──────────────────────> Response 1
│ Request 2       │ (waits)                Response 2
│ Request 3       │ (waits more)           Response 3
└─────────────────┘
Problem: Head-of-line blocking, one request at a time per connection

HTTP/2 (2015)
┌─────────────────┐
│ Request 1 ──────│────> Response 1
│ Request 2 ──────│────> Response 2  (multiplexed!)
│ Request 3 ──────│────> Response 3
└─────────────────┘
Better: Multiple requests on single connection, binary protocol

HTTP/3 (2022)
┌─────────────────┐
│ Uses QUIC (UDP) │
│ Even faster!    │
│ Better mobile   │
└─────────────────┘
Best: No TCP head-of-line blocking, faster connection setup
```

**HTTP Request/Response in Python**:

```python
import httpx  # Modern HTTP client (like axios)

# Sync request
response = httpx.get('https://api.github.com/users/octocat')
print(response.status_code)  # 200
print(response.json())       # {'login': 'octocat', ...}

# Async request (for distributed systems)
async def fetch_data():
    async with httpx.AsyncClient() as client:
        response = await client.get('https://api.github.com/users/octocat')
        return response.json()

# HTTP methods
async with httpx.AsyncClient() as client:
    # GET - retrieve
    await client.get('/users/1')
    
    # POST - create
    await client.post('/users', json={'name': 'John'})
    
    # PUT - full update
    await client.put('/users/1', json={'name': 'Jane', 'email': 'jane@example.com'})
    
    # PATCH - partial update
    await client.patch('/users/1', json={'name': 'Jane'})
    
    # DELETE - remove
    await client.delete('/users/1')
```

### 1.2.4 Latency - The Enemy of Distributed Systems

**Latency Components**:
```
Total Latency = Propagation + Transmission + Processing + Queuing

┌──────────────────────────────────────────────────────────────────┐
│                                                                  │
│  Propagation Delay: Time for signal to travel through wire      │
│  ─────────────────                                               │
│  Light in fiber ≈ 200,000 km/s = 200 km/ms                      │
│  NYC to LA (4,000 km) ≈ 20ms one way, 40ms round trip           │
│                                                                  │
│  Transmission Delay: Time to push bits onto wire                │
│  ──────────────────                                              │
│  1 MB on 100 Mbps = 80ms                                        │
│  1 MB on 1 Gbps = 8ms                                           │
│                                                                  │
│  Processing Delay: Time for router/server to process            │
│  ─────────────────                                               │
│  Usually microseconds to milliseconds                           │
│                                                                  │
│  Queuing Delay: Time waiting in buffers                         │
│  ──────────────                                                  │
│  Highly variable (0 to seconds during congestion)               │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

**Real-World Latency Numbers** (memorize these!):

```python
"""
LATENCY NUMBERS EVERY PROGRAMMER SHOULD KNOW
─────────────────────────────────────────────
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns
Compress 1K bytes with Zippy             3,000   ns =   3 µs
Send 1K bytes over 1 Gbps network       10,000   ns =  10 µs
Read 4K randomly from SSD              150,000   ns = 150 µs
Read 1 MB sequentially from memory     250,000   ns = 250 µs
Round trip within same datacenter      500,000   ns = 500 µs = 0.5 ms
Read 1 MB sequentially from SSD      1,000,000   ns =   1 ms
Disk seek                           10,000,000   ns =  10 ms
Read 1 MB sequentially from disk    20,000,000   ns =  20 ms
Send packet CA→Netherlands→CA      150,000,000   ns = 150 ms

KEY INSIGHTS FOR DISTRIBUTED SYSTEMS:
- Memory is ~100x faster than SSD
- SSD is ~10x faster than HDD
- Network within datacenter: 0.5ms
- Network across regions: 50-150ms
- Caching is CRUCIAL!
"""
```

**Measuring Latency in Python**:

```python
import time
import statistics
from typing import Callable
import asyncio
import httpx

def measure_latency(func: Callable, iterations: int = 100) -> dict:
    """Measure function latency statistics"""
    latencies = []
    
    for _ in range(iterations):
        start = time.perf_counter()
        func()
        end = time.perf_counter()
        latencies.append((end - start) * 1000)  # Convert to ms
    
    return {
        'min': min(latencies),
        'max': max(latencies),
        'mean': statistics.mean(latencies),
        'median': statistics.median(latencies),
        'p95': statistics.quantiles(latencies, n=20)[18],  # 95th percentile
        'p99': statistics.quantiles(latencies, n=100)[98],  # 99th percentile
    }

# Example: Measure HTTP request latency
async def measure_http_latency():
    async with httpx.AsyncClient() as client:
        latencies = []
        for _ in range(10):
            start = time.perf_counter()
            await client.get('https://api.github.com')
            latencies.append((time.perf_counter() - start) * 1000)
        
        print(f"Average latency: {statistics.mean(latencies):.2f}ms")
        print(f"P99 latency: {statistics.quantiles(latencies, n=100)[98]:.2f}ms")

asyncio.run(measure_http_latency())
```

---

## 1.3 Operating System Concepts

### 1.3.1 Processes vs Threads vs Coroutines

**Frontend Analogy**:
- **Process** = Browser tab (completely isolated)
- **Thread** = Web Worker (shared memory, true parallelism)
- **Coroutine** = `async/await` (cooperative multitasking)

```
┌─────────────────────────────────────────────────────────────────┐
│ PROCESS                                                          │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ Own memory space, own resources                              │ │
│ │ Expensive to create (~10ms)                                  │ │
│ │ Inter-process communication is slow                          │ │
│ │                                                               │ │
│ │ THREAD 1         THREAD 2         THREAD 3                   │ │
│ │ ┌───────────┐   ┌───────────┐   ┌───────────┐              │ │
│ │ │ Own stack │   │ Own stack │   │ Own stack │              │ │
│ │ │ Shared    │   │ Shared    │   │ Shared    │              │ │
│ │ │ heap      │   │ heap      │   │ heap      │              │ │
│ │ └───────────┘   └───────────┘   └───────────┘              │ │
│ │                                                               │ │
│ │ Within each thread: COROUTINES                               │ │
│ │ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐                            │ │
│ │ │coro1│ │coro2│ │coro3│ │coro4│   (thousands possible!)    │ │
│ │ └─────┘ └─────┘ └─────┘ └─────┘                            │ │
│ └─────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
```

**Python Implementation**:

```python
import multiprocessing
import threading
import asyncio
import time

# 1. MULTIPROCESSING - True parallelism, separate memory
def cpu_bound_task(n):
    """Simulates CPU-intensive work"""
    total = 0
    for i in range(n):
        total += i * i
    return total

def run_with_processes():
    start = time.time()
    
    # Create 4 processes (uses all CPU cores)
    with multiprocessing.Pool(4) as pool:
        results = pool.map(cpu_bound_task, [10_000_000] * 4)
    
    print(f"Multiprocessing: {time.time() - start:.2f}s")
    return results


# 2. THREADING - Shared memory, limited by GIL for CPU tasks
def run_with_threads():
    start = time.time()
    threads = []
    
    for _ in range(4):
        t = threading.Thread(target=cpu_bound_task, args=(10_000_000,))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    print(f"Threading: {time.time() - start:.2f}s")  # Not faster due to GIL!


# 3. ASYNCIO - Best for I/O-bound tasks (network, disk)
async def io_bound_task(task_id):
    """Simulates I/O wait (API call, database query)"""
    print(f"Task {task_id} starting...")
    await asyncio.sleep(1)  # Non-blocking wait
    print(f"Task {task_id} done!")
    return task_id

async def run_with_asyncio():
    start = time.time()
    
    # Run 100 I/O tasks concurrently
    tasks = [io_bound_task(i) for i in range(100)]
    results = await asyncio.gather(*tasks)
    
    print(f"Asyncio: {time.time() - start:.2f}s")  # ~1 second for 100 tasks!
    return results

# asyncio.run(run_with_asyncio())
```

**When to Use What**:

| Scenario | Use | Why |
|----------|-----|-----|
| CPU-intensive (math, compression) | `multiprocessing` | Bypasses GIL, uses all cores |
| I/O-intensive (HTTP, DB) | `asyncio` | Handles thousands of concurrent I/O |
| Blocking libraries | `threading` | When async version unavailable |
| Web servers | `asyncio` + workers | FastAPI uses this model |

### 1.3.2 Python's GIL (Global Interpreter Lock)

**The Problem**:
```
Python's GIL = Only one thread executes Python code at a time

This means:
┌──────────────────────────────────────┐
│ Thread 1: [====]      [====]         │
│ Thread 2:       [====]      [====]   │  ← They take turns!
│ Thread 3:                      [====]│
└──────────────────────────────────────┘

Not truly parallel for CPU tasks!
```

**The Solution for Distributed Systems**:
```python
# For web servers: Use multiple processes (workers)
# Each process has its own GIL

# Uvicorn with multiple workers:
# uvicorn main:app --workers 4

# Gunicorn (production):
# gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker
```

---

## 1.4 Database Fundamentals

### 1.4.1 SQL Basics with PostgreSQL

**Frontend Analogy**: Database is like a persistent version of your Redux/Zustand store, but with powerful querying.

```python
# Install: pip install asyncpg databases

import asyncio
import asyncpg

async def main():
    # Connect to PostgreSQL
    conn = await asyncpg.connect(
        host='localhost',
        database='myapp',
        user='postgres',
        password='secret'
    )
    
    # Create table
    await conn.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id SERIAL PRIMARY KEY,
            username VARCHAR(50) UNIQUE NOT NULL,
            email VARCHAR(100) UNIQUE NOT NULL,
            created_at TIMESTAMP DEFAULT NOW()
        )
    ''')
    
    # Insert (Create)
    await conn.execute('''
        INSERT INTO users (username, email) 
        VALUES ($1, $2)
    ''', 'johndoe', 'john@example.com')
    
    # Select (Read)
    row = await conn.fetchrow(
        'SELECT * FROM users WHERE username = $1', 
        'johndoe'
    )
    print(f"Found user: {row['email']}")
    
    # Select multiple
    rows = await conn.fetch('SELECT * FROM users LIMIT 10')
    for row in rows:
        print(row)
    
    # Update
    await conn.execute('''
        UPDATE users SET email = $1 WHERE username = $2
    ''', 'newemail@example.com', 'johndoe')
    
    # Delete
    await conn.execute(
        'DELETE FROM users WHERE username = $1', 
        'johndoe'
    )
    
    await conn.close()

asyncio.run(main())
```

### 1.4.2 ACID Properties

**Critical for distributed systems** - understand what guarantees your database provides:

```
A - ATOMICITY
━━━━━━━━━━━━━
"All or nothing"

Example: Bank transfer
┌─────────────────────────────────┐
│ 1. Deduct $100 from Account A  │
│ 2. Add $100 to Account B       │
└─────────────────────────────────┘
If step 2 fails, step 1 is rolled back.
Money doesn't disappear!


C - CONSISTENCY  
━━━━━━━━━━━━━━━
"Valid state to valid state"

Example: Foreign key constraint
┌─────────────────────────────────┐
│ orders.user_id must exist in   │
│ users.id                        │
└─────────────────────────────────┘
Can't create order for non-existent user.


I - ISOLATION
━━━━━━━━━━━━━
"Transactions don't interfere"

Example: Two users buying last item
┌─────────────────────────────────┐
│ User A: Check stock → 1 item   │
│ User B: Check stock → 1 item   │
│ User A: Purchase → Success     │
│ User B: Purchase → Fails!      │
└─────────────────────────────────┘
Without isolation, both might succeed = overselling!


D - DURABILITY
━━━━━━━━━━━━━━
"Committed = Permanent"

Once transaction commits, it survives:
- Power failure
- System crash
- Hardware failure (with replication)
```

### 1.4.3 Transaction Isolation Levels

```python
import asyncpg

async def demonstrate_isolation():
    conn = await asyncpg.connect(...)
    
    # Start transaction with specific isolation level
    async with conn.transaction(isolation='serializable'):
        # Highest isolation - no anomalies possible
        # But slowest and may fail due to conflicts
        
        balance = await conn.fetchval(
            'SELECT balance FROM accounts WHERE id = $1', 
            account_id
        )
        
        if balance >= amount:
            await conn.execute(
                'UPDATE accounts SET balance = balance - $1 WHERE id = $2',
                amount, account_id
            )
```

**Isolation Levels** (from weakest to strongest):

```
┌─────────────────┬─────────────┬─────────────┬───────────────┐
│ Level           │ Dirty Read  │ Non-repeat  │ Phantom Read  │
├─────────────────┼─────────────┼─────────────┼───────────────┤
│ READ UNCOMMITTED│ Possible    │ Possible    │ Possible      │
│ READ COMMITTED  │ Prevented   │ Possible    │ Possible      │
│ REPEATABLE READ │ Prevented   │ Prevented   │ Possible      │
│ SERIALIZABLE    │ Prevented   │ Prevented   │ Prevented     │
└─────────────────┴─────────────┴─────────────┴───────────────┘

PostgreSQL default: READ COMMITTED
For financial: Use SERIALIZABLE

Dirty Read: See uncommitted changes from other transactions
Non-repeatable: Same query returns different results in same transaction
Phantom: New rows appear from other transactions
```

### 1.4.4 Indexing

**Frontend Analogy**: Index is like browser's address bar autocomplete - quick lookup without scanning everything.

```sql
-- Without index: Full table scan O(n)
SELECT * FROM users WHERE email = 'john@example.com';
-- Scans all 1 million rows!

-- Create index: Now O(log n)
CREATE INDEX idx_users_email ON users(email);
-- Now finds instantly using B-tree!

-- Composite index for multiple columns
CREATE INDEX idx_users_name_email ON users(username, email);

-- Partial index (index only active users)
CREATE INDEX idx_active_users ON users(email) WHERE active = true;
```

```python
# Check if index is being used
async def explain_query(conn):
    plan = await conn.fetch('''
        EXPLAIN ANALYZE 
        SELECT * FROM users WHERE email = 'john@example.com'
    ''')
    for row in plan:
        print(row['QUERY PLAN'])
    
    # Output shows:
    # Index Scan using idx_users_email on users
    # Index Cond: (email = 'john@example.com')
    # Execution Time: 0.042 ms  ← Fast!
```

### 1.4.5 NoSQL Introduction

**When to use SQL vs NoSQL**:

```
SQL (PostgreSQL, MySQL)
━━━━━━━━━━━━━━━━━━━━━━━
✓ Structured data with relationships
✓ Complex queries with JOINs
✓ ACID transactions
✓ Data integrity crucial

Examples: E-commerce orders, banking, inventory


NoSQL Document Store (MongoDB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
✓ Flexible schema
✓ Hierarchical data
✓ Rapid development
✓ Horizontal scaling

Examples: Content management, user profiles, catalogs


NoSQL Key-Value (Redis)
━━━━━━━━━━━━━━━━━━━━━━━
✓ Simple get/set
✓ Extremely fast (in-memory)
✓ Caching
✓ Session storage

Examples: Cache, rate limiting, leaderboards
```

**Redis Example**:

```python
import redis.asyncio as redis

async def redis_examples():
    r = redis.Redis(host='localhost', port=6379, decode_responses=True)
    
    # String (most basic)
    await r.set('user:123:name', 'John Doe')
    name = await r.get('user:123:name')  # 'John Doe'
    
    # With expiration (great for caching!)
    await r.setex('session:abc123', 3600, 'user_id:123')  # Expires in 1 hour
    
    # Hash (like a mini-document)
    await r.hset('user:123', mapping={
        'name': 'John Doe',
        'email': 'john@example.com',
        'age': '30'
    })
    user = await r.hgetall('user:123')  # {'name': 'John Doe', ...}
    
    # List (queue operations)
    await r.lpush('queue:tasks', 'task1', 'task2', 'task3')
    task = await r.rpop('queue:tasks')  # 'task1' (FIFO)
    
    # Set (unique items)
    await r.sadd('user:123:followers', 'user:456', 'user:789')
    followers = await r.smembers('user:123:followers')
    
    # Sorted Set (leaderboard!)
    await r.zadd('leaderboard', {'player1': 100, 'player2': 85, 'player3': 92})
    top_players = await r.zrevrange('leaderboard', 0, 2, withscores=True)
    # [('player1', 100.0), ('player3', 92.0), ('player2', 85.0)]
    
    await r.close()
```

---

## 1.5 Putting It All Together: Mini Project

Let's build a simple API that combines everything:

```python
# main.py - A complete FastAPI application with PostgreSQL and Redis

from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel, EmailStr
from typing import Optional
import asyncpg
import redis.asyncio as redis
import json

app = FastAPI(title="User Service")

# Connection pools (initialized on startup)
db_pool: asyncpg.Pool = None
redis_client: redis.Redis = None

# Models
class UserCreate(BaseModel):
    username: str
    email: EmailStr

class User(BaseModel):
    id: int
    username: str
    email: str

# Startup/shutdown events
@app.on_event("startup")
async def startup():
    global db_pool, redis_client
    
    db_pool = await asyncpg.create_pool(
        host='localhost',
        database='myapp',
        user='postgres',
        password='secret',
        min_size=5,
        max_size=20
    )
    
    redis_client = redis.Redis(
        host='localhost', 
        port=6379, 
        decode_responses=True
    )
    
    # Create tables
    async with db_pool.acquire() as conn:
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id SERIAL PRIMARY KEY,
                username VARCHAR(50) UNIQUE NOT NULL,
                email VARCHAR(100) UNIQUE NOT NULL
            )
        ''')

@app.on_event("shutdown")
async def shutdown():
    await db_pool.close()
    await redis_client.close()

# Routes with caching
@app.get("/users/{user_id}", response_model=User)
async def get_user(user_id: int):
    cache_key = f"user:{user_id}"
    
    # Try cache first
    cached = await redis_client.get(cache_key)
    if cached:
        return json.loads(cached)
    
    # Query database
    async with db_pool.acquire() as conn:
        row = await conn.fetchrow(
            'SELECT * FROM users WHERE id = $1', 
            user_id
        )
    
    if not row:
        raise HTTPException(status_code=404, detail="User not found")
    
    user = User(id=row['id'], username=row['username'], email=row['email'])
    
    # Cache for 5 minutes
    await redis_client.setex(cache_key, 300, json.dumps(user.model_dump()))
    
    return user

@app.post("/users", response_model=User, status_code=201)
async def create_user(user: UserCreate):
    async with db_pool.acquire() as conn:
        try:
            row = await conn.fetchrow('''
                INSERT INTO users (username, email) 
                VALUES ($1, $2) 
                RETURNING *
            ''', user.username, user.email)
        except asyncpg.UniqueViolationError:
            raise HTTPException(
                status_code=400, 
                detail="Username or email already exists"
            )
    
    return User(id=row['id'], username=row['username'], email=row['email'])

@app.delete("/users/{user_id}", status_code=204)
async def delete_user(user_id: int):
    async with db_pool.acquire() as conn:
        result = await conn.execute(
            'DELETE FROM users WHERE id = $1', 
            user_id
        )
    
    if result == 'DELETE 0':
        raise HTTPException(status_code=404, detail="User not found")
    
    # Invalidate cache
    await redis_client.delete(f"user:{user_id}")
```

---

## Summary: Key Takeaways

1. **Python async** is crucial for distributed systems - learn `asyncio` well
2. **FastAPI** is your go-to framework - modern, fast, and type-safe
3. **Network latency** is your enemy - memorize the latency numbers
4. **ACID properties** tell you what guarantees your database provides
5. **Caching with Redis** dramatically improves performance
6. **Use processes for CPU-bound**, **asyncio for I/O-bound** tasks

---

## Practice Exercises

1. Build a REST API with FastAPI that has CRUD operations
2. Add PostgreSQL with proper connection pooling
3. Implement Redis caching with cache invalidation
4. Measure latency of your endpoints
5. Run load tests with `locust` or `wrk`

**Next Chapter**: We'll learn what distributed systems actually are and why they're so challenging!
