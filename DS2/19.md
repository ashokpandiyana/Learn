# Chapter 19: Deployment and Operations

> **Goal**: Master deployment strategies, containerization, and operational practices for distributed systems

---

## 19.1 Deployment Strategies

### 19.1.1 Why Deployment Strategy Matters

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           WHY DEPLOYMENT STRATEGY MATTERS                    â”‚
â”‚                                                              â”‚
â”‚  Bad Deployment:                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â”‚
â”‚  1. Push new code to all servers at once                    â”‚
â”‚  2. Bug in new code crashes everything                      â”‚
â”‚  3. All users affected, revenue lost                        â”‚
â”‚  4. Rollback takes 30 minutes                               â”‚
â”‚  5. Postmortem, blame, sadness                              â”‚
â”‚                                                              â”‚
â”‚  Good Deployment:                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  1. Push new code to 1% of servers                          â”‚
â”‚  2. Monitor for errors/latency                              â”‚
â”‚  3. Bug detected, only 1% of users affected                 â”‚
â”‚  4. Automatic rollback in seconds                           â”‚
â”‚  5. Fix bug, try again                                      â”‚
â”‚                                                              â”‚
â”‚  The difference is MILLIONS of dollars for large systems!   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 19.1.2 Rolling Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ROLLING DEPLOYMENT                          â”‚
â”‚                                                              â”‚
â”‚  Replace instances one at a time (or in batches).           â”‚
â”‚                                                              â”‚
â”‚  Time 0: All running v1                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                              â”‚
â”‚  Time 1: First instance updated                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ v2  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                              â”‚
â”‚  Time 2: Second instance updated                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ v2  â”‚ â”‚ v2  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                              â”‚
â”‚  Time 5: All running v2                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ v2  â”‚ â”‚ v2  â”‚ â”‚ v2  â”‚ â”‚ v2  â”‚ â”‚ v2  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                              â”‚
â”‚  Pros:                      Cons:                           â”‚
â”‚  â”œâ”€â”€ Zero downtime          â”œâ”€â”€ Slow rollout                â”‚
â”‚  â”œâ”€â”€ Gradual rollout        â”œâ”€â”€ Multiple versions running   â”‚
â”‚  â”œâ”€â”€ Easy rollback          â”œâ”€â”€ Must handle version compat  â”‚
â”‚  â””â”€â”€ Resource efficient     â””â”€â”€ Complex for stateful apps   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 19.1.3 Blue-Green Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 BLUE-GREEN DEPLOYMENT                        â”‚
â”‚                                                              â”‚
â”‚  Two identical environments. Switch traffic instantly.      â”‚
â”‚                                                              â”‚
â”‚  BEFORE: Blue is live                                       â”‚
â”‚                                                              â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  Users â”€â”€â”€â”€â”€â–¶â”‚ Load Balancerâ”‚                               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                     â”‚                                        â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚           â–¼                   â”‚                              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚    â”‚    BLUE     â”‚     â”‚   GREEN     â”‚                     â”‚
â”‚    â”‚ (v1 - LIVE) â”‚     â”‚ (v2 - IDLE) â”‚                     â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â” â”‚     â”‚  â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â” â”‚                     â”‚
â”‚    â”‚  â”‚ S â”‚â”‚ S â”‚ â”‚     â”‚  â”‚ S â”‚â”‚ S â”‚ â”‚                     â”‚
â”‚    â”‚  â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜ â”‚     â”‚  â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜ â”‚                     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                              â”‚
â”‚  AFTER: Green is live (instant switch!)                     â”‚
â”‚                                                              â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  Users â”€â”€â”€â”€â”€â–¶â”‚ Load Balancerâ”‚                               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                     â”‚                                        â”‚
â”‚           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚           â”‚                   â–¼                              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚    â”‚    BLUE     â”‚     â”‚   GREEN     â”‚                     â”‚
â”‚    â”‚ (v1 - IDLE) â”‚     â”‚ (v2 - LIVE) â”‚                     â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â” â”‚     â”‚  â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â” â”‚                     â”‚
â”‚    â”‚  â”‚ S â”‚â”‚ S â”‚ â”‚     â”‚  â”‚ S â”‚â”‚ S â”‚ â”‚                     â”‚
â”‚    â”‚  â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜ â”‚     â”‚  â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜ â”‚                     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                              â”‚
â”‚  Pros:                      Cons:                           â”‚
â”‚  â”œâ”€â”€ Instant rollback       â”œâ”€â”€ Double infrastructure cost  â”‚
â”‚  â”œâ”€â”€ Zero downtime          â”œâ”€â”€ Database migrations tricky  â”‚
â”‚  â”œâ”€â”€ Full testing in prod   â”œâ”€â”€ State sync between envs     â”‚
â”‚  â””â”€â”€ Simple mental model    â””â”€â”€ Resource intensive          â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 19.1.4 Canary Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CANARY DEPLOYMENT                          â”‚
â”‚                                                              â”‚
â”‚  Named after "canary in coal mine" - detect danger early.   â”‚
â”‚  Route small % of traffic to new version, monitor, expand.  â”‚
â”‚                                                              â”‚
â”‚                                                              â”‚
â”‚  Stage 1: 1% traffic to canary                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚  99% â”€â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚           â”‚         Production (v1)              â”‚  â”‚    â”‚
â”‚  â”‚           â”‚    [S] [S] [S] [S] [S] [S] [S]      â”‚  â”‚    â”‚
â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚   1% â”€â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚    â”‚
â”‚  â”‚           â”‚ Canary  â”‚ â† Watch for errors!          â”‚    â”‚
â”‚  â”‚           â”‚  (v2)   â”‚                              â”‚    â”‚
â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â”‚  Stage 2: 10% (if canary healthy)                           â”‚
â”‚  Stage 3: 50%                                               â”‚
â”‚  Stage 4: 100% - Full rollout!                              â”‚
â”‚                                                              â”‚
â”‚                                                              â”‚
â”‚  Monitoring During Canary:                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  Compare canary vs production:                              â”‚
â”‚  â”œâ”€â”€ Error rates (should be similar or lower)               â”‚
â”‚  â”œâ”€â”€ Latency p50, p99 (should be similar or lower)         â”‚
â”‚  â”œâ”€â”€ CPU/Memory usage                                       â”‚
â”‚  â””â”€â”€ Business metrics (conversion, revenue)                 â”‚
â”‚                                                              â”‚
â”‚  If canary worse â†’ Automatic rollback!                      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
# canary_deployment.py
import asyncio
import random
from dataclasses import dataclass, field
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import statistics

@dataclass
class DeploymentMetrics:
    """Metrics collected during deployment"""
    error_count: int = 0
    request_count: int = 0
    latencies: List[float] = field(default_factory=list)
    
    @property
    def error_rate(self) -> float:
        if self.request_count == 0:
            return 0.0
        return self.error_count / self.request_count
    
    @property
    def p50_latency(self) -> float:
        if not self.latencies:
            return 0.0
        return statistics.median(self.latencies)
    
    @property
    def p99_latency(self) -> float:
        if len(self.latencies) < 100:
            return max(self.latencies) if self.latencies else 0.0
        sorted_latencies = sorted(self.latencies)
        return sorted_latencies[int(len(sorted_latencies) * 0.99)]

@dataclass
class CanaryConfig:
    """Configuration for canary deployment"""
    stages: List[int] = field(default_factory=lambda: [1, 5, 10, 25, 50, 100])
    stage_duration_seconds: int = 60
    error_rate_threshold: float = 0.01  # 1% error rate threshold
    latency_increase_threshold: float = 1.5  # 50% latency increase threshold

class CanaryDeploymentController:
    """
    Controls canary deployment with automatic rollback.
    """
    
    def __init__(self, config: CanaryConfig = None):
        self.config = config or CanaryConfig()
        self.current_stage = 0
        self.canary_percentage = 0
        self.production_metrics = DeploymentMetrics()
        self.canary_metrics = DeploymentMetrics()
        self.is_rolling_back = False
        self.deployment_start: Optional[datetime] = None
    
    def start_deployment(self):
        """Start canary deployment"""
        self.deployment_start = datetime.utcnow()
        self.current_stage = 0
        self.canary_percentage = self.config.stages[0]
        self.production_metrics = DeploymentMetrics()
        self.canary_metrics = DeploymentMetrics()
        self.is_rolling_back = False
        
        print(f"ğŸš€ Starting canary deployment")
        print(f"   Stage 1: {self.canary_percentage}% traffic to canary")
    
    def route_request(self) -> str:
        """Decide which version handles the request"""
        if self.is_rolling_back:
            return "production"
        
        if random.randint(1, 100) <= self.canary_percentage:
            return "canary"
        return "production"
    
    def record_request(
        self, 
        version: str, 
        latency_ms: float, 
        is_error: bool
    ):
        """Record metrics for a request"""
        metrics = self.canary_metrics if version == "canary" else self.production_metrics
        metrics.request_count += 1
        metrics.latencies.append(latency_ms)
        if is_error:
            metrics.error_count += 1
    
    def evaluate_canary(self) -> tuple[bool, str]:
        """
        Evaluate if canary is healthy.
        Returns (is_healthy, reason)
        """
        if self.canary_metrics.request_count < 100:
            return True, "Not enough data yet"
        
        # Check error rate
        if self.canary_metrics.error_rate > self.config.error_rate_threshold:
            return False, f"Error rate too high: {self.canary_metrics.error_rate:.2%}"
        
        # Compare error rates
        if self.production_metrics.request_count > 0:
            error_ratio = (self.canary_metrics.error_rate / 
                         max(self.production_metrics.error_rate, 0.001))
            if error_ratio > 2.0:  # Canary has 2x more errors
                return False, f"Error rate {error_ratio:.1f}x higher than production"
        
        # Check latency
        if self.production_metrics.p50_latency > 0:
            latency_ratio = (self.canary_metrics.p50_latency / 
                           self.production_metrics.p50_latency)
            if latency_ratio > self.config.latency_increase_threshold:
                return False, f"Latency {latency_ratio:.1f}x higher than production"
        
        return True, "Canary is healthy"
    
    def advance_stage(self) -> bool:
        """
        Advance to next canary stage.
        Returns True if deployment complete.
        """
        is_healthy, reason = self.evaluate_canary()
        
        if not is_healthy:
            print(f"âŒ Canary unhealthy: {reason}")
            self.rollback()
            return False
        
        self.current_stage += 1
        
        if self.current_stage >= len(self.config.stages):
            print(f"âœ… Canary deployment complete! 100% on new version")
            return True
        
        self.canary_percentage = self.config.stages[self.current_stage]
        print(f"ğŸ“ˆ Stage {self.current_stage + 1}: {self.canary_percentage}% traffic to canary")
        print(f"   Canary metrics: errors={self.canary_metrics.error_rate:.2%}, "
              f"p50={self.canary_metrics.p50_latency:.1f}ms")
        
        return False
    
    def rollback(self):
        """Rollback to production version"""
        self.is_rolling_back = True
        self.canary_percentage = 0
        print(f"ğŸ”„ ROLLBACK initiated! All traffic to production")
    
    def get_status(self) -> dict:
        """Get current deployment status"""
        return {
            "stage": self.current_stage + 1,
            "total_stages": len(self.config.stages),
            "canary_percentage": self.canary_percentage,
            "is_rolling_back": self.is_rolling_back,
            "canary_metrics": {
                "requests": self.canary_metrics.request_count,
                "error_rate": f"{self.canary_metrics.error_rate:.2%}",
                "p50_latency": f"{self.canary_metrics.p50_latency:.1f}ms",
                "p99_latency": f"{self.canary_metrics.p99_latency:.1f}ms"
            },
            "production_metrics": {
                "requests": self.production_metrics.request_count,
                "error_rate": f"{self.production_metrics.error_rate:.2%}",
                "p50_latency": f"{self.production_metrics.p50_latency:.1f}ms"
            }
        }

# ============== SIMULATION ==============

async def simulate_canary_deployment():
    """Simulate a canary deployment with traffic"""
    controller = CanaryDeploymentController(
        CanaryConfig(
            stages=[1, 5, 10, 25, 50, 100],
            stage_duration_seconds=2  # Fast for demo
        )
    )
    
    controller.start_deployment()
    
    # Simulate traffic
    async def simulate_traffic(duration_seconds: int, canary_has_bug: bool = False):
        end_time = datetime.utcnow() + timedelta(seconds=duration_seconds)
        
        while datetime.utcnow() < end_time:
            version = controller.route_request()
            
            # Simulate request
            base_latency = 50  # 50ms base latency
            
            if version == "canary":
                # Canary might have issues
                if canary_has_bug:
                    is_error = random.random() < 0.05  # 5% error rate
                    latency = base_latency * random.uniform(1.5, 3.0)  # Higher latency
                else:
                    is_error = random.random() < 0.005  # 0.5% error rate
                    latency = base_latency * random.uniform(0.9, 1.1)
            else:
                # Production is stable
                is_error = random.random() < 0.005  # 0.5% error rate
                latency = base_latency * random.uniform(0.9, 1.1)
            
            controller.record_request(version, latency, is_error)
            await asyncio.sleep(0.01)  # 100 requests per second
    
    # Run deployment stages
    print("\n" + "="*60)
    print("SCENARIO 1: Successful Canary Deployment")
    print("="*60)
    
    while True:
        await simulate_traffic(2, canary_has_bug=False)
        
        if controller.advance_stage():
            break
        
        if controller.is_rolling_back:
            break
    
    print(f"\nFinal status: {controller.get_status()}")
    
    # Scenario 2: Failed deployment
    print("\n" + "="*60)
    print("SCENARIO 2: Failed Canary (Bug Detected)")
    print("="*60)
    
    controller2 = CanaryDeploymentController()
    controller2.start_deployment()
    
    while True:
        await simulate_traffic(2, canary_has_bug=True)  # Canary has bugs!
        
        if controller2.advance_stage():
            break
        
        if controller2.is_rolling_back:
            print(f"\nDeployment aborted due to canary issues")
            break
    
    print(f"\nFinal status: {controller2.get_status()}")

# asyncio.run(simulate_canary_deployment())
```

### 19.1.5 Feature Flags

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FEATURE FLAGS                             â”‚
â”‚                                                              â”‚
â”‚  Decouple DEPLOYMENT from RELEASE.                          â”‚
â”‚  Code is deployed but features are toggled on/off.          â”‚
â”‚                                                              â”‚
â”‚                                                              â”‚
â”‚  Traditional:                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚  Deploy = Release (same thing, scary!)                      â”‚
â”‚                                                              â”‚
â”‚  With Feature Flags:                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  Deploy code â†’ Feature OFF â†’ Test internally                â”‚
â”‚              â†’ Feature ON for 1% â†’ Monitor                  â”‚
â”‚              â†’ Feature ON for 10% â†’ Monitor                 â”‚
â”‚              â†’ Feature ON for 100% â†’ Done!                  â”‚
â”‚                                                              â”‚
â”‚                                                              â”‚
â”‚  Types of Feature Flags:                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚                                                              â”‚
â”‚  1. RELEASE FLAGS                                           â”‚
â”‚     Toggle new features on/off                              â”‚
â”‚     Example: new_checkout_flow = True/False                 â”‚
â”‚                                                              â”‚
â”‚  2. EXPERIMENT FLAGS                                        â”‚
â”‚     A/B testing                                             â”‚
â”‚     Example: button_color = "blue" | "green" | "red"        â”‚
â”‚                                                              â”‚
â”‚  3. OPS FLAGS                                               â”‚
â”‚     Operational controls                                    â”‚
â”‚     Example: enable_cache = True/False                      â”‚
â”‚                                                              â”‚
â”‚  4. PERMISSION FLAGS                                        â”‚
â”‚     User-specific features                                  â”‚
â”‚     Example: premium_features = True (for paid users)       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
# feature_flags.py
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Callable
from enum import Enum
import hashlib
import random
from datetime import datetime

class RolloutStrategy(Enum):
    ALL = "all"
    NONE = "none"
    PERCENTAGE = "percentage"
    USER_IDS = "user_ids"
    GRADUAL = "gradual"

@dataclass
class FeatureFlag:
    """Definition of a feature flag"""
    name: str
    description: str
    enabled: bool = False
    strategy: RolloutStrategy = RolloutStrategy.NONE
    percentage: int = 0  # For percentage rollout
    user_ids: List[str] = field(default_factory=list)  # For specific users
    variants: Dict[str, int] = field(default_factory=dict)  # For A/B tests
    created_at: datetime = field(default_factory=datetime.utcnow)

class FeatureFlagService:
    """
    Feature flag service for controlled rollouts.
    In production, use services like LaunchDarkly, Unleash, or Flagsmith.
    """
    
    def __init__(self):
        self.flags: Dict[str, FeatureFlag] = {}
        self._listeners: List[Callable] = []
    
    def create_flag(
        self,
        name: str,
        description: str,
        strategy: RolloutStrategy = RolloutStrategy.NONE,
        percentage: int = 0,
        user_ids: List[str] = None,
        variants: Dict[str, int] = None
    ) -> FeatureFlag:
        """Create a new feature flag"""
        flag = FeatureFlag(
            name=name,
            description=description,
            enabled=strategy != RolloutStrategy.NONE,
            strategy=strategy,
            percentage=percentage,
            user_ids=user_ids or [],
            variants=variants or {}
        )
        self.flags[name] = flag
        return flag
    
    def is_enabled(
        self, 
        flag_name: str, 
        user_id: str = None,
        default: bool = False
    ) -> bool:
        """Check if a feature flag is enabled for a user"""
        flag = self.flags.get(flag_name)
        
        if not flag or not flag.enabled:
            return default
        
        if flag.strategy == RolloutStrategy.ALL:
            return True
        
        if flag.strategy == RolloutStrategy.NONE:
            return False
        
        if flag.strategy == RolloutStrategy.USER_IDS:
            return user_id in flag.user_ids
        
        if flag.strategy == RolloutStrategy.PERCENTAGE:
            if not user_id:
                return random.randint(1, 100) <= flag.percentage
            # Consistent hashing - same user always gets same result
            hash_value = int(hashlib.md5(
                f"{flag_name}:{user_id}".encode()
            ).hexdigest(), 16)
            return (hash_value % 100) < flag.percentage
        
        if flag.strategy == RolloutStrategy.GRADUAL:
            return self._gradual_rollout(flag, user_id)
        
        return default
    
    def get_variant(
        self, 
        flag_name: str, 
        user_id: str,
        default: str = "control"
    ) -> str:
        """Get A/B test variant for a user"""
        flag = self.flags.get(flag_name)
        
        if not flag or not flag.enabled or not flag.variants:
            return default
        
        # Consistent hashing for variant assignment
        hash_value = int(hashlib.md5(
            f"{flag_name}:{user_id}".encode()
        ).hexdigest(), 16)
        
        bucket = hash_value % 100
        cumulative = 0
        
        for variant, percentage in flag.variants.items():
            cumulative += percentage
            if bucket < cumulative:
                return variant
        
        return default
    
    def _gradual_rollout(self, flag: FeatureFlag, user_id: str) -> bool:
        """
        Gradual rollout based on time since creation.
        Increases percentage over time.
        """
        hours_since_creation = (
            datetime.utcnow() - flag.created_at
        ).total_seconds() / 3600
        
        # Increase 10% per hour, max 100%
        current_percentage = min(100, int(hours_since_creation * 10))
        
        if not user_id:
            return random.randint(1, 100) <= current_percentage
        
        hash_value = int(hashlib.md5(
            f"{flag.name}:{user_id}".encode()
        ).hexdigest(), 16)
        return (hash_value % 100) < current_percentage
    
    def update_flag(
        self, 
        flag_name: str, 
        enabled: bool = None,
        strategy: RolloutStrategy = None,
        percentage: int = None
    ):
        """Update a feature flag"""
        if flag_name not in self.flags:
            raise ValueError(f"Flag {flag_name} not found")
        
        flag = self.flags[flag_name]
        
        if enabled is not None:
            flag.enabled = enabled
        if strategy is not None:
            flag.strategy = strategy
        if percentage is not None:
            flag.percentage = percentage
        
        # Notify listeners
        for listener in self._listeners:
            listener(flag_name, flag)
    
    def on_change(self, callback: Callable):
        """Register a callback for flag changes"""
        self._listeners.append(callback)

# ============== USAGE IN FASTAPI ==============

from fastapi import FastAPI, Depends, Request

app = FastAPI()
feature_flags = FeatureFlagService()

# Setup flags
feature_flags.create_flag(
    name="new_checkout",
    description="New checkout flow",
    strategy=RolloutStrategy.PERCENTAGE,
    percentage=10  # 10% of users
)

feature_flags.create_flag(
    name="button_color_test",
    description="A/B test for button colors",
    strategy=RolloutStrategy.ALL,
    variants={"blue": 33, "green": 33, "red": 34}
)

feature_flags.create_flag(
    name="premium_features",
    description="Premium user features",
    strategy=RolloutStrategy.USER_IDS,
    user_ids=["user_premium_1", "user_premium_2"]
)

def get_user_id(request: Request) -> str:
    """Extract user ID from request"""
    return request.headers.get("X-User-ID", "anonymous")

@app.get("/checkout")
async def checkout(user_id: str = Depends(get_user_id)):
    if feature_flags.is_enabled("new_checkout", user_id):
        return {"flow": "new", "message": "Using new checkout!"}
    else:
        return {"flow": "legacy", "message": "Using legacy checkout"}

@app.get("/homepage")
async def homepage(user_id: str = Depends(get_user_id)):
    button_color = feature_flags.get_variant(
        "button_color_test", 
        user_id,
        default="blue"
    )
    return {
        "button_color": button_color,
        "premium": feature_flags.is_enabled("premium_features", user_id)
    }

# Admin endpoints
@app.post("/admin/flags/{flag_name}/enable")
async def enable_flag(flag_name: str, percentage: int = 100):
    feature_flags.update_flag(
        flag_name,
        enabled=True,
        strategy=RolloutStrategy.PERCENTAGE,
        percentage=percentage
    )
    return {"status": "enabled", "percentage": percentage}

@app.post("/admin/flags/{flag_name}/disable")
async def disable_flag(flag_name: str):
    feature_flags.update_flag(flag_name, enabled=False)
    return {"status": "disabled"}
```

---

## 19.2 Containerization with Docker

### 19.2.1 Why Containers?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WHY CONTAINERS?                            â”‚
â”‚                                                              â”‚
â”‚  The Problem (Before Containers):                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚  "It works on my machine!" ğŸ¤·                               â”‚
â”‚                                                              â”‚
â”‚  Developer laptop:  Python 3.9, Ubuntu 20.04, lib v1.2     â”‚
â”‚  Production server: Python 3.8, CentOS 7, lib v1.0         â”‚
â”‚  â†’ Different behavior, bugs only in production!            â”‚
â”‚                                                              â”‚
â”‚                                                              â”‚
â”‚  The Solution (Containers):                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  Package EVERYTHING together:                               â”‚
â”‚  - Application code                                         â”‚
â”‚  - Runtime (Python)                                         â”‚
â”‚  - Libraries (exact versions)                               â”‚
â”‚  - System dependencies                                      â”‚
â”‚  - Configuration                                            â”‚
â”‚                                                              â”‚
â”‚  Same container runs identically everywhere!                â”‚
â”‚                                                              â”‚
â”‚                                                              â”‚
â”‚  Container vs VM:                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚                                                              â”‚
â”‚  Virtual Machine              Container                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚     App A       â”‚         â”‚     App A       â”‚           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚  â”‚   Guest OS      â”‚         â”‚   Container     â”‚           â”‚
â”‚  â”‚   (2 GB)        â”‚         â”‚   Runtime       â”‚           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚   (100 MB)      â”‚           â”‚
â”‚  â”‚   Hypervisor    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚                     â”‚
â”‚  â”‚   Host OS       â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚   Host OS       â”‚           â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚  Heavy, slow startup         Light, fast startup           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 19.2.2 Dockerfile Best Practices

```dockerfile
# Dockerfile - Production-ready Python application

# ============== STAGE 1: Builder ==============
# Use multi-stage builds to keep final image small
FROM python:3.11-slim as builder

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Create virtual environment
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt


# ============== STAGE 2: Runtime ==============
FROM python:3.11-slim as runtime

# Security: Don't run as root
RUN groupadd --gid 1000 appgroup \
    && useradd --uid 1000 --gid 1000 --shell /bin/bash appuser

# Install runtime dependencies only
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq5 \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Set working directory
WORKDIR /app

# Copy application code
COPY --chown=appuser:appgroup . .

# Switch to non-root user
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```python
# main.py - FastAPI application
from fastapi import FastAPI
import os

app = FastAPI(title="My Service")

@app.get("/")
async def root():
    return {
        "service": "my-service",
        "version": os.getenv("APP_VERSION", "1.0.0"),
        "environment": os.getenv("ENVIRONMENT", "development")
    }

@app.get("/health")
async def health():
    return {"status": "healthy"}

@app.get("/ready")
async def ready():
    # Check dependencies here
    return {"status": "ready"}
```

```yaml
# docker-compose.yml - Local development
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/myapp
      - REDIS_URL=redis://redis:6379
      - ENVIRONMENT=development
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    volumes:
      - .:/app  # Mount code for hot reload in development
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=myapp
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:
```

---

## 19.3 Kubernetes Essentials

### 19.3.1 Kubernetes Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              KUBERNETES ARCHITECTURE                         â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   CONTROL PLANE                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚    API    â”‚ â”‚  etcd     â”‚ â”‚    Scheduler      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Server   â”‚ â”‚ (state)   â”‚ â”‚ (pod placement)   â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚         Controller Manager                     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (ensures desired state = actual state)       â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                  â”‚
â”‚                           â”‚ API calls                        â”‚
â”‚                           â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    WORKER NODES                      â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                   Node 1                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  Pod A  â”‚  â”‚  Pod B  â”‚  â”‚  Pod C  â”‚     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚â”‚Containerâ”‚  â”‚â”‚Containerâ”‚  â”‚â”‚Containerâ”‚    â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ kubelet â”‚ kube-proxy â”‚ Container RT â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                   Node 2                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚           (similar structure)                â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 19.3.2 Kubernetes Resources

```yaml
# Complete Kubernetes deployment for a Python service

# ============== NAMESPACE ==============
apiVersion: v1
kind: Namespace
metadata:
  name: myapp
  labels:
    name: myapp

---
# ============== CONFIGMAP ==============
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: myapp
data:
  LOG_LEVEL: "INFO"
  MAX_CONNECTIONS: "100"
  CACHE_TTL: "300"

---
# ============== SECRET ==============
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: myapp
type: Opaque
stringData:
  DATABASE_URL: "postgresql://user:password@postgres:5432/myapp"
  API_KEY: "your-secret-api-key"

---
# ============== DEPLOYMENT ==============
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  namespace: myapp
  labels:
    app: user-service
spec:
  replicas: 3  # Run 3 instances
  selector:
    matchLabels:
      app: user-service
  
  # Deployment strategy
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # Can have 1 extra pod during update
      maxUnavailable: 0  # Always keep all pods running
  
  template:
    metadata:
      labels:
        app: user-service
        version: v1.2.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
    spec:
      # Security context
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      
      # Service account
      serviceAccountName: user-service-sa
      
      containers:
      - name: user-service
        image: myregistry/user-service:v1.2.0
        imagePullPolicy: Always
        
        ports:
        - containerPort: 8000
          name: http
          protocol: TCP
        
        # Environment variables
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DATABASE_URL
        
        envFrom:
        - configMapRef:
            name: app-config
        
        # Resource limits
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        
        # Probes
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        
        startupProbe:
          httpGet:
            path: /health/live
            port: 8000
          initialDelaySeconds: 0
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 30  # Allow 150s for startup
        
        # Volume mounts
        volumeMounts:
        - name: tmp
          mountPath: /tmp
      
      volumes:
      - name: tmp
        emptyDir: {}
      
      # Pod scheduling
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: user-service
              topologyKey: kubernetes.io/hostname

---
# ============== SERVICE ==============
apiVersion: v1
kind: Service
metadata:
  name: user-service
  namespace: myapp
spec:
  selector:
    app: user-service
  ports:
  - port: 80
    targetPort: 8000
    protocol: TCP
  type: ClusterIP

---
# ============== HORIZONTAL POD AUTOSCALER ==============
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
  namespace: myapp
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60

---
# ============== INGRESS ==============
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: user-service-ingress
  namespace: myapp
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  tls:
  - hosts:
    - api.example.com
    secretName: api-tls-secret
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /users
        pathType: Prefix
        backend:
          service:
            name: user-service
            port:
              number: 80

---
# ============== POD DISRUPTION BUDGET ==============
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: user-service-pdb
  namespace: myapp
spec:
  minAvailable: 2  # Always keep at least 2 pods running
  selector:
    matchLabels:
      app: user-service
```

---

## 19.4 Configuration Management

### 19.4.1 12-Factor App Configuration

```python
# config.py - Production-ready configuration management
from pydantic_settings import BaseSettings
from pydantic import Field, validator
from typing import Optional, List
from functools import lru_cache
import os

class Settings(BaseSettings):
    """
    Application settings following 12-Factor App methodology.
    All configuration comes from environment variables.
    """
    
    # Application
    app_name: str = Field(default="my-service")
    environment: str = Field(default="development")
    debug: bool = Field(default=False)
    log_level: str = Field(default="INFO")
    
    # Server
    host: str = Field(default="0.0.0.0")
    port: int = Field(default=8000)
    workers: int = Field(default=4)
    
    # Database
    database_url: str = Field(...)  # Required
    db_pool_size: int = Field(default=10)
    db_max_overflow: int = Field(default=20)
    
    # Redis
    redis_url: str = Field(default="redis://localhost:6379")
    redis_pool_size: int = Field(default=10)
    
    # Security
    secret_key: str = Field(...)  # Required
    api_key: Optional[str] = Field(default=None)
    allowed_origins: List[str] = Field(default=["*"])
    
    # External Services
    payment_service_url: Optional[str] = Field(default=None)
    notification_service_url: Optional[str] = Field(default=None)
    
    # Feature Flags
    enable_new_feature: bool = Field(default=False)
    feature_rollout_percentage: int = Field(default=0)
    
    @validator('environment')
    def validate_environment(cls, v):
        allowed = ['development', 'staging', 'production']
        if v not in allowed:
            raise ValueError(f'environment must be one of {allowed}')
        return v
    
    @validator('log_level')
    def validate_log_level(cls, v):
        allowed = ['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL']
        if v.upper() not in allowed:
            raise ValueError(f'log_level must be one of {allowed}')
        return v.upper()
    
    @property
    def is_production(self) -> bool:
        return self.environment == 'production'
    
    @property
    def is_development(self) -> bool:
        return self.environment == 'development'
    
    class Config:
        env_file = '.env'
        env_file_encoding = 'utf-8'
        case_sensitive = False

@lru_cache()
def get_settings() -> Settings:
    """
    Cached settings instance.
    Environment variables are read once at startup.
    """
    return Settings()

# Usage in FastAPI
from fastapi import FastAPI, Depends

app = FastAPI()

@app.get("/config")
async def get_config(settings: Settings = Depends(get_settings)):
    """Expose non-sensitive configuration"""
    return {
        "app_name": settings.app_name,
        "environment": settings.environment,
        "debug": settings.debug,
        "features": {
            "new_feature": settings.enable_new_feature,
            "rollout_percentage": settings.feature_rollout_percentage
        }
    }
```

### 19.4.2 Secrets Management

```python
# secrets_manager.py - Secure secrets handling
import os
from abc import ABC, abstractmethod
from typing import Optional, Dict
import json
from functools import lru_cache

class SecretsManager(ABC):
    """Abstract base for secrets management"""
    
    @abstractmethod
    def get_secret(self, key: str) -> Optional[str]:
        pass
    
    @abstractmethod
    def get_json_secret(self, key: str) -> Optional[Dict]:
        pass

class EnvironmentSecretsManager(SecretsManager):
    """Read secrets from environment variables (simple)"""
    
    def get_secret(self, key: str) -> Optional[str]:
        return os.getenv(key)
    
    def get_json_secret(self, key: str) -> Optional[Dict]:
        value = os.getenv(key)
        if value:
            return json.loads(value)
        return None

class AWSSecretsManager(SecretsManager):
    """Read secrets from AWS Secrets Manager"""
    
    def __init__(self, region: str = "us-east-1"):
        import boto3
        self.client = boto3.client('secretsmanager', region_name=region)
        self._cache: Dict[str, str] = {}
    
    def get_secret(self, key: str) -> Optional[str]:
        if key in self._cache:
            return self._cache[key]
        
        try:
            response = self.client.get_secret_value(SecretId=key)
            secret = response.get('SecretString')
            self._cache[key] = secret
            return secret
        except Exception as e:
            print(f"Error fetching secret {key}: {e}")
            return None
    
    def get_json_secret(self, key: str) -> Optional[Dict]:
        secret = self.get_secret(key)
        if secret:
            return json.loads(secret)
        return None

class VaultSecretsManager(SecretsManager):
    """Read secrets from HashiCorp Vault"""
    
    def __init__(self, url: str, token: str):
        import hvac
        self.client = hvac.Client(url=url, token=token)
    
    def get_secret(self, key: str) -> Optional[str]:
        try:
            # Assuming KV v2 secrets engine
            path_parts = key.split('/')
            mount_point = path_parts[0]
            secret_path = '/'.join(path_parts[1:])
            
            response = self.client.secrets.kv.v2.read_secret_version(
                path=secret_path,
                mount_point=mount_point
            )
            return response['data']['data'].get('value')
        except Exception as e:
            print(f"Error fetching secret {key}: {e}")
            return None
    
    def get_json_secret(self, key: str) -> Optional[Dict]:
        try:
            path_parts = key.split('/')
            mount_point = path_parts[0]
            secret_path = '/'.join(path_parts[1:])
            
            response = self.client.secrets.kv.v2.read_secret_version(
                path=secret_path,
                mount_point=mount_point
            )
            return response['data']['data']
        except Exception as e:
            print(f"Error fetching secret {key}: {e}")
            return None

@lru_cache()
def get_secrets_manager() -> SecretsManager:
    """Factory for secrets manager based on environment"""
    provider = os.getenv('SECRETS_PROVIDER', 'environment')
    
    if provider == 'aws':
        return AWSSecretsManager(
            region=os.getenv('AWS_REGION', 'us-east-1')
        )
    elif provider == 'vault':
        return VaultSecretsManager(
            url=os.getenv('VAULT_URL'),
            token=os.getenv('VAULT_TOKEN')
        )
    else:
        return EnvironmentSecretsManager()

# Usage
secrets = get_secrets_manager()
db_password = secrets.get_secret('DATABASE_PASSWORD')
api_keys = secrets.get_json_secret('API_KEYS')
```

---

## 19.5 Chaos Engineering

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CHAOS ENGINEERING                           â”‚
â”‚                                                              â”‚
â”‚  "The discipline of experimenting on a system to build      â”‚
â”‚   confidence in its capability to withstand turbulent       â”‚
â”‚   conditions in production."                                â”‚
â”‚                                                              â”‚
â”‚  Philosophy:                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                â”‚
â”‚  Don't wait for failures to happen.                         â”‚
â”‚  Deliberately CAUSE failures to find weaknesses.            â”‚
â”‚                                                              â”‚
â”‚                                                              â”‚
â”‚  Types of Chaos Experiments:                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚                                                              â”‚
â”‚  1. INFRASTRUCTURE FAILURES                                 â”‚
â”‚     â”œâ”€â”€ Kill random instances                               â”‚
â”‚     â”œâ”€â”€ Shut down availability zones                        â”‚
â”‚     â”œâ”€â”€ Fill disk space                                     â”‚
â”‚     â””â”€â”€ Exhaust CPU/memory                                  â”‚
â”‚                                                              â”‚
â”‚  2. NETWORK FAILURES                                        â”‚
â”‚     â”œâ”€â”€ Add latency (slow network)                          â”‚
â”‚     â”œâ”€â”€ Drop packets (unreliable network)                   â”‚
â”‚     â”œâ”€â”€ Partition network (split brain)                     â”‚
â”‚     â””â”€â”€ DNS failures                                        â”‚
â”‚                                                              â”‚
â”‚  3. APPLICATION FAILURES                                    â”‚
â”‚     â”œâ”€â”€ Crash processes                                     â”‚
â”‚     â”œâ”€â”€ Throw exceptions                                    â”‚
â”‚     â”œâ”€â”€ Return errors from dependencies                     â”‚
â”‚     â””â”€â”€ Slow down responses                                 â”‚
â”‚                                                              â”‚
â”‚  4. DEPENDENCY FAILURES                                     â”‚
â”‚     â”œâ”€â”€ Database unavailable                                â”‚
â”‚     â”œâ”€â”€ Cache failures                                      â”‚
â”‚     â”œâ”€â”€ Third-party API down                                â”‚
â”‚     â””â”€â”€ Message queue unavailable                           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
# chaos_engineering.py - Simple chaos testing framework
import asyncio
import random
from dataclasses import dataclass
from typing import Callable, Optional, List
from functools import wraps
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

@dataclass
class ChaosConfig:
    """Configuration for chaos experiments"""
    enabled: bool = False
    failure_rate: float = 0.1  # 10% failure rate
    latency_min_ms: int = 100
    latency_max_ms: int = 5000
    affected_services: List[str] = None

class ChaosMonkey:
    """
    Chaos Monkey - randomly injects failures into your system.
    """
    
    def __init__(self, config: ChaosConfig):
        self.config = config
        self.experiments_run = 0
        self.failures_injected = 0
    
    def should_inject_failure(self, service: str = None) -> bool:
        """Determine if we should inject a failure"""
        if not self.config.enabled:
            return False
        
        if self.config.affected_services:
            if service and service not in self.config.affected_services:
                return False
        
        return random.random() < self.config.failure_rate
    
    async def maybe_fail(self, service: str = None):
        """Maybe throw an exception"""
        if self.should_inject_failure(service):
            self.failures_injected += 1
            logger.warning(f"ğŸ’ Chaos Monkey: Injecting failure for {service}")
            raise Exception(f"Chaos Monkey killed {service}!")
    
    async def maybe_delay(self, service: str = None):
        """Maybe add latency"""
        if self.should_inject_failure(service):
            delay_ms = random.randint(
                self.config.latency_min_ms,
                self.config.latency_max_ms
            )
            logger.warning(f"ğŸ’ Chaos Monkey: Adding {delay_ms}ms delay for {service}")
            await asyncio.sleep(delay_ms / 1000)
    
    def chaos_decorator(self, service: str = None):
        """Decorator to add chaos to any async function"""
        def decorator(func: Callable):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                self.experiments_run += 1
                
                # Random failure type
                chaos_type = random.choice(['fail', 'delay', 'none'])
                
                if chaos_type == 'fail':
                    await self.maybe_fail(service)
                elif chaos_type == 'delay':
                    await self.maybe_delay(service)
                
                return await func(*args, **kwargs)
            return wrapper
        return decorator
    
    def get_stats(self) -> dict:
        return {
            "experiments_run": self.experiments_run,
            "failures_injected": self.failures_injected,
            "failure_rate": self.failures_injected / max(1, self.experiments_run)
        }

# ============== CHAOS EXPERIMENTS ==============

class ChaosExperiment:
    """Base class for chaos experiments"""
    
    def __init__(self, name: str, hypothesis: str):
        self.name = name
        self.hypothesis = hypothesis
        self.started_at: Optional[datetime] = None
        self.ended_at: Optional[datetime] = None
        self.results: dict = {}
    
    async def setup(self):
        """Setup before experiment"""
        pass
    
    async def run(self):
        """Run the experiment"""
        raise NotImplementedError
    
    async def teardown(self):
        """Cleanup after experiment"""
        pass
    
    async def execute(self) -> dict:
        """Execute the full experiment lifecycle"""
        self.started_at = datetime.utcnow()
        
        try:
            await self.setup()
            self.results = await self.run()
        finally:
            await self.teardown()
            self.ended_at = datetime.utcnow()
        
        return {
            "name": self.name,
            "hypothesis": self.hypothesis,
            "duration_seconds": (self.ended_at - self.started_at).total_seconds(),
            "results": self.results
        }

class ServiceFailureExperiment(ChaosExperiment):
    """Experiment: What happens when a dependency fails?"""
    
    def __init__(
        self, 
        target_service: str,
        duration_seconds: int = 60,
        health_check_url: str = None
    ):
        super().__init__(
            name=f"Service Failure: {target_service}",
            hypothesis=f"System remains available when {target_service} fails"
        )
        self.target_service = target_service
        self.duration_seconds = duration_seconds
        self.health_check_url = health_check_url
        self.original_state = None
    
    async def setup(self):
        """Save original state"""
        self.original_state = "running"
        logger.info(f"ğŸ”¬ Starting experiment: {self.name}")
    
    async def run(self) -> dict:
        """Inject failure and monitor"""
        import httpx
        
        results = {
            "successful_health_checks": 0,
            "failed_health_checks": 0,
            "errors": []
        }
        
        # Inject failure (in real scenario, would use k8s API, AWS API, etc.)
        logger.warning(f"ğŸ’¥ Injecting failure into {self.target_service}")
        
        # Monitor system health during failure
        end_time = datetime.utcnow() + timedelta(seconds=self.duration_seconds)
        
        async with httpx.AsyncClient() as client:
            while datetime.utcnow() < end_time:
                try:
                    if self.health_check_url:
                        response = await client.get(
                            self.health_check_url,
                            timeout=5.0
                        )
                        if response.status_code == 200:
                            results["successful_health_checks"] += 1
                        else:
                            results["failed_health_checks"] += 1
                except Exception as e:
                    results["failed_health_checks"] += 1
                    results["errors"].append(str(e))
                
                await asyncio.sleep(1)
        
        return results
    
    async def teardown(self):
        """Restore original state"""
        logger.info(f"ğŸ”§ Restoring {self.target_service} to original state")

class LatencyExperiment(ChaosExperiment):
    """Experiment: What happens with network latency?"""
    
    def __init__(
        self,
        target_service: str,
        latency_ms: int = 500,
        duration_seconds: int = 60
    ):
        super().__init__(
            name=f"Latency Injection: {target_service}",
            hypothesis=f"System handles {latency_ms}ms latency gracefully"
        )
        self.target_service = target_service
        self.latency_ms = latency_ms
        self.duration_seconds = duration_seconds
    
    async def run(self) -> dict:
        """Inject latency and monitor"""
        logger.warning(
            f"ğŸŒ Injecting {self.latency_ms}ms latency into {self.target_service}"
        )
        
        # In real scenario, use tc (traffic control) or service mesh
        # Here we just simulate
        await asyncio.sleep(self.duration_seconds)
        
        return {
            "latency_injected_ms": self.latency_ms,
            "duration_seconds": self.duration_seconds
        }

# ============== USAGE ==============

async def run_chaos_experiments():
    # Configure chaos monkey
    chaos = ChaosMonkey(ChaosConfig(
        enabled=True,
        failure_rate=0.1,
        affected_services=["user-service", "order-service"]
    ))
    
    # Example service with chaos
    @chaos.chaos_decorator(service="user-service")
    async def get_user(user_id: int):
        await asyncio.sleep(0.1)  # Simulate work
        return {"id": user_id, "name": "Alice"}
    
    # Run multiple requests
    print("Running requests with Chaos Monkey enabled...")
    successes = 0
    failures = 0
    
    for i in range(100):
        try:
            await get_user(i)
            successes += 1
        except Exception as e:
            failures += 1
    
    print(f"Results: {successes} successes, {failures} failures")
    print(f"Chaos stats: {chaos.get_stats()}")

# asyncio.run(run_chaos_experiments())
```

---

## Summary

| Topic | Key Points |
|-------|------------|
| **Rolling** | Gradual update, zero downtime, easy rollback |
| **Blue-Green** | Instant switch, double resources, easy rollback |
| **Canary** | Progressive rollout, automatic detection, safest |
| **Feature Flags** | Decouple deploy/release, A/B testing, kill switch |
| **Docker** | Consistent environments, isolated dependencies |
| **Kubernetes** | Orchestration, scaling, self-healing |
| **Chaos Engineering** | Find weaknesses before production failures |

---

## Practice Exercises

1. Create a multi-stage Dockerfile for your Python app
2. Write Kubernetes manifests with HPA and PDB
3. Implement a canary deployment controller
4. Build a feature flag service with percentage rollout
5. Run a chaos experiment against your service

**Next Chapter**: System Design Framework for interviews!
